{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatDoodlesGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av6c5F9HbGy-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rhbATqUbU5Z",
        "outputId": "21543750-4ddb-4186-c2d2-8ebd3099c1c7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") # Don't change this"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZweL-KZeb8Kq",
        "outputId": "71570607-f4cf-4068-a4b3-d24cb490e98e"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cats.npy\n",
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            " CoMeSySo_DiabetesPaper.zip\n",
            "'Designing a website - What is important.gdoc'\n",
            "'EAAA Robot Hackathon, august 2021..gform'\n",
            "'Hackathon. Plan.gdoc'\n",
            "'ITek, 2 sem. Programming 2. 2nd half of the course..gform'\n",
            "'Itek -Færdigheder.gsheet'\n",
            "'PBA AI Kursus. F2020.gform'\n",
            " RobotHackathon_KursusBevis.gdoc\n",
            "'Team 1. Ugeplan for Pupper Robot praktikperioden mm.gdoc'\n",
            "'Team 2. Ugeplan for Pupper Robot praktikperioden mm.gdoc'\n",
            "'Ugeplan for Pupper Robot praktikperioden.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgif6J3Oe6yM",
        "outputId": "6df71c9b-d230-49f1-a271-c3774e09d9d7"
      },
      "source": [
        "%cd drive"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD_wWCdFfL7k",
        "outputId": "4b262612-b4c5-4907-e4a8-bb949f400cce"
      },
      "source": [
        "%cd MyDrive/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzG2ulbnfRfk",
        "outputId": "738a75ca-a3c4-4d68-afef-8c32ac6311e0"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cats.npy\n",
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            " CoMeSySo_DiabetesPaper.zip\n",
            "'Designing a website - What is important.gdoc'\n",
            "'EAAA Robot Hackathon, august 2021..gform'\n",
            "'Hackathon. Plan.gdoc'\n",
            "'ITek, 2 sem. Programming 2. 2nd half of the course..gform'\n",
            "'Itek -Færdigheder.gsheet'\n",
            "'PBA AI Kursus. F2020.gform'\n",
            " RobotHackathon_KursusBevis.gdoc\n",
            "'Team 1. Ugeplan for Pupper Robot praktikperioden mm.gdoc'\n",
            "'Team 2. Ugeplan for Pupper Robot praktikperioden mm.gdoc'\n",
            "'Ugeplan for Pupper Robot praktikperioden.gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hm835LpUfiP6",
        "outputId": "cdd19163-a39d-4369-a744-7746f396af2e"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEW7SEiDfmyV"
      },
      "source": [
        "cat_doodles = np.load('/content/drive/My Drive/cats.npy')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "lngi7gsvgGOD",
        "outputId": "0df63eee-a06e-45d5-f407-45e4107d9a36"
      },
      "source": [
        "X_train = (cat_doodles.astype(np.float32)/127.5) - 1. #normalize to be [-1,1]\n",
        "num_train = X_train.shape[0]\n",
        "\n",
        "random_cat = X_train[np.random.randint(num_train-1)].reshape(28, 28)\n",
        "random_cat = random_cat*127.5 + 1\n",
        "plt.imshow(random_cat) #a wild random cat appears"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8907358ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8mIkG1-gyiw"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout, Flatten\n",
        "from keras.layers import Activation, Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.backend import clear_session\n",
        "np.random.seed(0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YabGK4d0hB6G"
      },
      "source": [
        "class SimpleGAN():\n",
        "  \n",
        "  def __init__(self):\n",
        "      self.img_rows = 28\n",
        "      self.img_cols = 28\n",
        "      self.img_shape = (self.img_rows, self.img_cols, 1)\n",
        "      self.latent_dim = 100\n",
        "\n",
        "      self.optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "      # Build and compile the discriminator\n",
        "      self.discriminator = self.build_discriminator()\n",
        "      self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
        "\n",
        "      # Build and compile the generator\n",
        "      self.generator = self.build_generator()\n",
        "      self.generator.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
        "\n",
        "      self.gan = self.build_GAN()\n",
        "  \n",
        "  def build_GAN(self):\n",
        "      self.discriminator.trainable = False\n",
        "      gan_input = Input(shape=(self.latent_dim,))\n",
        "      img = self.generator(gan_input)\n",
        "      \n",
        "      gan_output = self.discriminator(img)\n",
        "      gan = Model(gan_input, gan_output)\n",
        "      gan.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
        "      gan.summary()\n",
        "      \n",
        "      return gan\n",
        "  \n",
        "  def build_generator(self):\n",
        "\n",
        "      G = Sequential()\n",
        "\n",
        "      G.add(Dense(256, input_dim=self.latent_dim, kernel_initializer=RandomNormal(stddev=0.02)))\n",
        "      G.add(LeakyReLU(0.2))\n",
        "      G.add(Dense(512))\n",
        "      G.add(LeakyReLU(0.2))\n",
        "      G.add(Dense(1024))\n",
        "      G.add(LeakyReLU(0.2))\n",
        "      G.add(Dense(2048))\n",
        "      G.add(LeakyReLU(0.2))\n",
        "      G.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
        "      G.summary()\n",
        "\n",
        "      noise = Input(shape=(self.latent_dim,))\n",
        "      img = G(noise)\n",
        "\n",
        "      return Model(noise, img)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "\n",
        "      D = Sequential()\n",
        "      D.add(Dense(1024, input_dim=np.prod(self.img_shape), kernel_initializer=RandomNormal(stddev=0.02)))\n",
        "      D.add(LeakyReLU(0.2))\n",
        "      D.add(Dropout(0.4))\n",
        "      D.add(Dense(512))\n",
        "      D.add(LeakyReLU(0.2))\n",
        "      D.add(Dropout(0.4))\n",
        "      D.add(Dense(256))\n",
        "      D.add(LeakyReLU(0.2))\n",
        "      D.add(Dropout(0.4))\n",
        "      D.add(Dense(1, activation='sigmoid'))\n",
        "      D.summary()\n",
        "\n",
        "      img = Input(shape=(784, ))\n",
        "      validity = D(img)\n",
        "\n",
        "      return Model(img, validity)\n",
        "\n",
        "  def train(self, X_train, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "      real = np.ones((batch_size, 1))\n",
        "      fake = np.zeros((batch_size, 1))\n",
        "      avg_losses = {'D':[], 'G':[]}\n",
        "      num_batches = len(X_train) // batch_size\n",
        "      for epoch in range(epochs):\n",
        "          d_loss_acc = 0\n",
        "          g_loss_acc = 0\n",
        "          for i in range(num_batches):\n",
        "            \n",
        "            #Random batch of real doodles\n",
        "            imgs = X_train[np.random.randint(0, X_train.shape[0], batch_size)]\n",
        "\n",
        "\n",
        "            #Generate a batch of doodles\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "            #Train the discriminator (add random smoothing to labels)\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, real * (np.random.uniform(0.7, 1.2)))\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake + (np.random.uniform(0.0, 0.3)))\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            #We don't want the discriminator to get updated while the generator is being trained\n",
        "            self.discriminator.trainable = False\n",
        "            \n",
        "            #Train the generator\n",
        "            g_loss = self.gan.train_on_batch(noise, real)            \n",
        "\n",
        "#             if i % 100 == 0:\n",
        "            print (\"EPOCH:\", epoch, \"D LOSS\", d_loss, \"G LOSS:\", g_loss)\n",
        "            \n",
        "            d_loss_acc += d_loss\n",
        "            g_loss_acc += g_loss\n",
        "\n",
        "          #Print samples\n",
        "          if (epoch + 1) % sample_interval == 0:\n",
        "              self.sample_images(epoch)\n",
        "          \n",
        "          avg_losses['D'].append(d_loss_acc/num_batches)\n",
        "          avg_losses['G'].append(g_loss_acc/num_batches)\n",
        "      \n",
        "      self.plot_loss(avg_losses)\n",
        "\n",
        "  def sample_images(self, epoch):\n",
        "    num_examples = 100\n",
        "    random_noise = np.random.normal(0, 1, size=[num_examples, self.latent_dim])\n",
        "    generated_images = self.generator.predict(random_noise)\n",
        "    generated_images = generated_images.reshape(num_examples, 28, 28)*127.5 + 1\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(10, 10, i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    \n",
        "#     plt.tight_layout()\n",
        "    plt.suptitle(\"Samples from G - Epoch = \" + str(epoch+1))\n",
        "    plt.show()\n",
        "  \n",
        "  def plot_loss(self, losses):\n",
        "     \n",
        "      plt.figure(figsize=(10,8))\n",
        "      plt.plot(losses[\"D\"], label=\"Discriminator loss\")\n",
        "      plt.plot(losses[\"G\"], label=\"Generator loss\")\n",
        "   \n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      plt.legend()\n",
        "      plt.title(\"Loss History\")\n",
        "      plt.show()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TTnNj3BSiRfM",
        "outputId": "f6e74dad-7f56-4e7c-90b1-9827216e7a96"
      },
      "source": [
        "clear_session()\n",
        "gan = SimpleGAN()\n",
        "gan.train(X_train, epochs=100, batch_size=128, sample_interval=20)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1024)              803840    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,460,225\n",
            "Trainable params: 1,460,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2048)              2099200   \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 784)               1606416   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,388,368\n",
            "Trainable params: 4,388,368\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " model_1 (Functional)        (None, 784)               4388368   \n",
            "                                                                 \n",
            " model (Functional)          (None, 1)                 1460225   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,848,593\n",
            "Trainable params: 4,388,368\n",
            "Non-trainable params: 1,460,225\n",
            "_________________________________________________________________\n",
            "EPOCH: 0 D LOSS 0.5821457356214523 G LOSS: 0.6794263124465942\n",
            "EPOCH: 0 D LOSS 0.8104588985443115 G LOSS: 0.6577446460723877\n",
            "EPOCH: 0 D LOSS 0.5194529592990875 G LOSS: 0.6125912666320801\n",
            "EPOCH: 0 D LOSS 0.717281848192215 G LOSS: 0.595549464225769\n",
            "EPOCH: 0 D LOSS 0.6584599316120148 G LOSS: 0.5725255012512207\n",
            "EPOCH: 0 D LOSS 0.6632576286792755 G LOSS: 0.5869719982147217\n",
            "EPOCH: 0 D LOSS 0.5934102684259415 G LOSS: 0.6469528675079346\n",
            "EPOCH: 0 D LOSS 0.5386080592870712 G LOSS: 0.8060023784637451\n",
            "EPOCH: 0 D LOSS 0.3688595431158319 G LOSS: 0.8530102968215942\n",
            "EPOCH: 0 D LOSS 0.4229155480861664 G LOSS: 0.861129105091095\n",
            "EPOCH: 0 D LOSS 0.3933071158826351 G LOSS: 0.8991032242774963\n",
            "EPOCH: 0 D LOSS 0.1817305088043213 G LOSS: 0.6797951459884644\n",
            "EPOCH: 0 D LOSS 0.27379119396209717 G LOSS: 0.5274102687835693\n",
            "EPOCH: 0 D LOSS 0.2754545211791992 G LOSS: 0.39236685633659363\n",
            "EPOCH: 0 D LOSS 1.7744945287704468 G LOSS: 1.0458862781524658\n",
            "EPOCH: 0 D LOSS 0.9126501083374023 G LOSS: 0.8466745615005493\n",
            "EPOCH: 0 D LOSS 0.7837070226669312 G LOSS: 0.8684911727905273\n",
            "EPOCH: 0 D LOSS 0.7187473177909851 G LOSS: 0.9175942540168762\n",
            "EPOCH: 0 D LOSS 0.5994487553834915 G LOSS: 1.1274824142456055\n",
            "EPOCH: 0 D LOSS 0.36198096675798297 G LOSS: 1.1586582660675049\n",
            "EPOCH: 0 D LOSS 0.7566209435462952 G LOSS: 1.0513362884521484\n",
            "EPOCH: 0 D LOSS 0.6656502187252045 G LOSS: 0.817999005317688\n",
            "EPOCH: 0 D LOSS 0.6044740378856659 G LOSS: 0.7917494773864746\n",
            "EPOCH: 0 D LOSS 0.26777173578739166 G LOSS: 0.7770998477935791\n",
            "EPOCH: 0 D LOSS 0.6341916024684906 G LOSS: 0.8067352771759033\n",
            "EPOCH: 0 D LOSS 0.7562240958213806 G LOSS: 0.907692551612854\n",
            "EPOCH: 0 D LOSS 0.5773693919181824 G LOSS: 0.6797915101051331\n",
            "EPOCH: 0 D LOSS 0.4073618873953819 G LOSS: 0.5394777059555054\n",
            "EPOCH: 0 D LOSS 0.4115980640053749 G LOSS: 0.45700716972351074\n",
            "EPOCH: 0 D LOSS 0.8402804732322693 G LOSS: 0.5076776742935181\n",
            "EPOCH: 0 D LOSS 0.3974280059337616 G LOSS: 0.47309285402297974\n",
            "EPOCH: 0 D LOSS 0.8196776211261749 G LOSS: 0.6200593113899231\n",
            "EPOCH: 0 D LOSS 0.6265282928943634 G LOSS: 0.7313444018363953\n",
            "EPOCH: 0 D LOSS 0.649962991476059 G LOSS: 0.8051874041557312\n",
            "EPOCH: 0 D LOSS 0.6728822588920593 G LOSS: 0.8490012288093567\n",
            "EPOCH: 0 D LOSS 0.7347142100334167 G LOSS: 0.6213927865028381\n",
            "EPOCH: 0 D LOSS 0.6975584328174591 G LOSS: 0.734135627746582\n",
            "EPOCH: 0 D LOSS 0.6432907283306122 G LOSS: 0.7328968048095703\n",
            "EPOCH: 0 D LOSS 0.6590904891490936 G LOSS: 0.7005200386047363\n",
            "EPOCH: 0 D LOSS 0.6372337937355042 G LOSS: 0.8637194037437439\n",
            "EPOCH: 0 D LOSS 0.6561202108860016 G LOSS: 0.614305853843689\n",
            "EPOCH: 0 D LOSS 0.6726620197296143 G LOSS: 0.6880669593811035\n",
            "EPOCH: 0 D LOSS 0.5893865376710892 G LOSS: 0.6974616050720215\n",
            "EPOCH: 0 D LOSS 0.5796713382005692 G LOSS: 0.804739773273468\n",
            "EPOCH: 0 D LOSS 0.6062860488891602 G LOSS: 0.9678407907485962\n",
            "EPOCH: 0 D LOSS 0.5838745832443237 G LOSS: 1.00447416305542\n",
            "EPOCH: 0 D LOSS 0.5647053048014641 G LOSS: 0.7407246232032776\n",
            "EPOCH: 0 D LOSS 0.6062909364700317 G LOSS: 0.8669987916946411\n",
            "EPOCH: 0 D LOSS 0.5720069110393524 G LOSS: 0.8844143152236938\n",
            "EPOCH: 0 D LOSS 0.5505884140729904 G LOSS: 0.7124884128570557\n",
            "EPOCH: 0 D LOSS 0.6981046497821808 G LOSS: 0.9673607349395752\n",
            "EPOCH: 0 D LOSS 0.618715226650238 G LOSS: 0.982445240020752\n",
            "EPOCH: 0 D LOSS 0.7194425463676453 G LOSS: 0.6934619545936584\n",
            "EPOCH: 0 D LOSS 0.5769817531108856 G LOSS: 0.7287527322769165\n",
            "EPOCH: 0 D LOSS 0.5898102968931198 G LOSS: 0.9707392454147339\n",
            "EPOCH: 0 D LOSS 0.596908450126648 G LOSS: 1.0192205905914307\n",
            "EPOCH: 0 D LOSS 0.586256593465805 G LOSS: 0.9287047386169434\n",
            "EPOCH: 0 D LOSS 0.6104641854763031 G LOSS: 0.9837967753410339\n",
            "EPOCH: 0 D LOSS 0.6177155375480652 G LOSS: 0.8506983518600464\n",
            "EPOCH: 0 D LOSS 0.5831300020217896 G LOSS: 0.7972289323806763\n",
            "EPOCH: 0 D LOSS 0.37457433715462685 G LOSS: 0.5404720306396484\n",
            "EPOCH: 0 D LOSS 0.41796766221523285 G LOSS: 0.4913763403892517\n",
            "EPOCH: 0 D LOSS 0.9119678139686584 G LOSS: 0.7406495213508606\n",
            "EPOCH: 0 D LOSS 0.42474612407386303 G LOSS: 0.6339186429977417\n",
            "EPOCH: 0 D LOSS 0.7172977328300476 G LOSS: 0.7688776254653931\n",
            "EPOCH: 0 D LOSS 0.4807223603129387 G LOSS: 0.8149492740631104\n",
            "EPOCH: 0 D LOSS 0.4606849402189255 G LOSS: 0.961944580078125\n",
            "EPOCH: 0 D LOSS 0.31796909868717194 G LOSS: 0.9199825525283813\n",
            "EPOCH: 0 D LOSS 0.41724103689193726 G LOSS: 0.8043087720870972\n",
            "EPOCH: 0 D LOSS 0.5464190989732742 G LOSS: 0.977939248085022\n",
            "EPOCH: 0 D LOSS 0.7210877537727356 G LOSS: 0.8047247529029846\n",
            "EPOCH: 0 D LOSS 0.923524022102356 G LOSS: 0.47655442357063293\n",
            "EPOCH: 0 D LOSS 0.44562622904777527 G LOSS: 0.724542498588562\n",
            "EPOCH: 0 D LOSS 0.6333890557289124 G LOSS: 1.7158312797546387\n",
            "EPOCH: 0 D LOSS 0.46453121304512024 G LOSS: 1.0671849250793457\n",
            "EPOCH: 0 D LOSS 0.5919883847236633 G LOSS: 0.9961247444152832\n",
            "EPOCH: 0 D LOSS 0.5935778319835663 G LOSS: 1.043991208076477\n",
            "EPOCH: 0 D LOSS 0.6993961930274963 G LOSS: 0.5925043821334839\n",
            "EPOCH: 0 D LOSS 0.5578941255807877 G LOSS: 0.5830553770065308\n",
            "EPOCH: 0 D LOSS 0.4017890952527523 G LOSS: 0.5414379835128784\n",
            "EPOCH: 0 D LOSS 0.8244590163230896 G LOSS: 0.7574738264083862\n",
            "EPOCH: 0 D LOSS 0.4887683689594269 G LOSS: 0.7403059005737305\n",
            "EPOCH: 0 D LOSS 0.48548177629709244 G LOSS: 0.7051017880439758\n",
            "EPOCH: 0 D LOSS 0.5995078086853027 G LOSS: 0.8182548880577087\n",
            "EPOCH: 0 D LOSS 0.5048679709434509 G LOSS: 0.9310041666030884\n",
            "EPOCH: 0 D LOSS 0.5102255046367645 G LOSS: 1.0240654945373535\n",
            "EPOCH: 0 D LOSS 0.52729332447052 G LOSS: 1.0203633308410645\n",
            "EPOCH: 0 D LOSS 0.6093952655792236 G LOSS: 1.113504409790039\n",
            "EPOCH: 0 D LOSS 0.6339938342571259 G LOSS: 0.8108985424041748\n",
            "EPOCH: 0 D LOSS 0.5535106658935547 G LOSS: 0.827013373374939\n",
            "EPOCH: 0 D LOSS 0.3885121587663889 G LOSS: 0.7295852899551392\n",
            "EPOCH: 0 D LOSS 0.522075355052948 G LOSS: 0.7711343169212341\n",
            "EPOCH: 0 D LOSS 0.541155606508255 G LOSS: 0.9025058746337891\n",
            "EPOCH: 0 D LOSS 0.5106526911258698 G LOSS: 0.9173755645751953\n",
            "EPOCH: 0 D LOSS 0.4404379054903984 G LOSS: 0.7409650087356567\n",
            "EPOCH: 0 D LOSS 0.6970509886741638 G LOSS: 0.7729140520095825\n",
            "EPOCH: 0 D LOSS 0.6045450568199158 G LOSS: 0.8057907819747925\n",
            "EPOCH: 0 D LOSS 0.4782731235027313 G LOSS: 0.8318581581115723\n",
            "EPOCH: 0 D LOSS 0.2825894430279732 G LOSS: 0.809993326663971\n",
            "EPOCH: 0 D LOSS 0.317874014377594 G LOSS: 0.9863420724868774\n",
            "EPOCH: 0 D LOSS 0.10554459691047668 G LOSS: 1.2391477823257446\n",
            "EPOCH: 0 D LOSS 0.6248777806758881 G LOSS: 1.377756118774414\n",
            "EPOCH: 0 D LOSS 0.5197675228118896 G LOSS: 1.051987886428833\n",
            "EPOCH: 0 D LOSS 0.5554828196763992 G LOSS: 0.6400629281997681\n",
            "EPOCH: 0 D LOSS 0.41567331552505493 G LOSS: 0.4682435393333435\n",
            "EPOCH: 0 D LOSS 0.45275890827178955 G LOSS: 0.5033937692642212\n",
            "EPOCH: 0 D LOSS 0.5205967798829079 G LOSS: 0.817795991897583\n",
            "EPOCH: 0 D LOSS 0.3978065252304077 G LOSS: 0.9033782482147217\n",
            "EPOCH: 0 D LOSS 0.5138846039772034 G LOSS: 1.1330361366271973\n",
            "EPOCH: 0 D LOSS 0.484281986951828 G LOSS: 0.9021241664886475\n",
            "EPOCH: 0 D LOSS 0.453357994556427 G LOSS: 0.9120051860809326\n",
            "EPOCH: 0 D LOSS 0.6116240620613098 G LOSS: 1.1916042566299438\n",
            "EPOCH: 0 D LOSS 0.4527027904987335 G LOSS: 0.8861967325210571\n",
            "EPOCH: 0 D LOSS 0.596389502286911 G LOSS: 0.9000900983810425\n",
            "EPOCH: 0 D LOSS 0.3303211978636682 G LOSS: 0.90309739112854\n",
            "EPOCH: 0 D LOSS 0.3750124014914036 G LOSS: 0.9094042778015137\n",
            "EPOCH: 0 D LOSS 0.5944516956806183 G LOSS: 0.9720872640609741\n",
            "EPOCH: 0 D LOSS 0.41271544247865677 G LOSS: 0.8824281692504883\n",
            "EPOCH: 0 D LOSS 0.7338079214096069 G LOSS: 0.955531120300293\n",
            "EPOCH: 0 D LOSS 0.5395210683345795 G LOSS: 0.849494218826294\n",
            "EPOCH: 0 D LOSS 0.5443703085184097 G LOSS: 0.8308852910995483\n",
            "EPOCH: 0 D LOSS 0.4385429620742798 G LOSS: 0.8557134866714478\n",
            "EPOCH: 0 D LOSS 0.49861957132816315 G LOSS: 1.0906038284301758\n",
            "EPOCH: 0 D LOSS 0.477032333612442 G LOSS: 1.1203088760375977\n",
            "EPOCH: 0 D LOSS 0.48385876417160034 G LOSS: 0.9163433313369751\n",
            "EPOCH: 0 D LOSS 0.6139090657234192 G LOSS: 0.8980351686477661\n",
            "EPOCH: 0 D LOSS 0.5483762919902802 G LOSS: 0.949425995349884\n",
            "EPOCH: 0 D LOSS 0.4904369115829468 G LOSS: 1.0194532871246338\n",
            "EPOCH: 0 D LOSS 0.5054807364940643 G LOSS: 1.0116307735443115\n",
            "EPOCH: 0 D LOSS 0.47706790268421173 G LOSS: 0.8696099519729614\n",
            "EPOCH: 0 D LOSS 0.6613608300685883 G LOSS: 1.0581302642822266\n",
            "EPOCH: 0 D LOSS 0.6337808668613434 G LOSS: 1.1015136241912842\n",
            "EPOCH: 0 D LOSS 0.6474285125732422 G LOSS: 0.8326643109321594\n",
            "EPOCH: 0 D LOSS 0.6215273439884186 G LOSS: 0.8430717587471008\n",
            "EPOCH: 0 D LOSS 0.3968939483165741 G LOSS: 0.8676077127456665\n",
            "EPOCH: 0 D LOSS 0.35098082199692726 G LOSS: 1.059356689453125\n",
            "EPOCH: 0 D LOSS 0.3380315899848938 G LOSS: 1.272862434387207\n",
            "EPOCH: 0 D LOSS 0.6024637818336487 G LOSS: 1.225907564163208\n",
            "EPOCH: 0 D LOSS 0.7206589877605438 G LOSS: 1.018172264099121\n",
            "EPOCH: 0 D LOSS 0.8805494606494904 G LOSS: 0.44521617889404297\n",
            "EPOCH: 0 D LOSS 0.8388950228691101 G LOSS: 0.7042673826217651\n",
            "EPOCH: 0 D LOSS 0.5387652069330215 G LOSS: 0.8870575428009033\n",
            "EPOCH: 0 D LOSS 0.513884574174881 G LOSS: 0.8336080312728882\n",
            "EPOCH: 0 D LOSS 0.5312532335519791 G LOSS: 0.8113467693328857\n",
            "EPOCH: 0 D LOSS 0.5589287281036377 G LOSS: 0.8474197387695312\n",
            "EPOCH: 0 D LOSS 0.5644984096288681 G LOSS: 0.911259114742279\n",
            "EPOCH: 0 D LOSS 0.44374391436576843 G LOSS: 0.9632117748260498\n",
            "EPOCH: 0 D LOSS 0.37920263037085533 G LOSS: 0.811509907245636\n",
            "EPOCH: 0 D LOSS 0.349403977394104 G LOSS: 0.8311682939529419\n",
            "EPOCH: 0 D LOSS 0.42390840500593185 G LOSS: 0.9515695571899414\n",
            "EPOCH: 0 D LOSS 0.3839469403028488 G LOSS: 0.8077216148376465\n",
            "EPOCH: 0 D LOSS 0.4500477835536003 G LOSS: 0.7968266010284424\n",
            "EPOCH: 0 D LOSS 0.5747109204530716 G LOSS: 0.887259840965271\n",
            "EPOCH: 0 D LOSS 0.5739628374576569 G LOSS: 0.8371623158454895\n",
            "EPOCH: 0 D LOSS 0.5788710862398148 G LOSS: 0.869682788848877\n",
            "EPOCH: 0 D LOSS 0.5244096964597702 G LOSS: 0.9089577794075012\n",
            "EPOCH: 0 D LOSS 0.5561381876468658 G LOSS: 1.0876604318618774\n",
            "EPOCH: 0 D LOSS 0.48493391275405884 G LOSS: 1.1283926963806152\n",
            "EPOCH: 0 D LOSS 0.5806940495967865 G LOSS: 1.2601661682128906\n",
            "EPOCH: 0 D LOSS 0.5698919892311096 G LOSS: 1.1263447999954224\n",
            "EPOCH: 0 D LOSS 0.5736562013626099 G LOSS: 1.0707361698150635\n",
            "EPOCH: 0 D LOSS 0.5416864235885441 G LOSS: 0.9062677621841431\n",
            "EPOCH: 0 D LOSS 0.6907298862934113 G LOSS: 1.1613315343856812\n",
            "EPOCH: 0 D LOSS 0.6456561386585236 G LOSS: 1.0771410465240479\n",
            "EPOCH: 0 D LOSS 0.6902069449424744 G LOSS: 0.9233704805374146\n",
            "EPOCH: 0 D LOSS 0.49762778729200363 G LOSS: 0.7649427056312561\n",
            "EPOCH: 0 D LOSS 0.7362397313117981 G LOSS: 0.9158368706703186\n",
            "EPOCH: 0 D LOSS 0.6473890841007233 G LOSS: 1.1105769872665405\n",
            "EPOCH: 0 D LOSS 0.6051932871341705 G LOSS: 0.9273436665534973\n",
            "EPOCH: 0 D LOSS 0.5144916325807571 G LOSS: 0.7307083606719971\n",
            "EPOCH: 0 D LOSS 0.48818978667259216 G LOSS: 0.9322065114974976\n",
            "EPOCH: 0 D LOSS 0.48161838948726654 G LOSS: 1.257444977760315\n",
            "EPOCH: 0 D LOSS 0.5127944052219391 G LOSS: 1.1460052728652954\n",
            "EPOCH: 0 D LOSS 0.5142553597688675 G LOSS: 1.2036399841308594\n",
            "EPOCH: 0 D LOSS 0.5280886590480804 G LOSS: 1.0149873495101929\n",
            "EPOCH: 0 D LOSS 0.4935171939432621 G LOSS: 0.8526731729507446\n",
            "EPOCH: 0 D LOSS 0.35606101155281067 G LOSS: 0.8416252136230469\n",
            "EPOCH: 0 D LOSS 0.6748886108398438 G LOSS: 1.2657885551452637\n",
            "EPOCH: 0 D LOSS 0.6098814010620117 G LOSS: 0.8465821743011475\n",
            "EPOCH: 0 D LOSS 0.655904233455658 G LOSS: 0.9541216492652893\n",
            "EPOCH: 0 D LOSS 0.5957139432430267 G LOSS: 1.331634759902954\n",
            "EPOCH: 0 D LOSS 0.6119622588157654 G LOSS: 1.2493497133255005\n",
            "EPOCH: 0 D LOSS 0.6285761594772339 G LOSS: 1.0987238883972168\n",
            "EPOCH: 0 D LOSS 0.6062035262584686 G LOSS: 0.9505813717842102\n",
            "EPOCH: 0 D LOSS 0.5554083436727524 G LOSS: 0.9639449119567871\n",
            "EPOCH: 0 D LOSS 0.5855347216129303 G LOSS: 1.1074533462524414\n",
            "EPOCH: 0 D LOSS 0.5307208746671677 G LOSS: 1.0197172164916992\n",
            "EPOCH: 0 D LOSS 0.5128388702869415 G LOSS: 0.8461786508560181\n",
            "EPOCH: 0 D LOSS 0.47673606872558594 G LOSS: 1.0000150203704834\n",
            "EPOCH: 0 D LOSS 0.5827942490577698 G LOSS: 1.22049081325531\n",
            "EPOCH: 0 D LOSS 0.5766766369342804 G LOSS: 0.8185248374938965\n",
            "EPOCH: 0 D LOSS 0.5685739070177078 G LOSS: 0.9583311676979065\n",
            "EPOCH: 0 D LOSS 0.4766164571046829 G LOSS: 0.9807478785514832\n",
            "EPOCH: 0 D LOSS 0.5607016831636429 G LOSS: 1.0034654140472412\n",
            "EPOCH: 0 D LOSS 0.5855478122830391 G LOSS: 0.834529459476471\n",
            "EPOCH: 0 D LOSS 0.504631757736206 G LOSS: 1.0033917427062988\n",
            "EPOCH: 0 D LOSS 0.5312302485108376 G LOSS: 0.9527784585952759\n",
            "EPOCH: 0 D LOSS 0.4216931685805321 G LOSS: 1.040585994720459\n",
            "EPOCH: 0 D LOSS 0.4362907111644745 G LOSS: 1.2718846797943115\n",
            "EPOCH: 0 D LOSS 0.4360986649990082 G LOSS: 1.419357419013977\n",
            "EPOCH: 0 D LOSS 0.6641043424606323 G LOSS: 0.9473350644111633\n",
            "EPOCH: 0 D LOSS 0.344914510846138 G LOSS: 0.9147130250930786\n",
            "EPOCH: 0 D LOSS 0.46838119626045227 G LOSS: 1.3510781526565552\n",
            "EPOCH: 0 D LOSS 0.4863397032022476 G LOSS: 1.167792797088623\n",
            "EPOCH: 0 D LOSS 0.6475154459476471 G LOSS: 1.289466381072998\n",
            "EPOCH: 0 D LOSS 0.6151918768882751 G LOSS: 1.1825652122497559\n",
            "EPOCH: 0 D LOSS 0.6549924314022064 G LOSS: 1.1543267965316772\n",
            "EPOCH: 0 D LOSS 0.6979672610759735 G LOSS: 1.072800636291504\n",
            "EPOCH: 0 D LOSS 0.5833065807819366 G LOSS: 1.139222264289856\n",
            "EPOCH: 0 D LOSS 0.4156598951667547 G LOSS: 0.8865047693252563\n",
            "EPOCH: 0 D LOSS 0.39413735270500183 G LOSS: 1.2759233713150024\n",
            "EPOCH: 0 D LOSS 0.6336566805839539 G LOSS: 2.1427764892578125\n",
            "EPOCH: 0 D LOSS 0.9744191765785217 G LOSS: 0.6999607086181641\n",
            "EPOCH: 0 D LOSS 0.3688955157995224 G LOSS: 0.6695822477340698\n",
            "EPOCH: 0 D LOSS 0.43553730845451355 G LOSS: 0.8543274402618408\n",
            "EPOCH: 0 D LOSS 0.5397710502147675 G LOSS: 1.2046525478363037\n",
            "EPOCH: 0 D LOSS 0.4996972680091858 G LOSS: 1.0277525186538696\n",
            "EPOCH: 0 D LOSS 0.4528462737798691 G LOSS: 0.8783373832702637\n",
            "EPOCH: 0 D LOSS 0.465669609606266 G LOSS: 0.9159612655639648\n",
            "EPOCH: 0 D LOSS 0.5992529392242432 G LOSS: 1.1325600147247314\n",
            "EPOCH: 0 D LOSS 0.6706717759370804 G LOSS: 0.7675160765647888\n",
            "EPOCH: 0 D LOSS 0.5905805826187134 G LOSS: 0.9383113384246826\n",
            "EPOCH: 0 D LOSS 0.6207623481750488 G LOSS: 1.1329967975616455\n",
            "EPOCH: 0 D LOSS 0.6432714760303497 G LOSS: 1.065361738204956\n",
            "EPOCH: 0 D LOSS 0.6425257325172424 G LOSS: 1.1375339031219482\n",
            "EPOCH: 0 D LOSS 0.5295551419258118 G LOSS: 0.9628168344497681\n",
            "EPOCH: 0 D LOSS 0.5394222587347031 G LOSS: 1.1148157119750977\n",
            "EPOCH: 0 D LOSS 0.49452364444732666 G LOSS: 1.1731281280517578\n",
            "EPOCH: 0 D LOSS 0.4675452709197998 G LOSS: 1.2176860570907593\n",
            "EPOCH: 0 D LOSS 0.532106027007103 G LOSS: 1.1777689456939697\n",
            "EPOCH: 0 D LOSS 0.5431635975837708 G LOSS: 1.464319109916687\n",
            "EPOCH: 0 D LOSS 0.5877489447593689 G LOSS: 1.2207543849945068\n",
            "EPOCH: 0 D LOSS 0.6160309314727783 G LOSS: 1.1960406303405762\n",
            "EPOCH: 0 D LOSS 0.5274588316679001 G LOSS: 1.14371919631958\n",
            "EPOCH: 0 D LOSS 0.5688509345054626 G LOSS: 1.3186981678009033\n",
            "EPOCH: 0 D LOSS 0.6132104098796844 G LOSS: 1.2062780857086182\n",
            "EPOCH: 0 D LOSS 0.44537438452243805 G LOSS: 0.8588742017745972\n",
            "EPOCH: 0 D LOSS 0.3677040599286556 G LOSS: 0.8226783275604248\n",
            "EPOCH: 0 D LOSS 0.3870828105136752 G LOSS: 1.064897894859314\n",
            "EPOCH: 0 D LOSS 0.2753792926669121 G LOSS: 1.1115872859954834\n",
            "EPOCH: 0 D LOSS 0.6714814156293869 G LOSS: 1.5030320882797241\n",
            "EPOCH: 0 D LOSS 0.6605995893478394 G LOSS: 0.916252613067627\n",
            "EPOCH: 0 D LOSS 0.4204884245991707 G LOSS: 0.7642424702644348\n",
            "EPOCH: 0 D LOSS 0.4032422751188278 G LOSS: 0.9133230447769165\n",
            "EPOCH: 0 D LOSS 0.7186198532581329 G LOSS: 1.0896885395050049\n",
            "EPOCH: 0 D LOSS 0.4447190463542938 G LOSS: 0.913093626499176\n",
            "EPOCH: 0 D LOSS 0.3863156922161579 G LOSS: 0.9658881425857544\n",
            "EPOCH: 0 D LOSS 0.4908275008201599 G LOSS: 1.2057961225509644\n",
            "EPOCH: 0 D LOSS 0.30203364230692387 G LOSS: 1.048053503036499\n",
            "EPOCH: 0 D LOSS 0.4615180194377899 G LOSS: 1.1627042293548584\n",
            "EPOCH: 0 D LOSS 0.45695434883236885 G LOSS: 1.4610296487808228\n",
            "EPOCH: 0 D LOSS 0.4154273569583893 G LOSS: 0.888719916343689\n",
            "EPOCH: 0 D LOSS 0.7362740933895111 G LOSS: 1.304906964302063\n",
            "EPOCH: 0 D LOSS 0.4023890420794487 G LOSS: 1.2716469764709473\n",
            "EPOCH: 0 D LOSS 0.4655107371509075 G LOSS: 1.043770432472229\n",
            "EPOCH: 0 D LOSS 0.3609895557165146 G LOSS: 1.0675718784332275\n",
            "EPOCH: 0 D LOSS 0.3665594458580017 G LOSS: 1.1423451900482178\n",
            "EPOCH: 0 D LOSS 0.35190650820732117 G LOSS: 1.3191719055175781\n",
            "EPOCH: 0 D LOSS 0.5163211673498154 G LOSS: 2.0103554725646973\n",
            "EPOCH: 0 D LOSS 0.7112970650196075 G LOSS: 1.185539722442627\n",
            "EPOCH: 0 D LOSS 0.552890419960022 G LOSS: 0.7210707664489746\n",
            "EPOCH: 0 D LOSS 0.5311345532536507 G LOSS: 1.0711898803710938\n",
            "EPOCH: 0 D LOSS 0.4248373955488205 G LOSS: 1.2400763034820557\n",
            "EPOCH: 0 D LOSS 0.5369442403316498 G LOSS: 1.31672203540802\n",
            "EPOCH: 0 D LOSS 0.5746163129806519 G LOSS: 1.3979617357254028\n",
            "EPOCH: 0 D LOSS 0.47845517098903656 G LOSS: 1.0681779384613037\n",
            "EPOCH: 0 D LOSS 0.5484483391046524 G LOSS: 1.417327642440796\n",
            "EPOCH: 0 D LOSS 0.4698832929134369 G LOSS: 1.2059791088104248\n",
            "EPOCH: 0 D LOSS 0.5144073963165283 G LOSS: 1.2619556188583374\n",
            "EPOCH: 0 D LOSS 0.3679870702326298 G LOSS: 0.9733974933624268\n",
            "EPOCH: 0 D LOSS 0.683722198009491 G LOSS: 1.3681681156158447\n",
            "EPOCH: 0 D LOSS 0.6490850150585175 G LOSS: 1.2662125825881958\n",
            "EPOCH: 0 D LOSS 0.6536425948143005 G LOSS: 0.9878473281860352\n",
            "EPOCH: 0 D LOSS 0.542605072259903 G LOSS: 1.1224437952041626\n",
            "EPOCH: 0 D LOSS 0.60222327709198 G LOSS: 1.212327003479004\n",
            "EPOCH: 0 D LOSS 0.4859929829835892 G LOSS: 0.9507407546043396\n",
            "EPOCH: 0 D LOSS 0.44544365257024765 G LOSS: 1.0684363842010498\n",
            "EPOCH: 0 D LOSS 0.1606554090976715 G LOSS: 1.0863101482391357\n",
            "EPOCH: 0 D LOSS 0.5267271548509598 G LOSS: 1.44012451171875\n",
            "EPOCH: 0 D LOSS 0.47211435437202454 G LOSS: 1.3645120859146118\n",
            "EPOCH: 0 D LOSS 0.5825630724430084 G LOSS: 1.432877779006958\n",
            "EPOCH: 0 D LOSS 0.7386126518249512 G LOSS: 0.850608766078949\n",
            "EPOCH: 0 D LOSS 0.6117148399353027 G LOSS: 1.243023157119751\n",
            "EPOCH: 0 D LOSS 0.5746661722660065 G LOSS: 1.3106259107589722\n",
            "EPOCH: 0 D LOSS 0.5621678829193115 G LOSS: 1.0601252317428589\n",
            "EPOCH: 0 D LOSS 0.38624926656484604 G LOSS: 0.9263327121734619\n",
            "EPOCH: 0 D LOSS 0.4118935167789459 G LOSS: 1.0412838459014893\n",
            "EPOCH: 0 D LOSS 0.2375812977552414 G LOSS: 0.9150814414024353\n",
            "EPOCH: 0 D LOSS 0.5069060400128365 G LOSS: 1.5338681936264038\n",
            "EPOCH: 0 D LOSS 0.33893559873104095 G LOSS: 1.2127892971038818\n",
            "EPOCH: 0 D LOSS 0.4131774455308914 G LOSS: 1.05869460105896\n",
            "EPOCH: 0 D LOSS 0.21812286972999573 G LOSS: 1.2019243240356445\n",
            "EPOCH: 0 D LOSS 0.4173243045806885 G LOSS: 1.3364543914794922\n",
            "EPOCH: 0 D LOSS 0.36403294280171394 G LOSS: 0.9365322589874268\n",
            "EPOCH: 0 D LOSS 0.5437881052494049 G LOSS: 0.9946556091308594\n",
            "EPOCH: 0 D LOSS 0.4418754633516073 G LOSS: 0.9609988331794739\n",
            "EPOCH: 0 D LOSS 0.3948185443878174 G LOSS: 0.9396969676017761\n",
            "EPOCH: 0 D LOSS 0.40574110485613346 G LOSS: 1.101271390914917\n",
            "EPOCH: 0 D LOSS 0.46095407009124756 G LOSS: 1.5964001417160034\n",
            "EPOCH: 0 D LOSS 0.3049718886613846 G LOSS: 1.1587414741516113\n",
            "EPOCH: 0 D LOSS 0.6475524604320526 G LOSS: 1.3203281164169312\n",
            "EPOCH: 0 D LOSS 0.38904635515064 G LOSS: 1.318596363067627\n",
            "EPOCH: 0 D LOSS 0.6401943862438202 G LOSS: 1.7187047004699707\n",
            "EPOCH: 0 D LOSS 0.6485008001327515 G LOSS: 1.5010802745819092\n",
            "EPOCH: 0 D LOSS 0.7071970403194427 G LOSS: 1.3855361938476562\n",
            "EPOCH: 0 D LOSS 0.6644428670406342 G LOSS: 1.4035152196884155\n",
            "EPOCH: 0 D LOSS 0.47054439783096313 G LOSS: 1.3694239854812622\n",
            "EPOCH: 0 D LOSS 0.603979766368866 G LOSS: 1.1939483880996704\n",
            "EPOCH: 0 D LOSS 0.6076070070266724 G LOSS: 1.3561863899230957\n",
            "EPOCH: 0 D LOSS 0.6025192141532898 G LOSS: 1.0129063129425049\n",
            "EPOCH: 0 D LOSS 0.48673978820443153 G LOSS: 1.1841368675231934\n",
            "EPOCH: 0 D LOSS 0.2988312318921089 G LOSS: 1.2950514554977417\n",
            "EPOCH: 0 D LOSS 0.24933097511529922 G LOSS: 1.1132043600082397\n",
            "EPOCH: 0 D LOSS 0.7176873981952667 G LOSS: 1.7280771732330322\n",
            "EPOCH: 0 D LOSS 0.5258131623268127 G LOSS: 1.0100280046463013\n",
            "EPOCH: 0 D LOSS 0.7197092920541763 G LOSS: 1.3233658075332642\n",
            "EPOCH: 0 D LOSS 0.29401100240647793 G LOSS: 1.1724516153335571\n",
            "EPOCH: 0 D LOSS 0.6629703044891357 G LOSS: 1.4690548181533813\n",
            "EPOCH: 0 D LOSS 0.6693896949291229 G LOSS: 1.4041860103607178\n",
            "EPOCH: 0 D LOSS 0.7554441690444946 G LOSS: 1.0883855819702148\n",
            "EPOCH: 0 D LOSS 0.6496808379888535 G LOSS: 1.0822491645812988\n",
            "EPOCH: 0 D LOSS 0.428016260266304 G LOSS: 1.2275927066802979\n",
            "EPOCH: 0 D LOSS 0.586506187915802 G LOSS: 1.3715755939483643\n",
            "EPOCH: 0 D LOSS 0.548719048500061 G LOSS: 1.4198368787765503\n",
            "EPOCH: 0 D LOSS 0.49376925826072693 G LOSS: 1.2963733673095703\n",
            "EPOCH: 0 D LOSS 0.5079285800457001 G LOSS: 1.2713642120361328\n",
            "EPOCH: 0 D LOSS 0.6073062717914581 G LOSS: 1.4786115884780884\n",
            "EPOCH: 0 D LOSS 0.6175280809402466 G LOSS: 1.151111364364624\n",
            "EPOCH: 0 D LOSS 0.5167360603809357 G LOSS: 1.0215184688568115\n",
            "EPOCH: 0 D LOSS 0.3123008720576763 G LOSS: 1.3077526092529297\n",
            "EPOCH: 0 D LOSS 0.23113565146923065 G LOSS: 1.4849212169647217\n",
            "EPOCH: 0 D LOSS 0.2986278310418129 G LOSS: 1.3310809135437012\n",
            "EPOCH: 0 D LOSS 0.28578488528728485 G LOSS: 1.3090898990631104\n",
            "EPOCH: 0 D LOSS 0.39588428288698196 G LOSS: 1.2838908433914185\n",
            "EPOCH: 0 D LOSS 0.5650408864021301 G LOSS: 1.456160068511963\n",
            "EPOCH: 0 D LOSS 0.7137596607208252 G LOSS: 1.1504589319229126\n",
            "EPOCH: 0 D LOSS 0.8237803876399994 G LOSS: 1.145890474319458\n",
            "EPOCH: 0 D LOSS 0.5752792954444885 G LOSS: 1.5110206604003906\n",
            "EPOCH: 0 D LOSS 0.6432003974914551 G LOSS: 1.3633031845092773\n",
            "EPOCH: 0 D LOSS 0.7097568809986115 G LOSS: 0.9616507887840271\n",
            "EPOCH: 0 D LOSS 0.5857712915167212 G LOSS: 1.4649850130081177\n",
            "EPOCH: 0 D LOSS 0.5064132362604141 G LOSS: 1.4971578121185303\n",
            "EPOCH: 0 D LOSS 0.6812695264816284 G LOSS: 1.3600106239318848\n",
            "EPOCH: 0 D LOSS 0.7769708037376404 G LOSS: 1.011000156402588\n",
            "EPOCH: 0 D LOSS 0.6320231258869171 G LOSS: 1.2425533533096313\n",
            "EPOCH: 0 D LOSS 0.6793968379497528 G LOSS: 1.215530276298523\n",
            "EPOCH: 0 D LOSS 0.6628164649009705 G LOSS: 1.04252028465271\n",
            "EPOCH: 0 D LOSS 0.7547460794448853 G LOSS: 0.9535803198814392\n",
            "EPOCH: 0 D LOSS 0.5918655097484589 G LOSS: 1.24918794631958\n",
            "EPOCH: 0 D LOSS 0.48257313668727875 G LOSS: 1.2595109939575195\n",
            "EPOCH: 0 D LOSS 0.4188665822148323 G LOSS: 1.3485214710235596\n",
            "EPOCH: 0 D LOSS 0.2644459828734398 G LOSS: 1.4752379655838013\n",
            "EPOCH: 0 D LOSS 0.34316015988588333 G LOSS: 1.583859920501709\n",
            "EPOCH: 0 D LOSS 0.49851933121681213 G LOSS: 1.54274320602417\n",
            "EPOCH: 0 D LOSS 0.5936921983957291 G LOSS: 0.9895411133766174\n",
            "EPOCH: 0 D LOSS 0.4893203675746918 G LOSS: 0.9674428701400757\n",
            "EPOCH: 0 D LOSS 0.4846302792429924 G LOSS: 1.301021695137024\n",
            "EPOCH: 0 D LOSS 0.430866003036499 G LOSS: 1.2831180095672607\n",
            "EPOCH: 0 D LOSS 0.4471478536725044 G LOSS: 0.9703512191772461\n",
            "EPOCH: 0 D LOSS 0.5641693007200956 G LOSS: 1.4426016807556152\n",
            "EPOCH: 0 D LOSS 0.49102360010147095 G LOSS: 1.5416204929351807\n",
            "EPOCH: 0 D LOSS 0.5262224972248077 G LOSS: 1.4638323783874512\n",
            "EPOCH: 0 D LOSS 0.5369299650192261 G LOSS: 0.8836395740509033\n",
            "EPOCH: 0 D LOSS 0.4219967247918248 G LOSS: 0.9742557406425476\n",
            "EPOCH: 0 D LOSS 0.5368228107690811 G LOSS: 1.3359297513961792\n",
            "EPOCH: 0 D LOSS 0.6006043255329132 G LOSS: 1.1825847625732422\n",
            "EPOCH: 0 D LOSS 0.47576500475406647 G LOSS: 0.9443989992141724\n",
            "EPOCH: 0 D LOSS 0.29479774832725525 G LOSS: 1.0633760690689087\n",
            "EPOCH: 0 D LOSS 0.19636240601539612 G LOSS: 1.1051685810089111\n",
            "EPOCH: 0 D LOSS 0.34985217452049255 G LOSS: 1.2062487602233887\n",
            "EPOCH: 0 D LOSS 0.6909941583871841 G LOSS: 1.6134958267211914\n",
            "EPOCH: 0 D LOSS 0.4748821258544922 G LOSS: 1.1394740343093872\n",
            "EPOCH: 0 D LOSS 0.6159210205078125 G LOSS: 1.336106777191162\n",
            "EPOCH: 0 D LOSS 0.3675842210650444 G LOSS: 1.2107632160186768\n",
            "EPOCH: 0 D LOSS 0.4463280402123928 G LOSS: 1.336844801902771\n",
            "EPOCH: 0 D LOSS 0.7024918496608734 G LOSS: 1.574472427368164\n",
            "EPOCH: 0 D LOSS 0.7193710803985596 G LOSS: 0.8874120116233826\n",
            "EPOCH: 0 D LOSS 0.6215976178646088 G LOSS: 1.1240447759628296\n",
            "EPOCH: 0 D LOSS 0.5358270555734634 G LOSS: 0.9944645166397095\n",
            "EPOCH: 0 D LOSS 0.6459852159023285 G LOSS: 1.5582858324050903\n",
            "EPOCH: 0 D LOSS 0.604455977678299 G LOSS: 1.024357795715332\n",
            "EPOCH: 0 D LOSS 0.5858135521411896 G LOSS: 1.0203144550323486\n",
            "EPOCH: 0 D LOSS 0.4388246238231659 G LOSS: 1.152972936630249\n",
            "EPOCH: 0 D LOSS 0.4340922236442566 G LOSS: 1.5733133554458618\n",
            "EPOCH: 0 D LOSS 0.4155677706003189 G LOSS: 1.8119418621063232\n",
            "EPOCH: 0 D LOSS 0.6541751623153687 G LOSS: 1.5825104713439941\n",
            "EPOCH: 0 D LOSS 0.6517685651779175 G LOSS: 1.5603822469711304\n",
            "EPOCH: 0 D LOSS 0.720644623041153 G LOSS: 1.3291606903076172\n",
            "EPOCH: 0 D LOSS 0.5557595193386078 G LOSS: 1.5746597051620483\n",
            "EPOCH: 0 D LOSS 0.43656953051686287 G LOSS: 1.7006369829177856\n",
            "EPOCH: 0 D LOSS 0.1591939628124237 G LOSS: 1.3388032913208008\n",
            "EPOCH: 0 D LOSS 0.6231816858053207 G LOSS: 2.2396254539489746\n",
            "EPOCH: 0 D LOSS 0.46236490458250046 G LOSS: 2.6363744735717773\n",
            "EPOCH: 0 D LOSS 0.8484899699687958 G LOSS: 1.1583952903747559\n",
            "EPOCH: 0 D LOSS 0.46892300620675087 G LOSS: 0.839026927947998\n",
            "EPOCH: 0 D LOSS 0.4552450031042099 G LOSS: 1.1834115982055664\n",
            "EPOCH: 0 D LOSS 0.36597001552581787 G LOSS: 1.393673300743103\n",
            "EPOCH: 0 D LOSS 0.559957966208458 G LOSS: 1.6183969974517822\n",
            "EPOCH: 0 D LOSS 0.5784273445606232 G LOSS: 0.8455537557601929\n",
            "EPOCH: 0 D LOSS 0.43902453780174255 G LOSS: 1.0658727884292603\n",
            "EPOCH: 0 D LOSS 0.18369559198617935 G LOSS: 1.160549521446228\n",
            "EPOCH: 0 D LOSS 0.42752428352832794 G LOSS: 1.456763744354248\n",
            "EPOCH: 0 D LOSS 0.4872852861881256 G LOSS: 1.5519917011260986\n",
            "EPOCH: 0 D LOSS 0.5861119031906128 G LOSS: 1.3621118068695068\n",
            "EPOCH: 0 D LOSS 0.6295687928795815 G LOSS: 1.0393654108047485\n",
            "EPOCH: 0 D LOSS 0.5573680698871613 G LOSS: 1.1563878059387207\n",
            "EPOCH: 0 D LOSS 0.534327894449234 G LOSS: 0.9219467639923096\n",
            "EPOCH: 0 D LOSS 0.6709838211536407 G LOSS: 1.2559661865234375\n",
            "EPOCH: 0 D LOSS 0.5740877389907837 G LOSS: 1.7512714862823486\n",
            "EPOCH: 0 D LOSS 0.49225011467933655 G LOSS: 1.4943896532058716\n",
            "EPOCH: 0 D LOSS 0.7011485993862152 G LOSS: 1.3460580110549927\n",
            "EPOCH: 0 D LOSS 0.5813679993152618 G LOSS: 1.3974473476409912\n",
            "EPOCH: 0 D LOSS 0.46143245697021484 G LOSS: 1.4548561573028564\n",
            "EPOCH: 0 D LOSS 0.571300208568573 G LOSS: 1.5785175561904907\n",
            "EPOCH: 0 D LOSS 0.572607547044754 G LOSS: 1.5670199394226074\n",
            "EPOCH: 0 D LOSS 0.3650256022810936 G LOSS: 1.252660870552063\n",
            "EPOCH: 0 D LOSS 0.5067192316055298 G LOSS: 1.5431395769119263\n",
            "EPOCH: 0 D LOSS 0.3505351096391678 G LOSS: 1.7525174617767334\n",
            "EPOCH: 0 D LOSS 0.48472920060157776 G LOSS: 0.9689469337463379\n",
            "EPOCH: 0 D LOSS 0.5605980604887009 G LOSS: 1.1576180458068848\n",
            "EPOCH: 0 D LOSS 0.38244294188916683 G LOSS: 1.0474348068237305\n",
            "EPOCH: 0 D LOSS 0.3910984769463539 G LOSS: 1.1182441711425781\n",
            "EPOCH: 0 D LOSS 0.3851015865802765 G LOSS: 1.437465786933899\n",
            "EPOCH: 0 D LOSS 0.18458443880081177 G LOSS: 1.2449727058410645\n",
            "EPOCH: 0 D LOSS 0.47041289508342743 G LOSS: 1.2794957160949707\n",
            "EPOCH: 0 D LOSS 0.31214896216988564 G LOSS: 1.2381073236465454\n",
            "EPOCH: 0 D LOSS 0.4623123034834862 G LOSS: 1.4553543329238892\n",
            "EPOCH: 0 D LOSS 0.4129173830151558 G LOSS: 1.008523941040039\n",
            "EPOCH: 0 D LOSS 0.5490028262138367 G LOSS: 1.0679693222045898\n",
            "EPOCH: 0 D LOSS 0.48796577006578445 G LOSS: 1.1755423545837402\n",
            "EPOCH: 0 D LOSS 0.687709778547287 G LOSS: 1.2889535427093506\n",
            "EPOCH: 0 D LOSS 0.6356470286846161 G LOSS: 1.848039150238037\n",
            "EPOCH: 0 D LOSS 0.7240885198116302 G LOSS: 1.859951376914978\n",
            "EPOCH: 0 D LOSS 0.4099654406309128 G LOSS: 1.2918777465820312\n",
            "EPOCH: 0 D LOSS 0.5529953986406326 G LOSS: 1.157976508140564\n",
            "EPOCH: 0 D LOSS 0.5820901095867157 G LOSS: 1.450478196144104\n",
            "EPOCH: 0 D LOSS 0.6152561902999878 G LOSS: 1.699240803718567\n",
            "EPOCH: 0 D LOSS 0.7232714295387268 G LOSS: 1.0477622747421265\n",
            "EPOCH: 0 D LOSS 0.7864119410514832 G LOSS: 0.7940428853034973\n",
            "EPOCH: 0 D LOSS 0.6252253651618958 G LOSS: 1.3512992858886719\n",
            "EPOCH: 0 D LOSS 0.5514363646507263 G LOSS: 1.2214974164962769\n",
            "EPOCH: 0 D LOSS 0.5613114833831787 G LOSS: 1.1938248872756958\n",
            "EPOCH: 0 D LOSS 0.5497182011604309 G LOSS: 1.087814450263977\n",
            "EPOCH: 0 D LOSS 0.48791414871811867 G LOSS: 1.32917058467865\n",
            "EPOCH: 0 D LOSS 0.3906077668070793 G LOSS: 1.193108320236206\n",
            "EPOCH: 0 D LOSS 0.5240083038806915 G LOSS: 1.3553056716918945\n",
            "EPOCH: 0 D LOSS 0.38652152102440596 G LOSS: 0.9099353551864624\n",
            "EPOCH: 0 D LOSS 0.4934062920510769 G LOSS: 1.4048857688903809\n",
            "EPOCH: 0 D LOSS 0.4842439591884613 G LOSS: 1.7704436779022217\n",
            "EPOCH: 0 D LOSS 0.499805212020874 G LOSS: 1.5409538745880127\n",
            "EPOCH: 0 D LOSS 0.5395107567310333 G LOSS: 0.9724606871604919\n",
            "EPOCH: 0 D LOSS 0.5848245173692703 G LOSS: 1.370222806930542\n",
            "EPOCH: 0 D LOSS 0.4494936168193817 G LOSS: 1.6624157428741455\n",
            "EPOCH: 0 D LOSS 0.5768783688545227 G LOSS: 1.3459032773971558\n",
            "EPOCH: 0 D LOSS 0.4856991618871689 G LOSS: 1.251380205154419\n",
            "EPOCH: 0 D LOSS 0.46739092469215393 G LOSS: 1.5859535932540894\n",
            "EPOCH: 0 D LOSS 0.5902776420116425 G LOSS: 1.4481407403945923\n",
            "EPOCH: 0 D LOSS 0.6164933443069458 G LOSS: 1.5571753978729248\n",
            "EPOCH: 0 D LOSS 0.6172081232070923 G LOSS: 1.5352998971939087\n",
            "EPOCH: 0 D LOSS 0.6259826421737671 G LOSS: 1.1766817569732666\n",
            "EPOCH: 0 D LOSS 0.5678337588906288 G LOSS: 1.3735268115997314\n",
            "EPOCH: 0 D LOSS 0.32558467984199524 G LOSS: 2.020202875137329\n",
            "EPOCH: 0 D LOSS 0.368713341653347 G LOSS: 1.631732702255249\n",
            "EPOCH: 0 D LOSS 0.621787041425705 G LOSS: 1.6985479593276978\n",
            "EPOCH: 0 D LOSS 0.5742378830909729 G LOSS: 1.8226816654205322\n",
            "EPOCH: 0 D LOSS 0.7620030045509338 G LOSS: 1.2596983909606934\n",
            "EPOCH: 0 D LOSS 0.5629233196377754 G LOSS: 1.0197038650512695\n",
            "EPOCH: 0 D LOSS 0.4152532983571291 G LOSS: 1.121622920036316\n",
            "EPOCH: 0 D LOSS 0.535068616271019 G LOSS: 1.3257392644882202\n",
            "EPOCH: 0 D LOSS 0.5690939426422119 G LOSS: 1.5809080600738525\n",
            "EPOCH: 0 D LOSS 0.5578777343034744 G LOSS: 1.632330298423767\n",
            "EPOCH: 0 D LOSS 0.7214884161949158 G LOSS: 1.2329556941986084\n",
            "EPOCH: 0 D LOSS 0.5778405666351318 G LOSS: 1.3836169242858887\n",
            "EPOCH: 0 D LOSS 0.5105327218770981 G LOSS: 1.659196376800537\n",
            "EPOCH: 0 D LOSS 0.5457304418087006 G LOSS: 1.212369441986084\n",
            "EPOCH: 0 D LOSS 0.5394753590226173 G LOSS: 1.4924170970916748\n",
            "EPOCH: 0 D LOSS 0.33690235018730164 G LOSS: 1.6917750835418701\n",
            "EPOCH: 0 D LOSS 0.486187219619751 G LOSS: 1.0914011001586914\n",
            "EPOCH: 0 D LOSS 0.6595636904239655 G LOSS: 1.4484212398529053\n",
            "EPOCH: 0 D LOSS 0.46240904927253723 G LOSS: 1.2822585105895996\n",
            "EPOCH: 0 D LOSS 0.48352730460464954 G LOSS: 1.1132419109344482\n",
            "EPOCH: 0 D LOSS 0.517161101102829 G LOSS: 1.2091655731201172\n",
            "EPOCH: 0 D LOSS 0.4345949776470661 G LOSS: 1.0230621099472046\n",
            "EPOCH: 0 D LOSS 0.6293476521968842 G LOSS: 1.725169062614441\n",
            "EPOCH: 0 D LOSS 0.49045485258102417 G LOSS: 1.3324624300003052\n",
            "EPOCH: 0 D LOSS 0.5766263902187347 G LOSS: 1.5003798007965088\n",
            "EPOCH: 0 D LOSS 0.4995793402194977 G LOSS: 1.2048776149749756\n",
            "EPOCH: 0 D LOSS 0.5855339169502258 G LOSS: 1.34660804271698\n",
            "EPOCH: 0 D LOSS 0.43385012447834015 G LOSS: 1.1085370779037476\n",
            "EPOCH: 0 D LOSS 0.4868798106908798 G LOSS: 1.55989408493042\n",
            "EPOCH: 0 D LOSS 0.39693617075681686 G LOSS: 1.2995091676712036\n",
            "EPOCH: 0 D LOSS 0.538087859749794 G LOSS: 1.7827589511871338\n",
            "EPOCH: 0 D LOSS 0.31579381227493286 G LOSS: 1.577261209487915\n",
            "EPOCH: 0 D LOSS 0.4181254804134369 G LOSS: 1.1434097290039062\n",
            "EPOCH: 0 D LOSS 0.8022024631500244 G LOSS: 1.323096752166748\n",
            "EPOCH: 0 D LOSS 0.6514992117881775 G LOSS: 1.3012526035308838\n",
            "EPOCH: 0 D LOSS 0.6692260205745697 G LOSS: 1.2847150564193726\n",
            "EPOCH: 0 D LOSS 0.6531937718391418 G LOSS: 1.2253882884979248\n",
            "EPOCH: 0 D LOSS 0.6786967515945435 G LOSS: 1.308937430381775\n",
            "EPOCH: 0 D LOSS 0.4418001025915146 G LOSS: 1.2665714025497437\n",
            "EPOCH: 0 D LOSS 0.48546458780765533 G LOSS: 1.5832924842834473\n",
            "EPOCH: 0 D LOSS 0.2524055391550064 G LOSS: 1.521318793296814\n",
            "EPOCH: 0 D LOSS 0.3711453452706337 G LOSS: 1.621922254562378\n",
            "EPOCH: 0 D LOSS 0.46696075797080994 G LOSS: 1.3724331855773926\n",
            "EPOCH: 0 D LOSS 0.5211912095546722 G LOSS: 2.10756516456604\n",
            "EPOCH: 0 D LOSS 0.7273746430873871 G LOSS: 1.1936371326446533\n",
            "EPOCH: 0 D LOSS 0.6830432415008545 G LOSS: 1.4202779531478882\n",
            "EPOCH: 0 D LOSS 0.6044136136770248 G LOSS: 1.6047332286834717\n",
            "EPOCH: 0 D LOSS 0.7592008113861084 G LOSS: 1.065382480621338\n",
            "EPOCH: 0 D LOSS 0.6637097895145416 G LOSS: 1.2085458040237427\n",
            "EPOCH: 0 D LOSS 0.331479050219059 G LOSS: 1.2382222414016724\n",
            "EPOCH: 0 D LOSS 0.426197350025177 G LOSS: 1.4633933305740356\n",
            "EPOCH: 0 D LOSS 0.67424476146698 G LOSS: 1.5424860715866089\n",
            "EPOCH: 0 D LOSS 0.6510371565818787 G LOSS: 0.872753381729126\n",
            "EPOCH: 0 D LOSS 0.6115462053567171 G LOSS: 1.147890567779541\n",
            "EPOCH: 0 D LOSS 0.38356244564056396 G LOSS: 1.158743977546692\n",
            "EPOCH: 0 D LOSS 0.5968300700187683 G LOSS: 1.521454095840454\n",
            "EPOCH: 0 D LOSS 0.5128396153450012 G LOSS: 1.387527585029602\n",
            "EPOCH: 0 D LOSS 0.6031683087348938 G LOSS: 1.2494332790374756\n",
            "EPOCH: 0 D LOSS 0.5620219707489014 G LOSS: 1.439785122871399\n",
            "EPOCH: 0 D LOSS 0.4682915210723877 G LOSS: 1.2951654195785522\n",
            "EPOCH: 0 D LOSS 0.45910537242889404 G LOSS: 1.4951046705245972\n",
            "EPOCH: 0 D LOSS 0.45114681124687195 G LOSS: 1.5654687881469727\n",
            "EPOCH: 0 D LOSS 0.42349444329738617 G LOSS: 1.4899173974990845\n",
            "EPOCH: 0 D LOSS 0.5413424968719482 G LOSS: 1.7093329429626465\n",
            "EPOCH: 0 D LOSS 0.5776296257972717 G LOSS: 1.4219753742218018\n",
            "EPOCH: 0 D LOSS 0.5851350277662277 G LOSS: 1.1842694282531738\n",
            "EPOCH: 0 D LOSS 0.6975422203540802 G LOSS: 1.3815762996673584\n",
            "EPOCH: 0 D LOSS 0.6073904037475586 G LOSS: 1.721242904663086\n",
            "EPOCH: 0 D LOSS 0.6964587569236755 G LOSS: 1.0690901279449463\n",
            "EPOCH: 0 D LOSS 0.5757217109203339 G LOSS: 1.2746750116348267\n",
            "EPOCH: 0 D LOSS 0.37418264895677567 G LOSS: 1.5919500589370728\n",
            "EPOCH: 0 D LOSS 0.4127310514450073 G LOSS: 1.454040765762329\n",
            "EPOCH: 0 D LOSS 0.3988153338432312 G LOSS: 1.7015130519866943\n",
            "EPOCH: 0 D LOSS 0.4215955138206482 G LOSS: 1.4254162311553955\n",
            "EPOCH: 0 D LOSS 0.5884296484291553 G LOSS: 1.9365087747573853\n",
            "EPOCH: 0 D LOSS 0.5117270648479462 G LOSS: 2.0421247482299805\n",
            "EPOCH: 0 D LOSS 0.5764736980199814 G LOSS: 1.5650699138641357\n",
            "EPOCH: 0 D LOSS 0.660722553730011 G LOSS: 1.0005379915237427\n",
            "EPOCH: 0 D LOSS 0.6924600899219513 G LOSS: 1.1668323278427124\n",
            "EPOCH: 0 D LOSS 0.6491492390632629 G LOSS: 0.9905478358268738\n",
            "EPOCH: 0 D LOSS 0.4637545086443424 G LOSS: 1.204761028289795\n",
            "EPOCH: 0 D LOSS 0.4724012091755867 G LOSS: 1.872070074081421\n",
            "EPOCH: 0 D LOSS 0.461702823638916 G LOSS: 1.1767915487289429\n",
            "EPOCH: 0 D LOSS 0.6486414670944214 G LOSS: 1.5984094142913818\n",
            "EPOCH: 0 D LOSS 0.6427417695522308 G LOSS: 1.2433794736862183\n",
            "EPOCH: 0 D LOSS 0.8313657194375992 G LOSS: 1.1853899955749512\n",
            "EPOCH: 0 D LOSS 0.5689966678619385 G LOSS: 1.5116828680038452\n",
            "EPOCH: 0 D LOSS 0.6652057766914368 G LOSS: 0.9245120286941528\n",
            "EPOCH: 0 D LOSS 0.7155463993549347 G LOSS: 1.0137284994125366\n",
            "EPOCH: 0 D LOSS 0.6445310711860657 G LOSS: 1.0988261699676514\n",
            "EPOCH: 0 D LOSS 0.6489925384521484 G LOSS: 1.1411995887756348\n",
            "EPOCH: 0 D LOSS 0.5491657555103302 G LOSS: 1.439433217048645\n",
            "EPOCH: 0 D LOSS 0.5460614860057831 G LOSS: 1.067832350730896\n",
            "EPOCH: 0 D LOSS 0.535719633102417 G LOSS: 1.4479687213897705\n",
            "EPOCH: 0 D LOSS 0.38662485778331757 G LOSS: 1.5520007610321045\n",
            "EPOCH: 0 D LOSS 0.5536213964223862 G LOSS: 1.3633289337158203\n",
            "EPOCH: 0 D LOSS 0.5719795823097229 G LOSS: 1.1163747310638428\n",
            "EPOCH: 0 D LOSS 0.6814905405044556 G LOSS: 1.4203321933746338\n",
            "EPOCH: 0 D LOSS 0.7529980540275574 G LOSS: 0.7465791702270508\n",
            "EPOCH: 0 D LOSS 0.7014145851135254 G LOSS: 1.2140233516693115\n",
            "EPOCH: 0 D LOSS 0.5364462435245514 G LOSS: 1.4067120552062988\n",
            "EPOCH: 0 D LOSS 0.592132031917572 G LOSS: 1.1235027313232422\n",
            "EPOCH: 0 D LOSS 0.6433599591255188 G LOSS: 1.1395565271377563\n",
            "EPOCH: 0 D LOSS 0.5470572113990784 G LOSS: 1.1411409378051758\n",
            "EPOCH: 0 D LOSS 0.48862364888191223 G LOSS: 1.4824154376983643\n",
            "EPOCH: 0 D LOSS 0.461441233754158 G LOSS: 1.2562799453735352\n",
            "EPOCH: 0 D LOSS 0.5138457119464874 G LOSS: 1.372700572013855\n",
            "EPOCH: 0 D LOSS 0.5255288928747177 G LOSS: 1.851912260055542\n",
            "EPOCH: 0 D LOSS 0.6904744207859039 G LOSS: 1.1669574975967407\n",
            "EPOCH: 0 D LOSS 0.7145739197731018 G LOSS: 0.9512406587600708\n",
            "EPOCH: 0 D LOSS 0.6220194846391678 G LOSS: 1.108572244644165\n",
            "EPOCH: 0 D LOSS 0.6472452878952026 G LOSS: 1.030583381652832\n",
            "EPOCH: 0 D LOSS 0.6536433100700378 G LOSS: 0.8571300506591797\n",
            "EPOCH: 0 D LOSS 0.5266293734312057 G LOSS: 1.0377830266952515\n",
            "EPOCH: 0 D LOSS 0.5424545109272003 G LOSS: 1.51645827293396\n",
            "EPOCH: 0 D LOSS 0.5041865706443787 G LOSS: 1.4722864627838135\n",
            "EPOCH: 0 D LOSS 0.5447286367416382 G LOSS: 1.3575997352600098\n",
            "EPOCH: 0 D LOSS 0.5447227954864502 G LOSS: 0.9687081575393677\n",
            "EPOCH: 0 D LOSS 0.5036902660503983 G LOSS: 1.157312273979187\n",
            "EPOCH: 0 D LOSS 0.343983793631196 G LOSS: 1.2853872776031494\n",
            "EPOCH: 0 D LOSS 0.38508396688848734 G LOSS: 1.5168559551239014\n",
            "EPOCH: 0 D LOSS 0.3704189984127879 G LOSS: 1.2192479372024536\n",
            "EPOCH: 0 D LOSS 0.5105732828378677 G LOSS: 1.3073426485061646\n",
            "EPOCH: 0 D LOSS 0.5293151289224625 G LOSS: 1.4788751602172852\n",
            "EPOCH: 0 D LOSS 0.6582372784614563 G LOSS: 1.5876014232635498\n",
            "EPOCH: 0 D LOSS 0.6988467276096344 G LOSS: 1.30814528465271\n",
            "EPOCH: 0 D LOSS 0.6222890317440033 G LOSS: 1.2694387435913086\n",
            "EPOCH: 0 D LOSS 0.5712222456932068 G LOSS: 1.3373639583587646\n",
            "EPOCH: 0 D LOSS 0.5529642105102539 G LOSS: 1.4311621189117432\n",
            "EPOCH: 0 D LOSS 0.5872150361537933 G LOSS: 1.5211166143417358\n",
            "EPOCH: 0 D LOSS 0.6980509012937546 G LOSS: 1.644526720046997\n",
            "EPOCH: 0 D LOSS 0.5773349106311798 G LOSS: 1.783067226409912\n",
            "EPOCH: 0 D LOSS 0.5390357375144958 G LOSS: 1.4827239513397217\n",
            "EPOCH: 0 D LOSS 0.574298769235611 G LOSS: 1.564739465713501\n",
            "EPOCH: 0 D LOSS 0.5506523251533508 G LOSS: 1.8589909076690674\n",
            "EPOCH: 0 D LOSS 0.5498016178607941 G LOSS: 1.2605767250061035\n",
            "EPOCH: 0 D LOSS 0.5983197689056396 G LOSS: 1.1856828927993774\n",
            "EPOCH: 0 D LOSS 0.526598796248436 G LOSS: 1.2857983112335205\n",
            "EPOCH: 0 D LOSS 0.6353884935379028 G LOSS: 1.299764633178711\n",
            "EPOCH: 0 D LOSS 0.6240754723548889 G LOSS: 1.5492583513259888\n",
            "EPOCH: 0 D LOSS 0.6498682498931885 G LOSS: 1.4831347465515137\n",
            "EPOCH: 0 D LOSS 0.6469343602657318 G LOSS: 1.407122254371643\n",
            "EPOCH: 0 D LOSS 0.543078288435936 G LOSS: 1.494071125984192\n",
            "EPOCH: 0 D LOSS 0.5104946196079254 G LOSS: 1.2033803462982178\n",
            "EPOCH: 0 D LOSS 0.5069424510002136 G LOSS: 1.6186096668243408\n",
            "EPOCH: 0 D LOSS 0.43760979175567627 G LOSS: 1.687453031539917\n",
            "EPOCH: 0 D LOSS 0.5281854122877121 G LOSS: 1.0075392723083496\n",
            "EPOCH: 0 D LOSS 0.6267188489437103 G LOSS: 1.4714839458465576\n",
            "EPOCH: 0 D LOSS 0.4048118591308594 G LOSS: 1.4063512086868286\n",
            "EPOCH: 0 D LOSS 0.3395124636590481 G LOSS: 1.177466869354248\n",
            "EPOCH: 0 D LOSS 0.6423847377300262 G LOSS: 1.4728851318359375\n",
            "EPOCH: 0 D LOSS 0.5883969366550446 G LOSS: 1.3837895393371582\n",
            "EPOCH: 0 D LOSS 0.6333118975162506 G LOSS: 1.281904697418213\n",
            "EPOCH: 0 D LOSS 0.47551801800727844 G LOSS: 1.7900670766830444\n",
            "EPOCH: 0 D LOSS 0.514195054769516 G LOSS: 1.6258251667022705\n",
            "EPOCH: 0 D LOSS 0.5536796897649765 G LOSS: 1.4929051399230957\n",
            "EPOCH: 0 D LOSS 0.5368390381336212 G LOSS: 1.8629292249679565\n",
            "EPOCH: 0 D LOSS 0.5661430060863495 G LOSS: 1.439182996749878\n",
            "EPOCH: 0 D LOSS 0.8192316591739655 G LOSS: 1.5639996528625488\n",
            "EPOCH: 0 D LOSS 0.4951135516166687 G LOSS: 1.4605777263641357\n",
            "EPOCH: 0 D LOSS 0.6145991086959839 G LOSS: 1.2480210065841675\n",
            "EPOCH: 0 D LOSS 0.6074422597885132 G LOSS: 1.0414025783538818\n",
            "EPOCH: 0 D LOSS 0.6251732110977173 G LOSS: 1.261013150215149\n",
            "EPOCH: 0 D LOSS 0.49013982713222504 G LOSS: 1.6775915622711182\n",
            "EPOCH: 0 D LOSS 0.6344133019447327 G LOSS: 1.391253113746643\n",
            "EPOCH: 0 D LOSS 0.6551199555397034 G LOSS: 1.3359596729278564\n",
            "EPOCH: 0 D LOSS 0.5660362839698792 G LOSS: 1.571263074874878\n",
            "EPOCH: 0 D LOSS 0.6672963798046112 G LOSS: 1.142979383468628\n",
            "EPOCH: 0 D LOSS 0.6415224075317383 G LOSS: 1.363168716430664\n",
            "EPOCH: 0 D LOSS 0.5731815099716187 G LOSS: 1.285152792930603\n",
            "EPOCH: 0 D LOSS 0.5292554199695587 G LOSS: 0.9194295406341553\n",
            "EPOCH: 0 D LOSS 0.6730595529079437 G LOSS: 1.511366605758667\n",
            "EPOCH: 0 D LOSS 0.5150312781333923 G LOSS: 1.072484016418457\n",
            "EPOCH: 0 D LOSS 0.4034816846251488 G LOSS: 0.9861036539077759\n",
            "EPOCH: 0 D LOSS 0.38449255377054214 G LOSS: 1.5950878858566284\n",
            "EPOCH: 0 D LOSS 0.4597827345132828 G LOSS: 1.6904516220092773\n",
            "EPOCH: 0 D LOSS 0.4619048237800598 G LOSS: 1.707660436630249\n",
            "EPOCH: 0 D LOSS 0.4617178440093994 G LOSS: 1.3378554582595825\n",
            "EPOCH: 0 D LOSS 0.3816559985280037 G LOSS: 1.5308058261871338\n",
            "EPOCH: 0 D LOSS 0.3011964187026024 G LOSS: 1.7603024244308472\n",
            "EPOCH: 0 D LOSS 0.4021272361278534 G LOSS: 1.146430492401123\n",
            "EPOCH: 0 D LOSS 0.6854683607816696 G LOSS: 1.8827540874481201\n",
            "EPOCH: 0 D LOSS 0.526953786611557 G LOSS: 2.193312168121338\n",
            "EPOCH: 0 D LOSS 0.6844448745250702 G LOSS: 1.6051928997039795\n",
            "EPOCH: 0 D LOSS 0.6665450930595398 G LOSS: 1.1264925003051758\n",
            "EPOCH: 0 D LOSS 0.5380563177168369 G LOSS: 1.4667118787765503\n",
            "EPOCH: 0 D LOSS 0.3434026166796684 G LOSS: 2.0101327896118164\n",
            "EPOCH: 0 D LOSS 0.22832563519477844 G LOSS: 1.6630470752716064\n",
            "EPOCH: 0 D LOSS 0.38679400086402893 G LOSS: 1.919520378112793\n",
            "EPOCH: 0 D LOSS 0.4799095690250397 G LOSS: 1.9592936038970947\n",
            "EPOCH: 0 D LOSS 0.563453197479248 G LOSS: 1.121456503868103\n",
            "EPOCH: 0 D LOSS 0.6694612503051758 G LOSS: 1.582761526107788\n",
            "EPOCH: 0 D LOSS 0.5100816488265991 G LOSS: 1.530612587928772\n",
            "EPOCH: 0 D LOSS 0.5787373781204224 G LOSS: 1.2895359992980957\n",
            "EPOCH: 0 D LOSS 0.5553415864706039 G LOSS: 1.5226402282714844\n",
            "EPOCH: 0 D LOSS 0.38431692123413086 G LOSS: 1.5237581729888916\n",
            "EPOCH: 0 D LOSS 0.431389257311821 G LOSS: 1.5399343967437744\n",
            "EPOCH: 0 D LOSS 0.39881758391857147 G LOSS: 1.541399598121643\n",
            "EPOCH: 0 D LOSS 0.2739802300930023 G LOSS: 1.4771333932876587\n",
            "EPOCH: 0 D LOSS 0.4826858937740326 G LOSS: 1.9185044765472412\n",
            "EPOCH: 0 D LOSS 0.506396010518074 G LOSS: 1.43196439743042\n",
            "EPOCH: 0 D LOSS 0.751127153635025 G LOSS: 1.6298890113830566\n",
            "EPOCH: 0 D LOSS 0.6665945053100586 G LOSS: 1.4823496341705322\n",
            "EPOCH: 0 D LOSS 0.6381411850452423 G LOSS: 1.5529600381851196\n",
            "EPOCH: 0 D LOSS 0.564434140920639 G LOSS: 1.585888385772705\n",
            "EPOCH: 0 D LOSS 0.4510110467672348 G LOSS: 1.6160881519317627\n",
            "EPOCH: 0 D LOSS 0.33437611162662506 G LOSS: 1.8354613780975342\n",
            "EPOCH: 0 D LOSS 0.3014029860496521 G LOSS: 1.8011524677276611\n",
            "EPOCH: 0 D LOSS 0.7993886768817902 G LOSS: 1.9035277366638184\n",
            "EPOCH: 0 D LOSS 0.6564167141914368 G LOSS: 1.318532109260559\n",
            "EPOCH: 0 D LOSS 0.5776481628417969 G LOSS: 1.063009262084961\n",
            "EPOCH: 0 D LOSS 0.6327073872089386 G LOSS: 1.5564520359039307\n",
            "EPOCH: 0 D LOSS 0.6042603254318237 G LOSS: 1.4158415794372559\n",
            "EPOCH: 0 D LOSS 0.5983926057815552 G LOSS: 1.4503014087677002\n",
            "EPOCH: 0 D LOSS 0.5925229489803314 G LOSS: 1.3935267925262451\n",
            "EPOCH: 0 D LOSS 0.6088517606258392 G LOSS: 1.5952467918395996\n",
            "EPOCH: 0 D LOSS 0.6864819526672363 G LOSS: 1.438740611076355\n",
            "EPOCH: 0 D LOSS 0.5054590702056885 G LOSS: 1.2739896774291992\n",
            "EPOCH: 0 D LOSS 0.5998952984809875 G LOSS: 1.4481786489486694\n",
            "EPOCH: 0 D LOSS 0.40609124302864075 G LOSS: 1.5719022750854492\n",
            "EPOCH: 0 D LOSS 0.6671575903892517 G LOSS: 1.5241296291351318\n",
            "EPOCH: 0 D LOSS 0.5058068633079529 G LOSS: 1.4651601314544678\n",
            "EPOCH: 0 D LOSS 0.44434112310409546 G LOSS: 1.397209882736206\n",
            "EPOCH: 0 D LOSS 0.5868257135152817 G LOSS: 1.6732732057571411\n",
            "EPOCH: 0 D LOSS 0.4991210103034973 G LOSS: 1.4463586807250977\n",
            "EPOCH: 0 D LOSS 0.40281984210014343 G LOSS: 1.6116943359375\n",
            "EPOCH: 0 D LOSS 0.4628080874681473 G LOSS: 1.5813885927200317\n",
            "EPOCH: 0 D LOSS 0.3883276991546154 G LOSS: 1.3951659202575684\n",
            "EPOCH: 0 D LOSS 0.5504215359687805 G LOSS: 1.969029426574707\n",
            "EPOCH: 0 D LOSS 0.4041178971529007 G LOSS: 1.402105689048767\n",
            "EPOCH: 0 D LOSS 0.40228842524811625 G LOSS: 1.8006705045700073\n",
            "EPOCH: 0 D LOSS 0.6110226213932037 G LOSS: 2.1621057987213135\n",
            "EPOCH: 0 D LOSS 0.5898943543434143 G LOSS: 1.1498667001724243\n",
            "EPOCH: 0 D LOSS 0.627821296453476 G LOSS: 1.3818914890289307\n",
            "EPOCH: 0 D LOSS 0.5782055854797363 G LOSS: 1.50985848903656\n",
            "EPOCH: 0 D LOSS 0.49305908381938934 G LOSS: 1.379068374633789\n",
            "EPOCH: 0 D LOSS 0.5635807514190674 G LOSS: 1.1428494453430176\n",
            "EPOCH: 0 D LOSS 0.6449430882930756 G LOSS: 1.3253345489501953\n",
            "EPOCH: 0 D LOSS 0.5452721565961838 G LOSS: 1.086504340171814\n",
            "EPOCH: 0 D LOSS 0.5639171749353409 G LOSS: 1.1271464824676514\n",
            "EPOCH: 0 D LOSS 0.4163614995777607 G LOSS: 1.3920962810516357\n",
            "EPOCH: 0 D LOSS 0.527185931801796 G LOSS: 1.998418927192688\n",
            "EPOCH: 0 D LOSS 0.6593586206436157 G LOSS: 1.6096848249435425\n",
            "EPOCH: 0 D LOSS 0.6498795449733734 G LOSS: 1.307581901550293\n",
            "EPOCH: 0 D LOSS 0.6016954481601715 G LOSS: 1.4559906721115112\n",
            "EPOCH: 0 D LOSS 0.6212702393531799 G LOSS: 1.2964363098144531\n",
            "EPOCH: 0 D LOSS 0.5469541549682617 G LOSS: 1.1258955001831055\n",
            "EPOCH: 0 D LOSS 0.5136894881725311 G LOSS: 1.39110267162323\n",
            "EPOCH: 0 D LOSS 0.6308284401893616 G LOSS: 1.6916062831878662\n",
            "EPOCH: 0 D LOSS 0.5350210666656494 G LOSS: 1.5788943767547607\n",
            "EPOCH: 0 D LOSS 0.55268794298172 G LOSS: 1.8665294647216797\n",
            "EPOCH: 0 D LOSS 0.6617006361484528 G LOSS: 1.528380274772644\n",
            "EPOCH: 0 D LOSS 0.7055781185626984 G LOSS: 1.1847312450408936\n",
            "EPOCH: 0 D LOSS 0.3589993864297867 G LOSS: 1.2995840311050415\n",
            "EPOCH: 0 D LOSS 0.6395975053310394 G LOSS: 1.3426451683044434\n",
            "EPOCH: 0 D LOSS 0.5434350669384003 G LOSS: 1.5678960084915161\n",
            "EPOCH: 0 D LOSS 0.5075945258140564 G LOSS: 1.720860242843628\n",
            "EPOCH: 0 D LOSS 0.5384120047092438 G LOSS: 1.6230775117874146\n",
            "EPOCH: 0 D LOSS 0.5385296642780304 G LOSS: 1.421636939048767\n",
            "EPOCH: 0 D LOSS 0.5168927907943726 G LOSS: 1.4925687313079834\n",
            "EPOCH: 0 D LOSS 0.47020426392555237 G LOSS: 1.630901575088501\n",
            "EPOCH: 0 D LOSS 0.600161075592041 G LOSS: 1.6644197702407837\n",
            "EPOCH: 0 D LOSS 0.6136411428451538 G LOSS: 1.2418068647384644\n",
            "EPOCH: 0 D LOSS 0.6223959773778915 G LOSS: 1.318450927734375\n",
            "EPOCH: 0 D LOSS 0.6173338294029236 G LOSS: 1.1265432834625244\n",
            "EPOCH: 0 D LOSS 0.533063679933548 G LOSS: 1.382997751235962\n",
            "EPOCH: 0 D LOSS 0.5252202898263931 G LOSS: 1.2818886041641235\n",
            "EPOCH: 0 D LOSS 0.42378613352775574 G LOSS: 1.6734421253204346\n",
            "EPOCH: 0 D LOSS 0.5831805169582367 G LOSS: 1.5678610801696777\n",
            "EPOCH: 0 D LOSS 0.506211593747139 G LOSS: 1.2097268104553223\n",
            "EPOCH: 0 D LOSS 0.5166907608509064 G LOSS: 1.4888968467712402\n",
            "EPOCH: 0 D LOSS 0.3426925465464592 G LOSS: 1.1281728744506836\n",
            "EPOCH: 0 D LOSS 0.6215618848800659 G LOSS: 1.8270398378372192\n",
            "EPOCH: 0 D LOSS 0.5357842445373535 G LOSS: 1.5719451904296875\n",
            "EPOCH: 0 D LOSS 0.5899984836578369 G LOSS: 1.3274575471878052\n",
            "EPOCH: 0 D LOSS 0.5406123548746109 G LOSS: 1.351311445236206\n",
            "EPOCH: 0 D LOSS 0.4017039090394974 G LOSS: 1.8356664180755615\n",
            "EPOCH: 0 D LOSS 0.3978867009282112 G LOSS: 1.7636159658432007\n",
            "EPOCH: 0 D LOSS 0.6158291101455688 G LOSS: 1.6586298942565918\n",
            "EPOCH: 0 D LOSS 0.6182277202606201 G LOSS: 1.6136188507080078\n",
            "EPOCH: 0 D LOSS 0.7420359551906586 G LOSS: 1.0451700687408447\n",
            "EPOCH: 0 D LOSS 0.4967917501926422 G LOSS: 1.2174381017684937\n",
            "EPOCH: 0 D LOSS 0.5246568918228149 G LOSS: 1.3148858547210693\n",
            "EPOCH: 0 D LOSS 0.5118715614080429 G LOSS: 1.5641131401062012\n",
            "EPOCH: 0 D LOSS 0.5187888741493225 G LOSS: 1.5838102102279663\n",
            "EPOCH: 0 D LOSS 0.4377409815788269 G LOSS: 1.820467472076416\n",
            "EPOCH: 0 D LOSS 0.4384240359067917 G LOSS: 1.6275211572647095\n",
            "EPOCH: 0 D LOSS 0.5920256078243256 G LOSS: 2.1053757667541504\n",
            "EPOCH: 0 D LOSS 0.6611882448196411 G LOSS: 1.2104933261871338\n",
            "EPOCH: 0 D LOSS 0.7088583111763 G LOSS: 1.4699043035507202\n",
            "EPOCH: 0 D LOSS 0.707595944404602 G LOSS: 1.645867943763733\n",
            "EPOCH: 0 D LOSS 0.5869701206684113 G LOSS: 1.2922098636627197\n",
            "EPOCH: 0 D LOSS 0.46674200519919395 G LOSS: 1.3950867652893066\n",
            "EPOCH: 0 D LOSS 0.4558108188211918 G LOSS: 2.3111138343811035\n",
            "EPOCH: 0 D LOSS 0.6679652631282806 G LOSS: 2.0818564891815186\n",
            "EPOCH: 0 D LOSS 0.5815500915050507 G LOSS: 1.583390712738037\n",
            "EPOCH: 0 D LOSS 0.5458408296108246 G LOSS: 1.0414483547210693\n",
            "EPOCH: 0 D LOSS 0.6927839517593384 G LOSS: 1.5970325469970703\n",
            "EPOCH: 0 D LOSS 0.60175621509552 G LOSS: 1.1068944931030273\n",
            "EPOCH: 0 D LOSS 0.6193788945674896 G LOSS: 1.3561896085739136\n",
            "EPOCH: 0 D LOSS 0.575963169336319 G LOSS: 1.2472842931747437\n",
            "EPOCH: 0 D LOSS 0.5943342000246048 G LOSS: 1.2616132497787476\n",
            "EPOCH: 0 D LOSS 0.5736062824726105 G LOSS: 1.3499292135238647\n",
            "EPOCH: 0 D LOSS 0.7045741677284241 G LOSS: 1.6283280849456787\n",
            "EPOCH: 0 D LOSS 0.4759868085384369 G LOSS: 1.143505334854126\n",
            "EPOCH: 0 D LOSS 0.5846012234687805 G LOSS: 1.6028969287872314\n",
            "EPOCH: 0 D LOSS 0.4849187284708023 G LOSS: 1.5926141738891602\n",
            "EPOCH: 0 D LOSS 0.6384714245796204 G LOSS: 1.4366238117218018\n",
            "EPOCH: 0 D LOSS 0.5671592205762863 G LOSS: 1.4066821336746216\n",
            "EPOCH: 0 D LOSS 0.6378829181194305 G LOSS: 1.7474271059036255\n",
            "EPOCH: 0 D LOSS 0.5153649896383286 G LOSS: 1.6497611999511719\n",
            "EPOCH: 0 D LOSS 0.5191569030284882 G LOSS: 1.1084911823272705\n",
            "EPOCH: 0 D LOSS 0.4712022766470909 G LOSS: 1.6697633266448975\n",
            "EPOCH: 0 D LOSS 0.2381289042532444 G LOSS: 1.624333143234253\n",
            "EPOCH: 0 D LOSS 0.45451285783201456 G LOSS: 2.4634313583374023\n",
            "EPOCH: 0 D LOSS 0.46391406655311584 G LOSS: 2.8199334144592285\n",
            "EPOCH: 0 D LOSS 0.6997021734714508 G LOSS: 1.369261622428894\n",
            "EPOCH: 0 D LOSS 0.6632961481809616 G LOSS: 1.24175226688385\n",
            "EPOCH: 0 D LOSS 0.4306938946247101 G LOSS: 1.4089653491973877\n",
            "EPOCH: 0 D LOSS 0.41569337248802185 G LOSS: 1.1954965591430664\n",
            "EPOCH: 0 D LOSS 0.5784773156046867 G LOSS: 1.6845860481262207\n",
            "EPOCH: 0 D LOSS 0.46745383739471436 G LOSS: 1.7697606086730957\n",
            "EPOCH: 0 D LOSS 0.4837353676557541 G LOSS: 1.403581142425537\n",
            "EPOCH: 0 D LOSS 0.5602737963199615 G LOSS: 1.6409564018249512\n",
            "EPOCH: 0 D LOSS 0.4102523848414421 G LOSS: 1.2181013822555542\n",
            "EPOCH: 0 D LOSS 0.5733602941036224 G LOSS: 1.456355094909668\n",
            "EPOCH: 0 D LOSS 0.45839598774909973 G LOSS: 1.6261759996414185\n",
            "EPOCH: 0 D LOSS 0.5564216524362564 G LOSS: 1.8202146291732788\n",
            "EPOCH: 0 D LOSS 0.5628633201122284 G LOSS: 1.641510009765625\n",
            "EPOCH: 0 D LOSS 0.6277050375938416 G LOSS: 1.6900806427001953\n",
            "EPOCH: 0 D LOSS 0.5687165707349777 G LOSS: 1.9055849313735962\n",
            "EPOCH: 0 D LOSS 0.4487183690071106 G LOSS: 1.4923077821731567\n",
            "EPOCH: 0 D LOSS 0.5076375007629395 G LOSS: 1.6498010158538818\n",
            "EPOCH: 0 D LOSS 0.65971839427948 G LOSS: 1.7651822566986084\n",
            "EPOCH: 0 D LOSS 0.7696731686592102 G LOSS: 1.4577995538711548\n",
            "EPOCH: 0 D LOSS 0.28603535890579224 G LOSS: 1.7441928386688232\n",
            "EPOCH: 0 D LOSS 0.27113266102969646 G LOSS: 1.301499605178833\n",
            "EPOCH: 0 D LOSS 0.6091756224632263 G LOSS: 1.7993669509887695\n",
            "EPOCH: 0 D LOSS 0.6679883003234863 G LOSS: 1.9006547927856445\n",
            "EPOCH: 0 D LOSS 0.5726010203361511 G LOSS: 1.6047964096069336\n",
            "EPOCH: 0 D LOSS 0.6361881196498871 G LOSS: 1.4572476148605347\n",
            "EPOCH: 0 D LOSS 0.6696254014968872 G LOSS: 1.2884180545806885\n",
            "EPOCH: 0 D LOSS 0.89323690533638 G LOSS: 1.6595536470413208\n",
            "EPOCH: 0 D LOSS 0.5206237882375717 G LOSS: 1.8265023231506348\n",
            "EPOCH: 0 D LOSS 0.5280303359031677 G LOSS: 1.7448210716247559\n",
            "EPOCH: 0 D LOSS 0.5934504568576813 G LOSS: 1.1952275037765503\n",
            "EPOCH: 0 D LOSS 0.5730542093515396 G LOSS: 1.087557315826416\n",
            "EPOCH: 0 D LOSS 0.6831530630588531 G LOSS: 1.3430402278900146\n",
            "EPOCH: 0 D LOSS 0.6325222849845886 G LOSS: 1.2210826873779297\n",
            "EPOCH: 0 D LOSS 0.5997038185596466 G LOSS: 1.3137269020080566\n",
            "EPOCH: 0 D LOSS 0.578823134303093 G LOSS: 1.1480510234832764\n",
            "EPOCH: 0 D LOSS 0.5122186243534088 G LOSS: 1.342482328414917\n",
            "EPOCH: 0 D LOSS 0.5529652833938599 G LOSS: 1.648468017578125\n",
            "EPOCH: 0 D LOSS 0.5233348608016968 G LOSS: 1.2997610569000244\n",
            "EPOCH: 0 D LOSS 0.5100675225257874 G LOSS: 1.255200982093811\n",
            "EPOCH: 0 D LOSS 0.574527233839035 G LOSS: 1.223874807357788\n",
            "EPOCH: 0 D LOSS 0.6002540588378906 G LOSS: 1.5878574848175049\n",
            "EPOCH: 0 D LOSS 0.542981281876564 G LOSS: 1.3144652843475342\n",
            "EPOCH: 0 D LOSS 0.47846610099077225 G LOSS: 0.8923203945159912\n",
            "EPOCH: 0 D LOSS 0.4537019394338131 G LOSS: 1.3522958755493164\n",
            "EPOCH: 0 D LOSS 0.506610244512558 G LOSS: 2.011737823486328\n",
            "EPOCH: 0 D LOSS 0.6725126504898071 G LOSS: 1.314103364944458\n",
            "EPOCH: 0 D LOSS 0.5958269834518433 G LOSS: 1.0895421504974365\n",
            "EPOCH: 0 D LOSS 0.3950980082154274 G LOSS: 1.0868035554885864\n",
            "EPOCH: 0 D LOSS 0.6036959886550903 G LOSS: 1.5742790699005127\n",
            "EPOCH: 0 D LOSS 0.5571481138467789 G LOSS: 1.5936315059661865\n",
            "EPOCH: 0 D LOSS 0.6196801662445068 G LOSS: 0.9359481334686279\n",
            "EPOCH: 0 D LOSS 0.7123566269874573 G LOSS: 1.434594988822937\n",
            "EPOCH: 0 D LOSS 0.6432147324085236 G LOSS: 1.5319709777832031\n",
            "EPOCH: 0 D LOSS 0.6550567150115967 G LOSS: 1.0180068016052246\n",
            "EPOCH: 0 D LOSS 0.6730480790138245 G LOSS: 1.2188565731048584\n",
            "EPOCH: 0 D LOSS 0.5664882659912109 G LOSS: 1.3592358827590942\n",
            "EPOCH: 0 D LOSS 0.5621704459190369 G LOSS: 1.2435072660446167\n",
            "EPOCH: 0 D LOSS 0.5388662815093994 G LOSS: 1.4552669525146484\n",
            "EPOCH: 0 D LOSS 0.6208409368991852 G LOSS: 1.7179884910583496\n",
            "EPOCH: 0 D LOSS 0.6110431849956512 G LOSS: 1.1285544633865356\n",
            "EPOCH: 0 D LOSS 0.6106176972389221 G LOSS: 1.2745754718780518\n",
            "EPOCH: 0 D LOSS 0.47983697056770325 G LOSS: 1.0995290279388428\n",
            "EPOCH: 0 D LOSS 0.4222491383552551 G LOSS: 1.382844090461731\n",
            "EPOCH: 0 D LOSS 0.3668615520000458 G LOSS: 1.8053065538406372\n",
            "EPOCH: 0 D LOSS 0.36374951899051666 G LOSS: 1.1940325498580933\n",
            "EPOCH: 0 D LOSS 0.5774350464344025 G LOSS: 1.730541706085205\n",
            "EPOCH: 0 D LOSS 0.4776381552219391 G LOSS: 1.6934311389923096\n",
            "EPOCH: 0 D LOSS 0.5385824143886566 G LOSS: 1.074066162109375\n",
            "EPOCH: 0 D LOSS 0.6675755679607391 G LOSS: 1.6218960285186768\n",
            "EPOCH: 0 D LOSS 0.6207284033298492 G LOSS: 1.6425578594207764\n",
            "EPOCH: 0 D LOSS 0.7267178595066071 G LOSS: 0.8233314752578735\n",
            "EPOCH: 0 D LOSS 0.6359413266181946 G LOSS: 0.8729771375656128\n",
            "EPOCH: 0 D LOSS 0.5522398948669434 G LOSS: 1.1180126667022705\n",
            "EPOCH: 0 D LOSS 0.5800554752349854 G LOSS: 1.4164971113204956\n",
            "EPOCH: 0 D LOSS 0.6254113614559174 G LOSS: 1.3800055980682373\n",
            "EPOCH: 0 D LOSS 0.5232724249362946 G LOSS: 1.1142418384552002\n",
            "EPOCH: 0 D LOSS 0.38249480724334717 G LOSS: 1.1749211549758911\n",
            "EPOCH: 0 D LOSS 0.26881028711795807 G LOSS: 1.166275143623352\n",
            "EPOCH: 0 D LOSS 0.19064545631408691 G LOSS: 1.2675279378890991\n",
            "EPOCH: 0 D LOSS 0.123599573969841 G LOSS: 1.4421344995498657\n",
            "EPOCH: 0 D LOSS 0.11062824726104736 G LOSS: 1.2256391048431396\n",
            "EPOCH: 0 D LOSS 0.5442132353782654 G LOSS: 1.58492910861969\n",
            "EPOCH: 0 D LOSS 0.40687353909015656 G LOSS: 1.923424243927002\n",
            "EPOCH: 0 D LOSS 0.3662949800491333 G LOSS: 1.6649079322814941\n",
            "EPOCH: 0 D LOSS 0.38398173451423645 G LOSS: 1.830974817276001\n",
            "EPOCH: 0 D LOSS 0.20560653693974018 G LOSS: 1.7935411930084229\n",
            "EPOCH: 0 D LOSS 0.380960114300251 G LOSS: 1.7618775367736816\n",
            "EPOCH: 0 D LOSS 0.3496982157230377 G LOSS: 2.031466245651245\n",
            "EPOCH: 0 D LOSS 0.46144992113113403 G LOSS: 1.5226151943206787\n",
            "EPOCH: 0 D LOSS 0.5471776723861694 G LOSS: 1.331221103668213\n",
            "EPOCH: 0 D LOSS 0.5837616175413132 G LOSS: 2.2443737983703613\n",
            "EPOCH: 0 D LOSS 0.7632154226303101 G LOSS: 1.1054306030273438\n",
            "EPOCH: 0 D LOSS 0.6745341718196869 G LOSS: 1.5285578966140747\n",
            "EPOCH: 0 D LOSS 0.6384902000427246 G LOSS: 1.4370445013046265\n",
            "EPOCH: 0 D LOSS 0.6855317950248718 G LOSS: 1.6632919311523438\n",
            "EPOCH: 0 D LOSS 0.5446762144565582 G LOSS: 2.0961387157440186\n",
            "EPOCH: 0 D LOSS 0.6645517945289612 G LOSS: 1.2876665592193604\n",
            "EPOCH: 0 D LOSS 0.7028324007987976 G LOSS: 1.722618818283081\n",
            "EPOCH: 0 D LOSS 0.612228661775589 G LOSS: 1.3766772747039795\n",
            "EPOCH: 0 D LOSS 0.6611323058605194 G LOSS: 1.42939293384552\n",
            "EPOCH: 0 D LOSS 0.487297922372818 G LOSS: 1.2311725616455078\n",
            "EPOCH: 0 D LOSS 0.5998939275741577 G LOSS: 1.885960578918457\n",
            "EPOCH: 0 D LOSS 0.5593780875205994 G LOSS: 1.6793768405914307\n",
            "EPOCH: 0 D LOSS 0.6005554497241974 G LOSS: 1.4906716346740723\n",
            "EPOCH: 0 D LOSS 0.5950421094894409 G LOSS: 1.6844079494476318\n",
            "EPOCH: 0 D LOSS 0.5905671715736389 G LOSS: 1.6923333406448364\n",
            "EPOCH: 0 D LOSS 0.6318076848983765 G LOSS: 1.6633776426315308\n",
            "EPOCH: 0 D LOSS 0.6653604656457901 G LOSS: 1.7925246953964233\n",
            "EPOCH: 0 D LOSS 0.24953974038362503 G LOSS: 1.5264211893081665\n",
            "EPOCH: 0 D LOSS 0.5370423346757889 G LOSS: 2.039443016052246\n",
            "EPOCH: 0 D LOSS 0.4539014846086502 G LOSS: 1.4204049110412598\n",
            "EPOCH: 0 D LOSS 0.6975706517696381 G LOSS: 1.9772522449493408\n",
            "EPOCH: 0 D LOSS 0.4161973297595978 G LOSS: 1.5774414539337158\n",
            "EPOCH: 0 D LOSS 0.5099133253097534 G LOSS: 1.625741958618164\n",
            "EPOCH: 0 D LOSS 0.4578152596950531 G LOSS: 1.882572054862976\n",
            "EPOCH: 0 D LOSS 0.46241791546344757 G LOSS: 1.8729345798492432\n",
            "EPOCH: 0 D LOSS 0.6461704671382904 G LOSS: 1.332794189453125\n",
            "EPOCH: 0 D LOSS 0.8050964772701263 G LOSS: 1.607801914215088\n",
            "EPOCH: 0 D LOSS 0.5266413241624832 G LOSS: 1.7119907140731812\n",
            "EPOCH: 0 D LOSS 0.6499534249305725 G LOSS: 1.3205763101577759\n",
            "EPOCH: 0 D LOSS 0.6591796875 G LOSS: 1.199404239654541\n",
            "EPOCH: 0 D LOSS 0.557994544506073 G LOSS: 1.3421826362609863\n",
            "EPOCH: 0 D LOSS 0.6551007628440857 G LOSS: 1.445534110069275\n",
            "EPOCH: 0 D LOSS 0.6399096548557281 G LOSS: 1.4601922035217285\n",
            "EPOCH: 0 D LOSS 0.47763967514038086 G LOSS: 1.4289242029190063\n",
            "EPOCH: 0 D LOSS 0.5452124122530222 G LOSS: 1.7394189834594727\n",
            "EPOCH: 0 D LOSS 0.30046824365854263 G LOSS: 1.6500606536865234\n",
            "EPOCH: 0 D LOSS 0.3247296568006277 G LOSS: 1.5382722616195679\n",
            "EPOCH: 0 D LOSS 0.6744044423103333 G LOSS: 1.7364954948425293\n",
            "EPOCH: 0 D LOSS 0.5815314501523972 G LOSS: 1.5741369724273682\n",
            "EPOCH: 0 D LOSS 0.5754973888397217 G LOSS: 1.162635326385498\n",
            "EPOCH: 0 D LOSS 0.5282404944300652 G LOSS: 1.5551140308380127\n",
            "EPOCH: 0 D LOSS 0.4708084166049957 G LOSS: 1.4651821851730347\n",
            "EPOCH: 0 D LOSS 0.4890626519918442 G LOSS: 0.9325448870658875\n",
            "EPOCH: 0 D LOSS 0.45854925364255905 G LOSS: 1.182990312576294\n",
            "EPOCH: 0 D LOSS 0.5295599400997162 G LOSS: 1.5594778060913086\n",
            "EPOCH: 0 D LOSS 0.5242561250925064 G LOSS: 1.4454295635223389\n",
            "EPOCH: 0 D LOSS 0.4949788749217987 G LOSS: 1.189164400100708\n",
            "EPOCH: 0 D LOSS 0.598496675491333 G LOSS: 1.4707515239715576\n",
            "EPOCH: 0 D LOSS 0.5453745871782303 G LOSS: 1.2984603643417358\n",
            "EPOCH: 0 D LOSS 0.5381289720535278 G LOSS: 1.2104616165161133\n",
            "EPOCH: 0 D LOSS 0.5219417065382004 G LOSS: 1.370242953300476\n",
            "EPOCH: 0 D LOSS 0.44018682837486267 G LOSS: 1.4536769390106201\n",
            "EPOCH: 0 D LOSS 0.49378395080566406 G LOSS: 1.3886271715164185\n",
            "EPOCH: 0 D LOSS 0.6842615008354187 G LOSS: 1.5250093936920166\n",
            "EPOCH: 0 D LOSS 0.6435728073120117 G LOSS: 1.528123378753662\n",
            "EPOCH: 0 D LOSS 0.717292994260788 G LOSS: 1.579720377922058\n",
            "EPOCH: 0 D LOSS 0.5236735641956329 G LOSS: 2.0984272956848145\n",
            "EPOCH: 0 D LOSS 0.6215980052947998 G LOSS: 1.522408127784729\n",
            "EPOCH: 0 D LOSS 0.5352205336093903 G LOSS: 1.681955337524414\n",
            "EPOCH: 0 D LOSS 0.47263820469379425 G LOSS: 1.6340160369873047\n",
            "EPOCH: 0 D LOSS 0.6297873258590698 G LOSS: 1.3652801513671875\n",
            "EPOCH: 0 D LOSS 0.6370801031589508 G LOSS: 1.7448153495788574\n",
            "EPOCH: 0 D LOSS 0.5529202222824097 G LOSS: 1.5053894519805908\n",
            "EPOCH: 0 D LOSS 0.5669079422950745 G LOSS: 1.6208205223083496\n",
            "EPOCH: 0 D LOSS 0.5257194936275482 G LOSS: 1.5769373178482056\n",
            "EPOCH: 0 D LOSS 0.5496324896812439 G LOSS: 1.5627760887145996\n",
            "EPOCH: 0 D LOSS 0.5800124108791351 G LOSS: 1.1385632753372192\n",
            "EPOCH: 0 D LOSS 0.6975488066673279 G LOSS: 1.6836308240890503\n",
            "EPOCH: 0 D LOSS 0.7413781583309174 G LOSS: 1.4799216985702515\n",
            "EPOCH: 0 D LOSS 0.5091577917337418 G LOSS: 1.4691216945648193\n",
            "EPOCH: 0 D LOSS 0.5378836095333099 G LOSS: 1.4028226137161255\n",
            "EPOCH: 0 D LOSS 0.5341775119304657 G LOSS: 1.307100534439087\n",
            "EPOCH: 0 D LOSS 0.5389994978904724 G LOSS: 1.2942476272583008\n",
            "EPOCH: 0 D LOSS 0.5623455047607422 G LOSS: 1.6374359130859375\n",
            "EPOCH: 0 D LOSS 0.6870360225439072 G LOSS: 1.3153467178344727\n",
            "EPOCH: 0 D LOSS 0.6495623886585236 G LOSS: 1.4416451454162598\n",
            "EPOCH: 0 D LOSS 0.568517804145813 G LOSS: 1.5907411575317383\n",
            "EPOCH: 0 D LOSS 0.5719062387943268 G LOSS: 1.711709976196289\n",
            "EPOCH: 0 D LOSS 0.5839153379201889 G LOSS: 1.0030964612960815\n",
            "EPOCH: 0 D LOSS 0.6612379460129887 G LOSS: 1.6103988885879517\n",
            "EPOCH: 0 D LOSS 0.41614241898059845 G LOSS: 1.9267325401306152\n",
            "EPOCH: 0 D LOSS 0.4823504090309143 G LOSS: 1.4512654542922974\n",
            "EPOCH: 0 D LOSS 0.4825277328491211 G LOSS: 1.55674147605896\n",
            "EPOCH: 0 D LOSS 0.5412584543228149 G LOSS: 1.642190933227539\n",
            "EPOCH: 0 D LOSS 0.5985921323299408 G LOSS: 1.2923047542572021\n",
            "EPOCH: 0 D LOSS 0.5732753574848175 G LOSS: 0.9505866765975952\n",
            "EPOCH: 0 D LOSS 0.6749295592308044 G LOSS: 1.3620953559875488\n",
            "EPOCH: 0 D LOSS 0.6138901710510254 G LOSS: 1.104950189590454\n",
            "EPOCH: 0 D LOSS 0.6924106478691101 G LOSS: 1.4145770072937012\n",
            "EPOCH: 0 D LOSS 0.5056172609329224 G LOSS: 1.4206427335739136\n",
            "EPOCH: 0 D LOSS 0.4129476845264435 G LOSS: 1.6522246599197388\n",
            "EPOCH: 0 D LOSS 0.3563009947538376 G LOSS: 1.4408924579620361\n",
            "EPOCH: 0 D LOSS 0.7094513475894928 G LOSS: 1.6406117677688599\n",
            "EPOCH: 0 D LOSS 0.541354313492775 G LOSS: 1.8251118659973145\n",
            "EPOCH: 1 D LOSS 0.528313398361206 G LOSS: 1.5378812551498413\n",
            "EPOCH: 1 D LOSS 0.5958146154880524 G LOSS: 1.7392290830612183\n",
            "EPOCH: 1 D LOSS 0.5756459534168243 G LOSS: 1.8644987344741821\n",
            "EPOCH: 1 D LOSS 0.60222327709198 G LOSS: 1.5870864391326904\n",
            "EPOCH: 1 D LOSS 0.5499673038721085 G LOSS: 1.3157708644866943\n",
            "EPOCH: 1 D LOSS 0.6120724380016327 G LOSS: 1.8117636442184448\n",
            "EPOCH: 1 D LOSS 0.6050785183906555 G LOSS: 1.6732406616210938\n",
            "EPOCH: 1 D LOSS 0.6057519614696503 G LOSS: 1.7970584630966187\n",
            "EPOCH: 1 D LOSS 0.6579077690839767 G LOSS: 1.537447214126587\n",
            "EPOCH: 1 D LOSS 0.6975418627262115 G LOSS: 1.3036584854125977\n",
            "EPOCH: 1 D LOSS 0.714544266462326 G LOSS: 1.483588695526123\n",
            "EPOCH: 1 D LOSS 0.7345742285251617 G LOSS: 1.1331803798675537\n",
            "EPOCH: 1 D LOSS 0.6115871369838715 G LOSS: 1.2984447479248047\n",
            "EPOCH: 1 D LOSS 0.27519460394978523 G LOSS: 1.4473679065704346\n",
            "EPOCH: 1 D LOSS 0.2041676938533783 G LOSS: 1.2908120155334473\n",
            "EPOCH: 1 D LOSS 0.42882274836301804 G LOSS: 1.622916340827942\n",
            "EPOCH: 1 D LOSS 0.5657137483358383 G LOSS: 1.9139155149459839\n",
            "EPOCH: 1 D LOSS 0.5401716828346252 G LOSS: 1.2017371654510498\n",
            "EPOCH: 1 D LOSS 0.51491279900074 G LOSS: 1.6000711917877197\n",
            "EPOCH: 1 D LOSS 0.33452147245407104 G LOSS: 1.7505621910095215\n",
            "EPOCH: 1 D LOSS 0.6456299126148224 G LOSS: 1.6340436935424805\n",
            "EPOCH: 1 D LOSS 0.5460002422332764 G LOSS: 0.9076170921325684\n",
            "EPOCH: 1 D LOSS 0.5366155356168747 G LOSS: 1.329289436340332\n",
            "EPOCH: 1 D LOSS 0.5220672488212585 G LOSS: 1.4539783000946045\n",
            "EPOCH: 1 D LOSS 0.5505605936050415 G LOSS: 1.6073817014694214\n",
            "EPOCH: 1 D LOSS 0.6583836674690247 G LOSS: 1.0554544925689697\n",
            "EPOCH: 1 D LOSS 0.6113167107105255 G LOSS: 1.5843905210494995\n",
            "EPOCH: 1 D LOSS 0.5117105394601822 G LOSS: 1.260656714439392\n",
            "EPOCH: 1 D LOSS 0.40568190068006516 G LOSS: 0.8841751217842102\n",
            "EPOCH: 1 D LOSS 0.34515364468097687 G LOSS: 1.4711458683013916\n",
            "EPOCH: 1 D LOSS 0.3749518245458603 G LOSS: 1.2551133632659912\n",
            "EPOCH: 1 D LOSS 0.7494923174381256 G LOSS: 1.4319874048233032\n",
            "EPOCH: 1 D LOSS 0.5197492390871048 G LOSS: 0.9705262184143066\n",
            "EPOCH: 1 D LOSS 0.6259367913007736 G LOSS: 1.4474389553070068\n",
            "EPOCH: 1 D LOSS 0.5091323703527451 G LOSS: 1.7174935340881348\n",
            "EPOCH: 1 D LOSS 0.5914067029953003 G LOSS: 1.4790358543395996\n",
            "EPOCH: 1 D LOSS 0.51285120844841 G LOSS: 1.1747028827667236\n",
            "EPOCH: 1 D LOSS 0.5035887695848942 G LOSS: 1.5178178548812866\n",
            "EPOCH: 1 D LOSS 0.3528134748339653 G LOSS: 1.319103479385376\n",
            "EPOCH: 1 D LOSS 0.584039494395256 G LOSS: 1.6680097579956055\n",
            "EPOCH: 1 D LOSS 0.32865509390830994 G LOSS: 1.2691535949707031\n",
            "EPOCH: 1 D LOSS 0.4283995572477579 G LOSS: 1.6046487092971802\n",
            "EPOCH: 1 D LOSS 0.4820690453052521 G LOSS: 1.5577747821807861\n",
            "EPOCH: 1 D LOSS 0.5368168652057648 G LOSS: 1.1706273555755615\n",
            "EPOCH: 1 D LOSS 0.5396346151828766 G LOSS: 1.3829779624938965\n",
            "EPOCH: 1 D LOSS 0.5149131119251251 G LOSS: 1.836144208908081\n",
            "EPOCH: 1 D LOSS 0.40742382407188416 G LOSS: 1.646567702293396\n",
            "EPOCH: 1 D LOSS 0.5079841315746307 G LOSS: 1.7759771347045898\n",
            "EPOCH: 1 D LOSS 0.45222946256399155 G LOSS: 1.1439411640167236\n",
            "EPOCH: 1 D LOSS 0.7736252248287201 G LOSS: 1.6171295642852783\n",
            "EPOCH: 1 D LOSS 0.5038668513298035 G LOSS: 1.366314172744751\n",
            "EPOCH: 1 D LOSS 0.6451843678951263 G LOSS: 1.4958570003509521\n",
            "EPOCH: 1 D LOSS 0.5658416748046875 G LOSS: 1.1315486431121826\n",
            "EPOCH: 1 D LOSS 0.5908930748701096 G LOSS: 1.1643950939178467\n",
            "EPOCH: 1 D LOSS 0.5007218420505524 G LOSS: 1.501115322113037\n",
            "EPOCH: 1 D LOSS 0.3922620266675949 G LOSS: 1.722589373588562\n",
            "EPOCH: 1 D LOSS 0.4119684733450413 G LOSS: 1.101797342300415\n",
            "EPOCH: 1 D LOSS 0.4358097091317177 G LOSS: 1.8381905555725098\n",
            "EPOCH: 1 D LOSS 0.17729829251766205 G LOSS: 1.9030848741531372\n",
            "EPOCH: 1 D LOSS 0.5166296362876892 G LOSS: 2.1112937927246094\n",
            "EPOCH: 1 D LOSS 0.5787356346845627 G LOSS: 1.1637728214263916\n",
            "EPOCH: 1 D LOSS 0.7161395847797394 G LOSS: 2.3030638694763184\n",
            "EPOCH: 1 D LOSS 0.7458614110946655 G LOSS: 1.3985271453857422\n",
            "EPOCH: 1 D LOSS 0.6332142353057861 G LOSS: 1.10392427444458\n",
            "EPOCH: 1 D LOSS 0.5150755196809769 G LOSS: 1.1735875606536865\n",
            "EPOCH: 1 D LOSS 0.5783582925796509 G LOSS: 1.5998371839523315\n",
            "EPOCH: 1 D LOSS 0.5393271744251251 G LOSS: 1.42727530002594\n",
            "EPOCH: 1 D LOSS 0.45011935755610466 G LOSS: 1.1821675300598145\n",
            "EPOCH: 1 D LOSS 0.41587328910827637 G LOSS: 1.9642224311828613\n",
            "EPOCH: 1 D LOSS 0.5358896255493164 G LOSS: 2.5557661056518555\n",
            "EPOCH: 1 D LOSS 0.5905547142028809 G LOSS: 1.8893100023269653\n",
            "EPOCH: 1 D LOSS 0.4706341326236725 G LOSS: 1.6615798473358154\n",
            "EPOCH: 1 D LOSS 0.46553535759449005 G LOSS: 1.1876870393753052\n",
            "EPOCH: 1 D LOSS 0.5931463539600372 G LOSS: 1.2442330121994019\n",
            "EPOCH: 1 D LOSS 0.4069838970899582 G LOSS: 1.6560471057891846\n",
            "EPOCH: 1 D LOSS 0.3176435362547636 G LOSS: 1.292862892150879\n",
            "EPOCH: 1 D LOSS 0.5242026746273041 G LOSS: 1.900282382965088\n",
            "EPOCH: 1 D LOSS 0.4321959614753723 G LOSS: 1.6494078636169434\n",
            "EPOCH: 1 D LOSS 0.6529903411865234 G LOSS: 1.4190642833709717\n",
            "EPOCH: 1 D LOSS 0.6963541507720947 G LOSS: 1.3946995735168457\n",
            "EPOCH: 1 D LOSS 0.8155021071434021 G LOSS: 1.4633660316467285\n",
            "EPOCH: 1 D LOSS 0.5240528881549835 G LOSS: 1.8549742698669434\n",
            "EPOCH: 1 D LOSS 0.5657644867897034 G LOSS: 1.675226092338562\n",
            "EPOCH: 1 D LOSS 0.5679602324962616 G LOSS: 1.3832392692565918\n",
            "EPOCH: 1 D LOSS 0.5453486442565918 G LOSS: 1.5747404098510742\n",
            "EPOCH: 1 D LOSS 0.6480488181114197 G LOSS: 1.7792447805404663\n",
            "EPOCH: 1 D LOSS 0.519232988357544 G LOSS: 1.5246495008468628\n",
            "EPOCH: 1 D LOSS 0.45722564309835434 G LOSS: 1.0503660440444946\n",
            "EPOCH: 1 D LOSS 0.5655001401901245 G LOSS: 1.2576488256454468\n",
            "EPOCH: 1 D LOSS 0.392904045060277 G LOSS: 1.167289137840271\n",
            "EPOCH: 1 D LOSS 0.7116691768169403 G LOSS: 1.5414202213287354\n",
            "EPOCH: 1 D LOSS 0.5447070598602295 G LOSS: 1.5458123683929443\n",
            "EPOCH: 1 D LOSS 0.5394850969314575 G LOSS: 1.6956703662872314\n",
            "EPOCH: 1 D LOSS 0.4576815962791443 G LOSS: 1.1505308151245117\n",
            "EPOCH: 1 D LOSS 0.5381375178694725 G LOSS: 1.5869289636611938\n",
            "EPOCH: 1 D LOSS 0.4128500819206238 G LOSS: 1.3710300922393799\n",
            "EPOCH: 1 D LOSS 0.7135417461395264 G LOSS: 1.3340251445770264\n",
            "EPOCH: 1 D LOSS 0.570815920829773 G LOSS: 1.5533127784729004\n",
            "EPOCH: 1 D LOSS 0.501671314239502 G LOSS: 1.1102349758148193\n",
            "EPOCH: 1 D LOSS 0.5573127865791321 G LOSS: 1.3489271402359009\n",
            "EPOCH: 1 D LOSS 0.37842532619833946 G LOSS: 1.243332862854004\n",
            "EPOCH: 1 D LOSS 0.5401825308799744 G LOSS: 1.5209131240844727\n",
            "EPOCH: 1 D LOSS 0.4877307564020157 G LOSS: 2.1812593936920166\n",
            "EPOCH: 1 D LOSS 0.5467430353164673 G LOSS: 1.8086652755737305\n",
            "EPOCH: 1 D LOSS 0.6306599378585815 G LOSS: 1.1445132493972778\n",
            "EPOCH: 1 D LOSS 0.44099096953868866 G LOSS: 1.3290568590164185\n",
            "EPOCH: 1 D LOSS 0.6411972492933273 G LOSS: 1.7698564529418945\n",
            "EPOCH: 1 D LOSS 0.5231606960296631 G LOSS: 0.9859752058982849\n",
            "EPOCH: 1 D LOSS 0.7318218052387238 G LOSS: 1.7432572841644287\n",
            "EPOCH: 1 D LOSS 0.5295785814523697 G LOSS: 1.3009374141693115\n",
            "EPOCH: 1 D LOSS 0.5452838242053986 G LOSS: 1.6784374713897705\n",
            "EPOCH: 1 D LOSS 0.4909546673297882 G LOSS: 1.9366769790649414\n",
            "EPOCH: 1 D LOSS 0.4828084707260132 G LOSS: 1.9195090532302856\n",
            "EPOCH: 1 D LOSS 0.5704430937767029 G LOSS: 1.5055073499679565\n",
            "EPOCH: 1 D LOSS 0.4394470453262329 G LOSS: 1.6739490032196045\n",
            "EPOCH: 1 D LOSS 0.5275891721248627 G LOSS: 1.4875004291534424\n",
            "EPOCH: 1 D LOSS 0.5209738612174988 G LOSS: 1.6205127239227295\n",
            "EPOCH: 1 D LOSS 0.4654366374015808 G LOSS: 1.854190707206726\n",
            "EPOCH: 1 D LOSS 0.535121351480484 G LOSS: 1.2739406824111938\n",
            "EPOCH: 1 D LOSS 0.6431335508823395 G LOSS: 1.55855131149292\n",
            "EPOCH: 1 D LOSS 0.47537483274936676 G LOSS: 1.4957427978515625\n",
            "EPOCH: 1 D LOSS 0.5709675252437592 G LOSS: 1.4982343912124634\n",
            "EPOCH: 1 D LOSS 0.624342679977417 G LOSS: 1.452650547027588\n",
            "EPOCH: 1 D LOSS 0.5503947138786316 G LOSS: 1.479430079460144\n",
            "EPOCH: 1 D LOSS 0.5741167366504669 G LOSS: 2.030306339263916\n",
            "EPOCH: 1 D LOSS 0.6240518689155579 G LOSS: 1.5289318561553955\n",
            "EPOCH: 1 D LOSS 0.616706907749176 G LOSS: 1.6493500471115112\n",
            "EPOCH: 1 D LOSS 0.5017403364181519 G LOSS: 1.645942211151123\n",
            "EPOCH: 1 D LOSS 0.5454251170158386 G LOSS: 1.2016799449920654\n",
            "EPOCH: 1 D LOSS 0.5130370557308197 G LOSS: 1.520634412765503\n",
            "EPOCH: 1 D LOSS 0.33250216767191887 G LOSS: 1.5279850959777832\n",
            "EPOCH: 1 D LOSS 0.39232806116342545 G LOSS: 1.7908586263656616\n",
            "EPOCH: 1 D LOSS 0.3630213588476181 G LOSS: 1.9355319738388062\n",
            "EPOCH: 1 D LOSS 0.5839020609855652 G LOSS: 1.6267741918563843\n",
            "EPOCH: 1 D LOSS 0.6503093838691711 G LOSS: 1.5527772903442383\n",
            "EPOCH: 1 D LOSS 0.6727418899536133 G LOSS: 1.353224754333496\n",
            "EPOCH: 1 D LOSS 0.6435688138008118 G LOSS: 1.2661796808242798\n",
            "EPOCH: 1 D LOSS 0.5426852703094482 G LOSS: 1.570136308670044\n",
            "EPOCH: 1 D LOSS 0.5687469840049744 G LOSS: 1.521141529083252\n",
            "EPOCH: 1 D LOSS 0.6142727434635162 G LOSS: 1.172082543373108\n",
            "EPOCH: 1 D LOSS 0.6410606801509857 G LOSS: 1.543978214263916\n",
            "EPOCH: 1 D LOSS 0.6320824921131134 G LOSS: 1.5260246992111206\n",
            "EPOCH: 1 D LOSS 0.3535350733436644 G LOSS: 1.2795498371124268\n",
            "EPOCH: 1 D LOSS 0.5727711766958237 G LOSS: 2.0120606422424316\n",
            "EPOCH: 1 D LOSS 0.2935228869318962 G LOSS: 2.5296506881713867\n",
            "EPOCH: 1 D LOSS 0.49775776267051697 G LOSS: 1.6979032754898071\n",
            "EPOCH: 1 D LOSS 0.30015282426029444 G LOSS: 1.3477647304534912\n",
            "EPOCH: 1 D LOSS 0.1618828922510147 G LOSS: 1.7925933599472046\n",
            "EPOCH: 1 D LOSS 0.11956758797168732 G LOSS: 1.3521066904067993\n",
            "EPOCH: 1 D LOSS 0.5613422393798828 G LOSS: 1.8678085803985596\n",
            "EPOCH: 1 D LOSS 0.5026160925626755 G LOSS: 1.733860731124878\n",
            "EPOCH: 1 D LOSS 0.559938371181488 G LOSS: 1.4070677757263184\n",
            "EPOCH: 1 D LOSS 0.5660885274410248 G LOSS: 1.5118637084960938\n",
            "EPOCH: 1 D LOSS 0.4897385835647583 G LOSS: 1.4739277362823486\n",
            "EPOCH: 1 D LOSS 0.5964378714561462 G LOSS: 1.3539745807647705\n",
            "EPOCH: 1 D LOSS 0.5305432826280594 G LOSS: 1.4896149635314941\n",
            "EPOCH: 1 D LOSS 0.48797914385795593 G LOSS: 1.6809217929840088\n",
            "EPOCH: 1 D LOSS 0.37585850805044174 G LOSS: 1.6070568561553955\n",
            "EPOCH: 1 D LOSS 0.3410903438925743 G LOSS: 1.844102382659912\n",
            "EPOCH: 1 D LOSS 0.21492134034633636 G LOSS: 2.298290491104126\n",
            "EPOCH: 1 D LOSS 0.2055506408214569 G LOSS: 1.518645167350769\n",
            "EPOCH: 1 D LOSS 0.9221800565719604 G LOSS: 1.9425479173660278\n",
            "EPOCH: 1 D LOSS 0.6211408823728561 G LOSS: 1.1253483295440674\n",
            "EPOCH: 1 D LOSS 0.5373368561267853 G LOSS: 1.4033875465393066\n",
            "EPOCH: 1 D LOSS 0.5913998335599899 G LOSS: 1.7035372257232666\n",
            "EPOCH: 1 D LOSS 0.5679026395082474 G LOSS: 1.0244426727294922\n",
            "EPOCH: 1 D LOSS 0.7352156341075897 G LOSS: 1.4750816822052002\n",
            "EPOCH: 1 D LOSS 0.6076025068759918 G LOSS: 1.6982543468475342\n",
            "EPOCH: 1 D LOSS 0.5933334827423096 G LOSS: 1.2461941242218018\n",
            "EPOCH: 1 D LOSS 0.49402332305908203 G LOSS: 1.863356590270996\n",
            "EPOCH: 1 D LOSS 0.4421936720609665 G LOSS: 1.866980791091919\n",
            "EPOCH: 1 D LOSS 0.4790313243865967 G LOSS: 1.894770622253418\n",
            "EPOCH: 1 D LOSS 0.4045926630496979 G LOSS: 1.877924919128418\n",
            "EPOCH: 1 D LOSS 0.5002799928188324 G LOSS: 1.2962223291397095\n",
            "EPOCH: 1 D LOSS 0.6435706615447998 G LOSS: 2.02703857421875\n",
            "EPOCH: 1 D LOSS 0.7047212719917297 G LOSS: 2.344865322113037\n",
            "EPOCH: 1 D LOSS 0.4874095320701599 G LOSS: 1.4482674598693848\n",
            "EPOCH: 1 D LOSS 0.7188360393047333 G LOSS: 1.3680305480957031\n",
            "EPOCH: 1 D LOSS 0.6394161283969879 G LOSS: 1.7014182806015015\n",
            "EPOCH: 1 D LOSS 0.5451623499393463 G LOSS: 1.469894289970398\n",
            "EPOCH: 1 D LOSS 0.5838984400033951 G LOSS: 1.0047193765640259\n",
            "EPOCH: 1 D LOSS 0.6750306487083435 G LOSS: 1.5146541595458984\n",
            "EPOCH: 1 D LOSS 0.5677588433027267 G LOSS: 1.40682053565979\n",
            "EPOCH: 1 D LOSS 0.577210322022438 G LOSS: 1.3585751056671143\n",
            "EPOCH: 1 D LOSS 0.6468842029571533 G LOSS: 1.5332692861557007\n",
            "EPOCH: 1 D LOSS 0.6628365218639374 G LOSS: 1.7956178188323975\n",
            "EPOCH: 1 D LOSS 0.6219316124916077 G LOSS: 1.1700646877288818\n",
            "EPOCH: 1 D LOSS 0.7807989418506622 G LOSS: 1.7210981845855713\n",
            "EPOCH: 1 D LOSS 0.42733150720596313 G LOSS: 2.122134208679199\n",
            "EPOCH: 1 D LOSS 0.5366297513246536 G LOSS: 1.7863842248916626\n",
            "EPOCH: 1 D LOSS 0.6564360558986664 G LOSS: 1.2889952659606934\n",
            "EPOCH: 1 D LOSS 0.6557817757129669 G LOSS: 1.2650851011276245\n",
            "EPOCH: 1 D LOSS 0.5523262023925781 G LOSS: 1.5261797904968262\n",
            "EPOCH: 1 D LOSS 0.4739028811454773 G LOSS: 2.117948293685913\n",
            "EPOCH: 1 D LOSS 0.637155294418335 G LOSS: 1.0624773502349854\n",
            "EPOCH: 1 D LOSS 0.5751961320638657 G LOSS: 1.5903810262680054\n",
            "EPOCH: 1 D LOSS 0.34923475980758667 G LOSS: 1.6490908861160278\n",
            "EPOCH: 1 D LOSS 0.36984453722834587 G LOSS: 1.2615880966186523\n",
            "EPOCH: 1 D LOSS 0.6325756758451462 G LOSS: 1.755028486251831\n",
            "EPOCH: 1 D LOSS 0.47152942419052124 G LOSS: 1.3818697929382324\n",
            "EPOCH: 1 D LOSS 0.399546907749027 G LOSS: 0.984647274017334\n",
            "EPOCH: 1 D LOSS 0.5984839200973511 G LOSS: 1.3609888553619385\n",
            "EPOCH: 1 D LOSS 0.38565277121961117 G LOSS: 1.3771209716796875\n",
            "EPOCH: 1 D LOSS 0.6397575736045837 G LOSS: 1.5963585376739502\n",
            "EPOCH: 1 D LOSS 0.5532782226800919 G LOSS: 1.7438709735870361\n",
            "EPOCH: 1 D LOSS 0.560856431722641 G LOSS: 1.304349660873413\n",
            "EPOCH: 1 D LOSS 0.6518526375293732 G LOSS: 1.2319697141647339\n",
            "EPOCH: 1 D LOSS 0.6663438975811005 G LOSS: 1.1576629877090454\n",
            "EPOCH: 1 D LOSS 0.6143112778663635 G LOSS: 1.3603322505950928\n",
            "EPOCH: 1 D LOSS 0.623758003115654 G LOSS: 1.5297911167144775\n",
            "EPOCH: 1 D LOSS 0.6356942057609558 G LOSS: 1.0467629432678223\n",
            "EPOCH: 1 D LOSS 0.6131505966186523 G LOSS: 1.5564686059951782\n",
            "EPOCH: 1 D LOSS 0.4920836091041565 G LOSS: 1.975473165512085\n",
            "EPOCH: 1 D LOSS 0.6171940565109253 G LOSS: 1.5697832107543945\n",
            "EPOCH: 1 D LOSS 0.5395621359348297 G LOSS: 1.2770878076553345\n",
            "EPOCH: 1 D LOSS 0.4763649255037308 G LOSS: 1.7681838274002075\n",
            "EPOCH: 1 D LOSS 0.4939165264368057 G LOSS: 1.2482926845550537\n",
            "EPOCH: 1 D LOSS 0.46589805046096444 G LOSS: 1.2539715766906738\n",
            "EPOCH: 1 D LOSS 0.22771847248077393 G LOSS: 1.4564263820648193\n",
            "EPOCH: 1 D LOSS 0.26513421535491943 G LOSS: 1.8503973484039307\n",
            "EPOCH: 1 D LOSS 0.5544657409191132 G LOSS: 1.7609500885009766\n",
            "EPOCH: 1 D LOSS 0.40799680352211 G LOSS: 1.5506454706192017\n",
            "EPOCH: 1 D LOSS 0.4690903425216675 G LOSS: 1.7372413873672485\n",
            "EPOCH: 1 D LOSS 0.41907210648059845 G LOSS: 1.6514958143234253\n",
            "EPOCH: 1 D LOSS 0.5419804453849792 G LOSS: 2.099501609802246\n",
            "EPOCH: 1 D LOSS 0.5256087929010391 G LOSS: 2.2211081981658936\n",
            "EPOCH: 1 D LOSS 0.58922478556633 G LOSS: 1.6463695764541626\n",
            "EPOCH: 1 D LOSS 0.6083287298679352 G LOSS: 1.7763023376464844\n",
            "EPOCH: 1 D LOSS 0.6843980848789215 G LOSS: 1.5152302980422974\n",
            "EPOCH: 1 D LOSS 0.7402346432209015 G LOSS: 1.5033479928970337\n",
            "EPOCH: 1 D LOSS 0.6185466647148132 G LOSS: 1.558598518371582\n",
            "EPOCH: 1 D LOSS 0.6668165326118469 G LOSS: 1.0184755325317383\n",
            "EPOCH: 1 D LOSS 0.7005706429481506 G LOSS: 1.6070473194122314\n",
            "EPOCH: 1 D LOSS 0.6106567978858948 G LOSS: 1.1463298797607422\n",
            "EPOCH: 1 D LOSS 0.6105985641479492 G LOSS: 1.1239975690841675\n",
            "EPOCH: 1 D LOSS 0.38280361518263817 G LOSS: 1.1247310638427734\n",
            "EPOCH: 1 D LOSS 0.35809436440467834 G LOSS: 1.7640173435211182\n",
            "EPOCH: 1 D LOSS 0.18263708986341953 G LOSS: 1.7965967655181885\n",
            "EPOCH: 1 D LOSS 0.2916118651628494 G LOSS: 1.8499608039855957\n",
            "EPOCH: 1 D LOSS 0.2654690518975258 G LOSS: 2.175924777984619\n",
            "EPOCH: 1 D LOSS 0.6109990775585175 G LOSS: 2.015150547027588\n",
            "EPOCH: 1 D LOSS 0.5926958620548248 G LOSS: 2.0880722999572754\n",
            "EPOCH: 1 D LOSS 0.6576791107654572 G LOSS: 1.4284034967422485\n",
            "EPOCH: 1 D LOSS 0.633245050907135 G LOSS: 1.0884652137756348\n",
            "EPOCH: 1 D LOSS 0.5071641132235527 G LOSS: 1.4083075523376465\n",
            "EPOCH: 1 D LOSS 0.38862596452236176 G LOSS: 1.3499476909637451\n",
            "EPOCH: 1 D LOSS 0.4542529955506325 G LOSS: 1.4071860313415527\n",
            "EPOCH: 1 D LOSS 0.48867836594581604 G LOSS: 1.3699405193328857\n",
            "EPOCH: 1 D LOSS 0.5139631628990173 G LOSS: 1.4967600107192993\n",
            "EPOCH: 1 D LOSS 0.5788458585739136 G LOSS: 1.4074146747589111\n",
            "EPOCH: 1 D LOSS 0.5050911232829094 G LOSS: 1.1195967197418213\n",
            "EPOCH: 1 D LOSS 0.5591979324817657 G LOSS: 1.2517622709274292\n",
            "EPOCH: 1 D LOSS 0.5861022174358368 G LOSS: 1.9322474002838135\n",
            "EPOCH: 1 D LOSS 0.6653519570827484 G LOSS: 1.303480863571167\n",
            "EPOCH: 1 D LOSS 0.5066904872655869 G LOSS: 1.3812694549560547\n",
            "EPOCH: 1 D LOSS 0.6334735751152039 G LOSS: 1.4956495761871338\n",
            "EPOCH: 1 D LOSS 0.6636984050273895 G LOSS: 1.1773946285247803\n",
            "EPOCH: 1 D LOSS 0.6716780960559845 G LOSS: 1.632192611694336\n",
            "EPOCH: 1 D LOSS 0.6005449593067169 G LOSS: 1.5660877227783203\n",
            "EPOCH: 1 D LOSS 0.5145776867866516 G LOSS: 1.4869005680084229\n",
            "EPOCH: 1 D LOSS 0.38636886328458786 G LOSS: 1.5232505798339844\n",
            "EPOCH: 1 D LOSS 0.6439814865589142 G LOSS: 1.7550512552261353\n",
            "EPOCH: 1 D LOSS 0.3423110097646713 G LOSS: 1.1074426174163818\n",
            "EPOCH: 1 D LOSS 0.6013807654380798 G LOSS: 1.2894790172576904\n",
            "EPOCH: 1 D LOSS 0.5528939068317413 G LOSS: 1.9520502090454102\n",
            "EPOCH: 1 D LOSS 0.5555160194635391 G LOSS: 1.7726941108703613\n",
            "EPOCH: 1 D LOSS 0.5560465157032013 G LOSS: 1.7615878582000732\n",
            "EPOCH: 1 D LOSS 0.6209229081869125 G LOSS: 1.5861539840698242\n",
            "EPOCH: 1 D LOSS 0.6230826377868652 G LOSS: 1.1690870523452759\n",
            "EPOCH: 1 D LOSS 0.5488130412995815 G LOSS: 1.8205978870391846\n",
            "EPOCH: 1 D LOSS 0.28567346930503845 G LOSS: 1.8473225831985474\n",
            "EPOCH: 1 D LOSS 0.71033775806427 G LOSS: 1.6537452936172485\n",
            "EPOCH: 1 D LOSS 0.6288622617721558 G LOSS: 1.5792231559753418\n",
            "EPOCH: 1 D LOSS 0.5449428856372833 G LOSS: 1.7731834650039673\n",
            "EPOCH: 1 D LOSS 0.5981059968471527 G LOSS: 1.1529179811477661\n",
            "EPOCH: 1 D LOSS 0.6415559649467468 G LOSS: 1.5306053161621094\n",
            "EPOCH: 1 D LOSS 0.635233461856842 G LOSS: 1.1259841918945312\n",
            "EPOCH: 1 D LOSS 0.768758237361908 G LOSS: 1.537231206893921\n",
            "EPOCH: 1 D LOSS 0.5773719549179077 G LOSS: 1.6063300371170044\n",
            "EPOCH: 1 D LOSS 0.5626760125160217 G LOSS: 0.8603939414024353\n",
            "EPOCH: 1 D LOSS 0.6215826570987701 G LOSS: 1.4558727741241455\n",
            "EPOCH: 1 D LOSS 0.34054549783468246 G LOSS: 1.7228889465332031\n",
            "EPOCH: 1 D LOSS 0.5690116882324219 G LOSS: 1.4349336624145508\n",
            "EPOCH: 1 D LOSS 0.5873304903507233 G LOSS: 1.5047874450683594\n",
            "EPOCH: 1 D LOSS 0.5081998109817505 G LOSS: 1.1645781993865967\n",
            "EPOCH: 1 D LOSS 0.5616081357002258 G LOSS: 1.5100493431091309\n",
            "EPOCH: 1 D LOSS 0.45691201090812683 G LOSS: 1.6342986822128296\n",
            "EPOCH: 1 D LOSS 0.6134777665138245 G LOSS: 1.2608113288879395\n",
            "EPOCH: 1 D LOSS 0.6926653981208801 G LOSS: 1.348874568939209\n",
            "EPOCH: 1 D LOSS 0.6498843729496002 G LOSS: 1.5008877515792847\n",
            "EPOCH: 1 D LOSS 0.67441326379776 G LOSS: 1.244046926498413\n",
            "EPOCH: 1 D LOSS 0.6275682747364044 G LOSS: 1.2826093435287476\n",
            "EPOCH: 1 D LOSS 0.6292562186717987 G LOSS: 1.0597745180130005\n",
            "EPOCH: 1 D LOSS 0.6550704836845398 G LOSS: 1.3325445652008057\n",
            "EPOCH: 1 D LOSS 0.5846539437770844 G LOSS: 1.438577651977539\n",
            "EPOCH: 1 D LOSS 0.5871972888708115 G LOSS: 1.2045810222625732\n",
            "EPOCH: 1 D LOSS 0.6009095907211304 G LOSS: 1.5173065662384033\n",
            "EPOCH: 1 D LOSS 0.5190497636795044 G LOSS: 1.0599985122680664\n",
            "EPOCH: 1 D LOSS 0.5210484378039837 G LOSS: 1.2447214126586914\n",
            "EPOCH: 1 D LOSS 0.4783671796321869 G LOSS: 1.4376522302627563\n",
            "EPOCH: 1 D LOSS 0.47680234909057617 G LOSS: 1.689866065979004\n",
            "EPOCH: 1 D LOSS 0.47609843313694 G LOSS: 1.3664231300354004\n",
            "EPOCH: 1 D LOSS 0.5821724534034729 G LOSS: 1.5654484033584595\n",
            "EPOCH: 1 D LOSS 0.4553886950016022 G LOSS: 1.6083205938339233\n",
            "EPOCH: 1 D LOSS 0.5867078900337219 G LOSS: 1.444535493850708\n",
            "EPOCH: 1 D LOSS 0.5156880915164948 G LOSS: 1.2497628927230835\n",
            "EPOCH: 1 D LOSS 0.5436592698097229 G LOSS: 1.8278392553329468\n",
            "EPOCH: 1 D LOSS 0.6089092791080475 G LOSS: 1.5003412961959839\n",
            "EPOCH: 1 D LOSS 0.6297191381454468 G LOSS: 1.6985255479812622\n",
            "EPOCH: 1 D LOSS 0.6394848823547363 G LOSS: 1.661813735961914\n",
            "EPOCH: 1 D LOSS 0.7026827186346054 G LOSS: 1.6440236568450928\n",
            "EPOCH: 1 D LOSS 0.38600321114063263 G LOSS: 2.0299031734466553\n",
            "EPOCH: 1 D LOSS 0.4843499958515167 G LOSS: 2.143329620361328\n",
            "EPOCH: 1 D LOSS 0.4712529480457306 G LOSS: 1.510765552520752\n",
            "EPOCH: 1 D LOSS 0.6120912134647369 G LOSS: 2.006441831588745\n",
            "EPOCH: 1 D LOSS 0.7118032276630402 G LOSS: 1.7561362981796265\n",
            "EPOCH: 1 D LOSS 0.5611003935337067 G LOSS: 2.120182752609253\n",
            "EPOCH: 1 D LOSS 0.6600935459136963 G LOSS: 0.9969924092292786\n",
            "EPOCH: 1 D LOSS 0.7531540170311928 G LOSS: 1.6083440780639648\n",
            "EPOCH: 1 D LOSS 0.3096393495798111 G LOSS: 1.7672380208969116\n",
            "EPOCH: 1 D LOSS 0.40284427255392075 G LOSS: 1.5490057468414307\n",
            "EPOCH: 1 D LOSS 0.4815642088651657 G LOSS: 1.287874698638916\n",
            "EPOCH: 1 D LOSS 0.6037971675395966 G LOSS: 1.899436354637146\n",
            "EPOCH: 1 D LOSS 0.6539248526096344 G LOSS: 1.701131820678711\n",
            "EPOCH: 1 D LOSS 0.6374708116054535 G LOSS: 1.390572428703308\n",
            "EPOCH: 1 D LOSS 0.7715832591056824 G LOSS: 1.8179107904434204\n",
            "EPOCH: 1 D LOSS 0.5835674703121185 G LOSS: 1.923696756362915\n",
            "EPOCH: 1 D LOSS 0.7402953505516052 G LOSS: 1.2155747413635254\n",
            "EPOCH: 1 D LOSS 0.6827507019042969 G LOSS: 1.465897560119629\n",
            "EPOCH: 1 D LOSS 0.46014098823070526 G LOSS: 1.710574984550476\n",
            "EPOCH: 1 D LOSS 0.6678842902183533 G LOSS: 1.5932458639144897\n",
            "EPOCH: 1 D LOSS 0.5612946152687073 G LOSS: 1.0811445713043213\n",
            "EPOCH: 1 D LOSS 0.678922027349472 G LOSS: 1.4156345129013062\n",
            "EPOCH: 1 D LOSS 0.6178439259529114 G LOSS: 1.5000041723251343\n",
            "EPOCH: 1 D LOSS 0.6148775517940521 G LOSS: 1.1737303733825684\n",
            "EPOCH: 1 D LOSS 0.5049292743206024 G LOSS: 1.4367859363555908\n",
            "EPOCH: 1 D LOSS 0.40834199637174606 G LOSS: 1.4704774618148804\n",
            "EPOCH: 1 D LOSS 0.4383278042078018 G LOSS: 1.4114477634429932\n",
            "EPOCH: 1 D LOSS 0.5499744117259979 G LOSS: 1.7237259149551392\n",
            "EPOCH: 1 D LOSS 0.47475938498973846 G LOSS: 1.3214707374572754\n",
            "EPOCH: 1 D LOSS 0.701129823923111 G LOSS: 1.625309705734253\n",
            "EPOCH: 1 D LOSS 0.5662074089050293 G LOSS: 1.2709128856658936\n",
            "EPOCH: 1 D LOSS 0.47353966534137726 G LOSS: 1.14107346534729\n",
            "EPOCH: 1 D LOSS 0.5502361059188843 G LOSS: 1.5556187629699707\n",
            "EPOCH: 1 D LOSS 0.47297583520412445 G LOSS: 1.7432302236557007\n",
            "EPOCH: 1 D LOSS 0.5269731879234314 G LOSS: 1.7508771419525146\n",
            "EPOCH: 1 D LOSS 0.6177395880222321 G LOSS: 1.0054142475128174\n",
            "EPOCH: 1 D LOSS 0.6126123666763306 G LOSS: 1.506981611251831\n",
            "EPOCH: 1 D LOSS 0.48528939485549927 G LOSS: 1.6032593250274658\n",
            "EPOCH: 1 D LOSS 0.5727806091308594 G LOSS: 1.0631023645401\n",
            "EPOCH: 1 D LOSS 0.47738243266940117 G LOSS: 1.2940950393676758\n",
            "EPOCH: 1 D LOSS 0.3774138353765011 G LOSS: 1.3018043041229248\n",
            "EPOCH: 1 D LOSS 0.3338206745684147 G LOSS: 1.2624173164367676\n",
            "EPOCH: 1 D LOSS 0.4227137118577957 G LOSS: 1.8011157512664795\n",
            "EPOCH: 1 D LOSS 0.4959237575531006 G LOSS: 1.7822988033294678\n",
            "EPOCH: 1 D LOSS 0.5514352023601532 G LOSS: 1.6957268714904785\n",
            "EPOCH: 1 D LOSS 0.6195972561836243 G LOSS: 1.1474692821502686\n",
            "EPOCH: 1 D LOSS 0.6965271991211921 G LOSS: 1.591151475906372\n",
            "EPOCH: 1 D LOSS 0.5028693079948425 G LOSS: 1.9239528179168701\n",
            "EPOCH: 1 D LOSS 0.6928786933422089 G LOSS: 1.552344799041748\n",
            "EPOCH: 1 D LOSS 0.5356199741363525 G LOSS: 1.386723518371582\n",
            "EPOCH: 1 D LOSS 0.5370915830135345 G LOSS: 1.051588773727417\n",
            "EPOCH: 1 D LOSS 0.49515412747859955 G LOSS: 0.984952449798584\n",
            "EPOCH: 1 D LOSS 0.6089313328266144 G LOSS: 1.2301859855651855\n",
            "EPOCH: 1 D LOSS 0.4996607154607773 G LOSS: 1.2677645683288574\n",
            "EPOCH: 1 D LOSS 0.5648747980594635 G LOSS: 1.3607103824615479\n",
            "EPOCH: 1 D LOSS 0.5501410216093063 G LOSS: 1.4256216287612915\n",
            "EPOCH: 1 D LOSS 0.5608925670385361 G LOSS: 1.5631089210510254\n",
            "EPOCH: 1 D LOSS 0.6497259736061096 G LOSS: 1.3782063722610474\n",
            "EPOCH: 1 D LOSS 0.6087081432342529 G LOSS: 1.0247727632522583\n",
            "EPOCH: 1 D LOSS 0.5726666301488876 G LOSS: 1.3764123916625977\n",
            "EPOCH: 1 D LOSS 0.43043795228004456 G LOSS: 1.4198553562164307\n",
            "EPOCH: 1 D LOSS 0.5862298607826233 G LOSS: 1.366810917854309\n",
            "EPOCH: 1 D LOSS 0.4254259988665581 G LOSS: 1.0676894187927246\n",
            "EPOCH: 1 D LOSS 0.27397942543029785 G LOSS: 1.468090295791626\n",
            "EPOCH: 1 D LOSS 0.7612343728542328 G LOSS: 1.8582680225372314\n",
            "EPOCH: 1 D LOSS 0.4852282702922821 G LOSS: 1.7140998840332031\n",
            "EPOCH: 1 D LOSS 0.4864348769187927 G LOSS: 1.4396016597747803\n",
            "EPOCH: 1 D LOSS 0.4846465289592743 G LOSS: 1.5482914447784424\n",
            "EPOCH: 1 D LOSS 0.48114538192749023 G LOSS: 1.4866440296173096\n",
            "EPOCH: 1 D LOSS 0.4179531391710043 G LOSS: 1.4773151874542236\n",
            "EPOCH: 1 D LOSS 0.6571274101734161 G LOSS: 1.7914063930511475\n",
            "EPOCH: 1 D LOSS 0.5008309930562973 G LOSS: 1.5366041660308838\n",
            "EPOCH: 1 D LOSS 0.40376573614776134 G LOSS: 1.3748631477355957\n",
            "EPOCH: 1 D LOSS 0.36244768649339676 G LOSS: 1.4502167701721191\n",
            "EPOCH: 1 D LOSS 0.5554569959640503 G LOSS: 1.6291229724884033\n",
            "EPOCH: 1 D LOSS 0.45864737033843994 G LOSS: 1.3151040077209473\n",
            "EPOCH: 1 D LOSS 0.42040057480335236 G LOSS: 1.0874296426773071\n",
            "EPOCH: 1 D LOSS 0.6331621706485748 G LOSS: 1.8980722427368164\n",
            "EPOCH: 1 D LOSS 0.6160170137882233 G LOSS: 1.7570090293884277\n",
            "EPOCH: 1 D LOSS 0.5296306014060974 G LOSS: 1.2386022806167603\n",
            "EPOCH: 1 D LOSS 0.6224507987499237 G LOSS: 1.3975523710250854\n",
            "EPOCH: 1 D LOSS 0.6126330345869064 G LOSS: 1.7029365301132202\n",
            "EPOCH: 1 D LOSS 0.5144391804933548 G LOSS: 1.3554188013076782\n",
            "EPOCH: 1 D LOSS 0.6111215949058533 G LOSS: 1.3967781066894531\n",
            "EPOCH: 1 D LOSS 0.6251810789108276 G LOSS: 1.3895881175994873\n",
            "EPOCH: 1 D LOSS 0.550207108259201 G LOSS: 1.9064959287643433\n",
            "EPOCH: 1 D LOSS 0.5936834067106247 G LOSS: 1.8528292179107666\n",
            "EPOCH: 1 D LOSS 0.6854259967803955 G LOSS: 1.235199213027954\n",
            "EPOCH: 1 D LOSS 0.6319552659988403 G LOSS: 1.592864990234375\n",
            "EPOCH: 1 D LOSS 0.59537473320961 G LOSS: 1.5947800874710083\n",
            "EPOCH: 1 D LOSS 0.5022660791873932 G LOSS: 1.50021231174469\n",
            "EPOCH: 1 D LOSS 0.4984004944562912 G LOSS: 2.1094720363616943\n",
            "EPOCH: 1 D LOSS 0.49098676443099976 G LOSS: 1.6946372985839844\n",
            "EPOCH: 1 D LOSS 0.46685291826725006 G LOSS: 2.265664577484131\n",
            "EPOCH: 1 D LOSS 0.4541483521461487 G LOSS: 1.1288702487945557\n",
            "EPOCH: 1 D LOSS 0.5854558050632477 G LOSS: 1.9329044818878174\n",
            "EPOCH: 1 D LOSS 0.5367512702941895 G LOSS: 1.8790754079818726\n",
            "EPOCH: 1 D LOSS 0.5276400148868561 G LOSS: 1.1716465950012207\n",
            "EPOCH: 1 D LOSS 0.6805093884468079 G LOSS: 1.6440258026123047\n",
            "EPOCH: 1 D LOSS 0.4811593145132065 G LOSS: 1.6892412900924683\n",
            "EPOCH: 1 D LOSS 0.49103522300720215 G LOSS: 1.3744864463806152\n",
            "EPOCH: 1 D LOSS 0.4786469116806984 G LOSS: 1.2575435638427734\n",
            "EPOCH: 1 D LOSS 0.4236901253461838 G LOSS: 1.3297655582427979\n",
            "EPOCH: 1 D LOSS 0.588638424873352 G LOSS: 1.597505807876587\n",
            "EPOCH: 1 D LOSS 0.4702771380543709 G LOSS: 1.4582171440124512\n",
            "EPOCH: 1 D LOSS 0.3142902348190546 G LOSS: 1.1368024349212646\n",
            "EPOCH: 1 D LOSS 0.4891353426501155 G LOSS: 1.8673292398452759\n",
            "EPOCH: 1 D LOSS 0.28597790002822876 G LOSS: 1.6264269351959229\n",
            "EPOCH: 1 D LOSS 0.3843655586242676 G LOSS: 1.2839218378067017\n",
            "EPOCH: 1 D LOSS 0.33260253071784973 G LOSS: 1.524735689163208\n",
            "EPOCH: 1 D LOSS 0.1392519772052765 G LOSS: 1.6100478172302246\n",
            "EPOCH: 1 D LOSS 0.35801005363464355 G LOSS: 1.6529712677001953\n",
            "EPOCH: 1 D LOSS 0.38095083832740784 G LOSS: 2.202235698699951\n",
            "EPOCH: 1 D LOSS 0.5418119132518768 G LOSS: 2.3823177814483643\n",
            "EPOCH: 1 D LOSS 0.6844393908977509 G LOSS: 1.5853935480117798\n",
            "EPOCH: 1 D LOSS 0.7122812867164612 G LOSS: 1.7145746946334839\n",
            "EPOCH: 1 D LOSS 0.6477641761302948 G LOSS: 1.5562059879302979\n",
            "EPOCH: 1 D LOSS 0.6291845142841339 G LOSS: 2.3360767364501953\n",
            "EPOCH: 1 D LOSS 0.5729252099990845 G LOSS: 1.7836041450500488\n",
            "EPOCH: 1 D LOSS 0.7292780876159668 G LOSS: 1.3582745790481567\n",
            "EPOCH: 1 D LOSS 0.9475121051073074 G LOSS: 1.73976469039917\n",
            "EPOCH: 1 D LOSS 0.4650282561779022 G LOSS: 2.0923941135406494\n",
            "EPOCH: 1 D LOSS 0.4891641139984131 G LOSS: 1.3694546222686768\n",
            "EPOCH: 1 D LOSS 0.4196893274784088 G LOSS: 1.6411731243133545\n",
            "EPOCH: 1 D LOSS 0.33527031540870667 G LOSS: 2.4503986835479736\n",
            "EPOCH: 1 D LOSS 0.35441526770591736 G LOSS: 2.057593584060669\n",
            "EPOCH: 1 D LOSS 0.5195689052343369 G LOSS: 1.8506492376327515\n",
            "EPOCH: 1 D LOSS 0.5467664003372192 G LOSS: 2.0973658561706543\n",
            "EPOCH: 1 D LOSS 0.6777428090572357 G LOSS: 1.7852369546890259\n",
            "EPOCH: 1 D LOSS 0.3654956817626953 G LOSS: 1.991204023361206\n",
            "EPOCH: 1 D LOSS 0.5826913416385651 G LOSS: 1.302147388458252\n",
            "EPOCH: 1 D LOSS 0.6821941956877708 G LOSS: 1.6995676755905151\n",
            "EPOCH: 1 D LOSS 0.4058685302734375 G LOSS: 1.6428412199020386\n",
            "EPOCH: 1 D LOSS 0.5673753917217255 G LOSS: 1.3846960067749023\n",
            "EPOCH: 1 D LOSS 0.6354585289955139 G LOSS: 1.5316557884216309\n",
            "EPOCH: 1 D LOSS 0.48888082802295685 G LOSS: 1.4556033611297607\n",
            "EPOCH: 1 D LOSS 0.3940597288310528 G LOSS: 1.2991266250610352\n",
            "EPOCH: 1 D LOSS 0.49739310145378113 G LOSS: 1.405975103378296\n",
            "EPOCH: 1 D LOSS 0.5924753844738007 G LOSS: 1.8904311656951904\n",
            "EPOCH: 1 D LOSS 0.5283599644899368 G LOSS: 1.5105500221252441\n",
            "EPOCH: 1 D LOSS 0.5174635052680969 G LOSS: 1.539873480796814\n",
            "EPOCH: 1 D LOSS 0.6267563849687576 G LOSS: 1.973712682723999\n",
            "EPOCH: 1 D LOSS 0.6888332366943359 G LOSS: 1.5518550872802734\n",
            "EPOCH: 1 D LOSS 0.7295401692390442 G LOSS: 1.4556100368499756\n",
            "EPOCH: 1 D LOSS 0.5778070986270905 G LOSS: 1.8353997468948364\n",
            "EPOCH: 1 D LOSS 0.715880960226059 G LOSS: 1.5772840976715088\n",
            "EPOCH: 1 D LOSS 0.6975541710853577 G LOSS: 1.352852702140808\n",
            "EPOCH: 1 D LOSS 0.5847188234329224 G LOSS: 1.3477665185928345\n",
            "EPOCH: 1 D LOSS 0.5550250336527824 G LOSS: 1.5686371326446533\n",
            "EPOCH: 1 D LOSS 0.3487091660499573 G LOSS: 1.6495102643966675\n",
            "EPOCH: 1 D LOSS 0.48142194747924805 G LOSS: 1.8407357931137085\n",
            "EPOCH: 1 D LOSS 0.5220836102962494 G LOSS: 1.3536163568496704\n",
            "EPOCH: 1 D LOSS 0.6216639280319214 G LOSS: 1.2244062423706055\n",
            "EPOCH: 1 D LOSS 0.5955504775047302 G LOSS: 1.3266111612319946\n",
            "EPOCH: 1 D LOSS 0.5244746208190918 G LOSS: 1.6151607036590576\n",
            "EPOCH: 1 D LOSS 0.4973057061433792 G LOSS: 1.4595928192138672\n",
            "EPOCH: 1 D LOSS 0.5424293577671051 G LOSS: 1.8099031448364258\n",
            "EPOCH: 1 D LOSS 0.4605403244495392 G LOSS: 1.782505989074707\n",
            "EPOCH: 1 D LOSS 0.5047167241573334 G LOSS: 1.3234338760375977\n",
            "EPOCH: 1 D LOSS 0.4850457161664963 G LOSS: 1.3176711797714233\n",
            "EPOCH: 1 D LOSS 0.4692832976579666 G LOSS: 1.5193445682525635\n",
            "EPOCH: 1 D LOSS 0.49689270555973053 G LOSS: 1.6429495811462402\n",
            "EPOCH: 1 D LOSS 0.4921703338623047 G LOSS: 1.566528081893921\n",
            "EPOCH: 1 D LOSS 0.5515864938497543 G LOSS: 2.1540441513061523\n",
            "EPOCH: 1 D LOSS 0.5744647085666656 G LOSS: 1.8258217573165894\n",
            "EPOCH: 1 D LOSS 0.6090112030506134 G LOSS: 1.2542502880096436\n",
            "EPOCH: 1 D LOSS 0.5871141627430916 G LOSS: 1.262246012687683\n",
            "EPOCH: 1 D LOSS 0.49185431003570557 G LOSS: 1.4760106801986694\n",
            "EPOCH: 1 D LOSS 0.5104056000709534 G LOSS: 1.4503278732299805\n",
            "EPOCH: 1 D LOSS 0.4303843304514885 G LOSS: 1.1729004383087158\n",
            "EPOCH: 1 D LOSS 0.4426513435319066 G LOSS: 1.5177745819091797\n",
            "EPOCH: 1 D LOSS 0.31156349182128906 G LOSS: 2.008327007293701\n",
            "EPOCH: 1 D LOSS 0.4096856117248535 G LOSS: 1.4674162864685059\n",
            "EPOCH: 1 D LOSS 0.4584522992372513 G LOSS: 1.544710636138916\n",
            "EPOCH: 1 D LOSS 0.3433056559879333 G LOSS: 1.627471685409546\n",
            "EPOCH: 1 D LOSS 0.4262228310108185 G LOSS: 1.3441245555877686\n",
            "EPOCH: 1 D LOSS 0.4796459227800369 G LOSS: 1.4594216346740723\n",
            "EPOCH: 1 D LOSS 0.43356044590473175 G LOSS: 2.1014130115509033\n",
            "EPOCH: 1 D LOSS 0.6562793552875519 G LOSS: 1.7906360626220703\n",
            "EPOCH: 1 D LOSS 0.6303163766860962 G LOSS: 1.6257562637329102\n",
            "EPOCH: 1 D LOSS 0.5794431865215302 G LOSS: 1.7425291538238525\n",
            "EPOCH: 1 D LOSS 0.5870120227336884 G LOSS: 2.0050342082977295\n",
            "EPOCH: 1 D LOSS 0.5735850185155869 G LOSS: 1.0860979557037354\n",
            "EPOCH: 1 D LOSS 0.54072305560112 G LOSS: 1.8020544052124023\n",
            "EPOCH: 1 D LOSS 0.3330429270863533 G LOSS: 1.6985538005828857\n",
            "EPOCH: 1 D LOSS 0.5735125243663788 G LOSS: 2.060570240020752\n",
            "EPOCH: 1 D LOSS 0.3757103234529495 G LOSS: 1.3942692279815674\n",
            "EPOCH: 1 D LOSS 0.6155811697244644 G LOSS: 2.115884780883789\n",
            "EPOCH: 1 D LOSS 0.46234624087810516 G LOSS: 1.757460594177246\n",
            "EPOCH: 1 D LOSS 0.5764302313327789 G LOSS: 1.5517795085906982\n",
            "EPOCH: 1 D LOSS 0.5095218420028687 G LOSS: 1.696223258972168\n",
            "EPOCH: 1 D LOSS 0.41596680879592896 G LOSS: 1.469865083694458\n",
            "EPOCH: 1 D LOSS 0.4025647612288594 G LOSS: 1.9460134506225586\n",
            "EPOCH: 1 D LOSS 0.4299152046442032 G LOSS: 1.792901873588562\n",
            "EPOCH: 1 D LOSS 0.3517361283302307 G LOSS: 1.0271644592285156\n",
            "EPOCH: 1 D LOSS 0.45967167615890503 G LOSS: 2.2373242378234863\n",
            "EPOCH: 1 D LOSS 0.7695949673652649 G LOSS: 2.7213306427001953\n",
            "EPOCH: 1 D LOSS 0.6530134230852127 G LOSS: 1.5903104543685913\n",
            "EPOCH: 1 D LOSS 0.521712452173233 G LOSS: 1.3276381492614746\n",
            "EPOCH: 1 D LOSS 0.3465420976281166 G LOSS: 0.9322230219841003\n",
            "EPOCH: 1 D LOSS 0.5694345235824585 G LOSS: 1.11854887008667\n",
            "EPOCH: 1 D LOSS 0.4928831160068512 G LOSS: 1.3686455488204956\n",
            "EPOCH: 1 D LOSS 0.5950502306222916 G LOSS: 1.739473819732666\n",
            "EPOCH: 1 D LOSS 0.5764003396034241 G LOSS: 1.5565049648284912\n",
            "EPOCH: 1 D LOSS 0.4986981451511383 G LOSS: 1.2123425006866455\n",
            "EPOCH: 1 D LOSS 0.6675280034542084 G LOSS: 1.2794520854949951\n",
            "EPOCH: 1 D LOSS 0.5623963475227356 G LOSS: 1.4956095218658447\n",
            "EPOCH: 1 D LOSS 0.5224103927612305 G LOSS: 1.7651991844177246\n",
            "EPOCH: 1 D LOSS 0.5354377031326294 G LOSS: 1.3004992008209229\n",
            "EPOCH: 1 D LOSS 0.6071445345878601 G LOSS: 1.1027226448059082\n",
            "EPOCH: 1 D LOSS 0.6472133994102478 G LOSS: 1.5507570505142212\n",
            "EPOCH: 1 D LOSS 0.475101113319397 G LOSS: 1.6825995445251465\n",
            "EPOCH: 1 D LOSS 0.4182438403367996 G LOSS: 1.3876599073410034\n",
            "EPOCH: 1 D LOSS 0.5349722653627396 G LOSS: 1.8708969354629517\n",
            "EPOCH: 1 D LOSS 0.44226183742284775 G LOSS: 2.337798595428467\n",
            "EPOCH: 1 D LOSS 0.6194503009319305 G LOSS: 1.573821783065796\n",
            "EPOCH: 1 D LOSS 0.5420152842998505 G LOSS: 1.5201365947723389\n",
            "EPOCH: 1 D LOSS 0.4555782079696655 G LOSS: 1.3825310468673706\n",
            "EPOCH: 1 D LOSS 0.4433077946305275 G LOSS: 1.2688074111938477\n",
            "EPOCH: 1 D LOSS 0.2962677627801895 G LOSS: 1.8664308786392212\n",
            "EPOCH: 1 D LOSS 0.5529546141624451 G LOSS: 2.1174769401550293\n",
            "EPOCH: 1 D LOSS 0.2726058177649975 G LOSS: 1.608262062072754\n",
            "EPOCH: 1 D LOSS 0.3080701678991318 G LOSS: 1.418438196182251\n",
            "EPOCH: 1 D LOSS 0.4389796257019043 G LOSS: 1.601165533065796\n",
            "EPOCH: 1 D LOSS 0.3785620080307126 G LOSS: 1.7519335746765137\n",
            "EPOCH: 1 D LOSS 0.2756468281149864 G LOSS: 1.8717750310897827\n",
            "EPOCH: 1 D LOSS 0.5477071404457092 G LOSS: 2.688483953475952\n",
            "EPOCH: 1 D LOSS 0.6302351951599121 G LOSS: 2.0528390407562256\n",
            "EPOCH: 1 D LOSS 0.5793202668428421 G LOSS: 1.6930723190307617\n",
            "EPOCH: 1 D LOSS 0.4777354896068573 G LOSS: 1.4127521514892578\n",
            "EPOCH: 1 D LOSS 0.6164706945419312 G LOSS: 1.4283208847045898\n",
            "EPOCH: 1 D LOSS 0.5432250201702118 G LOSS: 1.7467910051345825\n",
            "EPOCH: 1 D LOSS 0.6547318994998932 G LOSS: 1.997859001159668\n",
            "EPOCH: 1 D LOSS 0.5848197937011719 G LOSS: 1.0702143907546997\n",
            "EPOCH: 1 D LOSS 0.5080633908510208 G LOSS: 1.5923118591308594\n",
            "EPOCH: 1 D LOSS 0.531327098608017 G LOSS: 2.1010546684265137\n",
            "EPOCH: 1 D LOSS 0.4983614906668663 G LOSS: 2.0843729972839355\n",
            "EPOCH: 1 D LOSS 0.6126146018505096 G LOSS: 1.2197128534317017\n",
            "EPOCH: 1 D LOSS 0.5603249669075012 G LOSS: 1.2604018449783325\n",
            "EPOCH: 1 D LOSS 0.4899120628833771 G LOSS: 1.6582204103469849\n",
            "EPOCH: 1 D LOSS 0.5632673799991608 G LOSS: 1.6542363166809082\n",
            "EPOCH: 1 D LOSS 0.46118974685668945 G LOSS: 1.5280711650848389\n",
            "EPOCH: 1 D LOSS 0.6839151382446289 G LOSS: 1.5578826665878296\n",
            "EPOCH: 1 D LOSS 0.6637487411499023 G LOSS: 1.386447548866272\n",
            "EPOCH: 1 D LOSS 0.5832202732563019 G LOSS: 1.302617073059082\n",
            "EPOCH: 1 D LOSS 0.6339778900146484 G LOSS: 1.3639094829559326\n",
            "EPOCH: 1 D LOSS 0.6162891238927841 G LOSS: 1.3565335273742676\n",
            "EPOCH: 1 D LOSS 0.5905198454856873 G LOSS: 1.6744706630706787\n",
            "EPOCH: 1 D LOSS 0.47245775163173676 G LOSS: 1.4389398097991943\n",
            "EPOCH: 1 D LOSS 0.5675903111696243 G LOSS: 2.077453851699829\n",
            "EPOCH: 1 D LOSS 0.602042019367218 G LOSS: 1.883786916732788\n",
            "EPOCH: 1 D LOSS 0.6193596720695496 G LOSS: 1.2545450925827026\n",
            "EPOCH: 1 D LOSS 0.5052375346422195 G LOSS: 1.11769700050354\n",
            "EPOCH: 1 D LOSS 0.5154455900192261 G LOSS: 1.4310872554779053\n",
            "EPOCH: 1 D LOSS 0.5803137719631195 G LOSS: 1.4232701063156128\n",
            "EPOCH: 1 D LOSS 0.598936140537262 G LOSS: 1.3044930696487427\n",
            "EPOCH: 1 D LOSS 0.5642128139734268 G LOSS: 1.521755576133728\n",
            "EPOCH: 1 D LOSS 0.33232636749744415 G LOSS: 1.540294885635376\n",
            "EPOCH: 1 D LOSS 0.3360071601346135 G LOSS: 1.173327922821045\n",
            "EPOCH: 1 D LOSS 0.5807797908782959 G LOSS: 1.3665375709533691\n",
            "EPOCH: 1 D LOSS 0.43635302782058716 G LOSS: 1.6315629482269287\n",
            "EPOCH: 1 D LOSS 0.42071812599897385 G LOSS: 1.6968201398849487\n",
            "EPOCH: 1 D LOSS 0.4127911925315857 G LOSS: 1.8783032894134521\n",
            "EPOCH: 1 D LOSS 0.43060189485549927 G LOSS: 1.9782063961029053\n",
            "EPOCH: 1 D LOSS 0.6452441215515137 G LOSS: 1.9095377922058105\n",
            "EPOCH: 1 D LOSS 0.5416508316993713 G LOSS: 1.4195818901062012\n",
            "EPOCH: 1 D LOSS 0.43411654233932495 G LOSS: 1.6299580335617065\n",
            "EPOCH: 1 D LOSS 0.666448712348938 G LOSS: 1.6562507152557373\n",
            "EPOCH: 1 D LOSS 0.664562851190567 G LOSS: 1.5452730655670166\n",
            "EPOCH: 1 D LOSS 0.5816522538661957 G LOSS: 1.1444802284240723\n",
            "EPOCH: 1 D LOSS 0.5134657621383667 G LOSS: 1.3098187446594238\n",
            "EPOCH: 1 D LOSS 0.66811603307724 G LOSS: 1.694342017173767\n",
            "EPOCH: 1 D LOSS 0.5268207788467407 G LOSS: 1.0734059810638428\n",
            "EPOCH: 1 D LOSS 0.42764126881957054 G LOSS: 1.2239176034927368\n",
            "EPOCH: 1 D LOSS 0.22329574823379517 G LOSS: 1.5622097253799438\n",
            "EPOCH: 1 D LOSS 0.48384062945842743 G LOSS: 2.0473875999450684\n",
            "EPOCH: 1 D LOSS 0.5882346332073212 G LOSS: 2.0297858715057373\n",
            "EPOCH: 1 D LOSS 0.45948968827724457 G LOSS: 1.486971139907837\n",
            "EPOCH: 1 D LOSS 0.4300176650285721 G LOSS: 1.164901852607727\n",
            "EPOCH: 1 D LOSS 0.5648077130317688 G LOSS: 1.5650160312652588\n",
            "EPOCH: 1 D LOSS 0.6894122362136841 G LOSS: 1.9612029790878296\n",
            "EPOCH: 1 D LOSS 0.570146769285202 G LOSS: 1.5616123676300049\n",
            "EPOCH: 1 D LOSS 0.6597341299057007 G LOSS: 1.3197767734527588\n",
            "EPOCH: 1 D LOSS 0.6349133625626564 G LOSS: 1.3584556579589844\n",
            "EPOCH: 1 D LOSS 0.5099402666091919 G LOSS: 2.208439350128174\n",
            "EPOCH: 1 D LOSS 0.5337188839912415 G LOSS: 1.6228983402252197\n",
            "EPOCH: 1 D LOSS 0.484233021736145 G LOSS: 1.1638503074645996\n",
            "EPOCH: 1 D LOSS 0.550056129693985 G LOSS: 1.5658552646636963\n",
            "EPOCH: 1 D LOSS 0.4063771814107895 G LOSS: 1.2660326957702637\n",
            "EPOCH: 1 D LOSS 0.4378403667360544 G LOSS: 1.2004978656768799\n",
            "EPOCH: 1 D LOSS 0.3626560643315315 G LOSS: 1.4291582107543945\n",
            "EPOCH: 1 D LOSS 0.3338810130953789 G LOSS: 1.572913646697998\n",
            "EPOCH: 1 D LOSS 0.5053559243679047 G LOSS: 1.6378939151763916\n",
            "EPOCH: 1 D LOSS 0.42199690639972687 G LOSS: 1.9055583477020264\n",
            "EPOCH: 1 D LOSS 0.5603103190660477 G LOSS: 2.062469720840454\n",
            "EPOCH: 1 D LOSS 0.632056474685669 G LOSS: 1.4622163772583008\n",
            "EPOCH: 1 D LOSS 0.6839371919631958 G LOSS: 1.285569429397583\n",
            "EPOCH: 1 D LOSS 0.7161294370889664 G LOSS: 1.532014012336731\n",
            "EPOCH: 1 D LOSS 0.34375418722629547 G LOSS: 1.2902500629425049\n",
            "EPOCH: 1 D LOSS 0.7204164564609528 G LOSS: 1.5018045902252197\n",
            "EPOCH: 1 D LOSS 0.5402755439281464 G LOSS: 1.281178593635559\n",
            "EPOCH: 1 D LOSS 0.4808207005262375 G LOSS: 1.6264125108718872\n",
            "EPOCH: 1 D LOSS 0.6654050946235657 G LOSS: 2.010575771331787\n",
            "EPOCH: 1 D LOSS 0.5603732466697693 G LOSS: 0.9326637387275696\n",
            "EPOCH: 1 D LOSS 0.696210116147995 G LOSS: 1.2002997398376465\n",
            "EPOCH: 1 D LOSS 0.44468653202056885 G LOSS: 1.4989032745361328\n",
            "EPOCH: 1 D LOSS 0.4658292233943939 G LOSS: 1.574669599533081\n",
            "EPOCH: 1 D LOSS 0.5280292481184006 G LOSS: 1.8153095245361328\n",
            "EPOCH: 1 D LOSS 0.46772992610931396 G LOSS: 1.4681323766708374\n",
            "EPOCH: 1 D LOSS 0.36652382276952267 G LOSS: 1.1617403030395508\n",
            "EPOCH: 1 D LOSS 0.5375091284513474 G LOSS: 1.5557560920715332\n",
            "EPOCH: 1 D LOSS 0.44763267040252686 G LOSS: 1.6623127460479736\n",
            "EPOCH: 1 D LOSS 0.43800676614046097 G LOSS: 1.7902696132659912\n",
            "EPOCH: 1 D LOSS 0.4699628949165344 G LOSS: 1.642190933227539\n",
            "EPOCH: 1 D LOSS 0.6198256611824036 G LOSS: 1.7772530317306519\n",
            "EPOCH: 1 D LOSS 0.5629405230283737 G LOSS: 1.6488466262817383\n",
            "EPOCH: 1 D LOSS 0.5252673029899597 G LOSS: 1.2403756380081177\n",
            "EPOCH: 1 D LOSS 0.5247855484485626 G LOSS: 1.6980397701263428\n",
            "EPOCH: 1 D LOSS 0.513961672782898 G LOSS: 2.0508527755737305\n",
            "EPOCH: 1 D LOSS 0.5334755033254623 G LOSS: 1.1869127750396729\n",
            "EPOCH: 1 D LOSS 0.46347223222255707 G LOSS: 1.5377711057662964\n",
            "EPOCH: 1 D LOSS 0.2006641887128353 G LOSS: 2.1035168170928955\n",
            "EPOCH: 1 D LOSS 0.23712192196398973 G LOSS: 1.629918098449707\n",
            "EPOCH: 1 D LOSS 0.349432110786438 G LOSS: 2.0037009716033936\n",
            "EPOCH: 1 D LOSS 0.10729669034481049 G LOSS: 2.0187649726867676\n",
            "EPOCH: 1 D LOSS 0.11771628260612488 G LOSS: 2.1563892364501953\n",
            "EPOCH: 1 D LOSS 0.29614436626434326 G LOSS: 2.2280659675598145\n",
            "EPOCH: 1 D LOSS 0.3560267314314842 G LOSS: 2.0742602348327637\n",
            "EPOCH: 1 D LOSS 0.5871598720550537 G LOSS: 2.816537380218506\n",
            "EPOCH: 1 D LOSS 0.6078270822763443 G LOSS: 2.0472044944763184\n",
            "EPOCH: 1 D LOSS 0.5378392934799194 G LOSS: 1.8480820655822754\n",
            "EPOCH: 1 D LOSS 0.7255581021308899 G LOSS: 1.6353286504745483\n",
            "EPOCH: 1 D LOSS 0.71575066447258 G LOSS: 1.550478219985962\n",
            "EPOCH: 1 D LOSS 0.6225264966487885 G LOSS: 1.978766679763794\n",
            "EPOCH: 1 D LOSS 0.5492805242538452 G LOSS: 1.9513013362884521\n",
            "EPOCH: 1 D LOSS 0.6350779235363007 G LOSS: 1.9802535772323608\n",
            "EPOCH: 1 D LOSS 0.7157280743122101 G LOSS: 1.0894997119903564\n",
            "EPOCH: 1 D LOSS 0.5032989382743835 G LOSS: 1.3568315505981445\n",
            "EPOCH: 1 D LOSS 0.3351391851902008 G LOSS: 1.8610090017318726\n",
            "EPOCH: 1 D LOSS 0.11769372224807739 G LOSS: 2.100224494934082\n",
            "EPOCH: 1 D LOSS 0.2638576813042164 G LOSS: 2.076225757598877\n",
            "EPOCH: 1 D LOSS 0.47412486374378204 G LOSS: 1.632718801498413\n",
            "EPOCH: 1 D LOSS 0.35994216799736023 G LOSS: 2.8650026321411133\n",
            "EPOCH: 1 D LOSS 0.7108901143074036 G LOSS: 3.0170698165893555\n",
            "EPOCH: 1 D LOSS 0.6485171616077423 G LOSS: 1.2020491361618042\n",
            "EPOCH: 1 D LOSS 0.36130291223526 G LOSS: 1.1197350025177002\n",
            "EPOCH: 1 D LOSS 0.6632427871227264 G LOSS: 1.9642781019210815\n",
            "EPOCH: 1 D LOSS 0.2878922149538994 G LOSS: 1.6842584609985352\n",
            "EPOCH: 1 D LOSS 0.3109710067510605 G LOSS: 1.5017032623291016\n",
            "EPOCH: 1 D LOSS 0.31297574611380696 G LOSS: 1.6504684686660767\n",
            "EPOCH: 1 D LOSS 0.41719380021095276 G LOSS: 1.5698156356811523\n",
            "EPOCH: 1 D LOSS 0.3333556354045868 G LOSS: 1.9336274862289429\n",
            "EPOCH: 1 D LOSS 0.20725509524345398 G LOSS: 1.7515008449554443\n",
            "EPOCH: 1 D LOSS 0.39061012491583824 G LOSS: 1.4558813571929932\n",
            "EPOCH: 1 D LOSS 0.4701453745365143 G LOSS: 2.6290676593780518\n",
            "EPOCH: 1 D LOSS 0.39791378378868103 G LOSS: 2.4774837493896484\n",
            "EPOCH: 1 D LOSS 0.7378331422805786 G LOSS: 1.6939136981964111\n",
            "EPOCH: 1 D LOSS 0.7350723743438721 G LOSS: 1.4424232244491577\n",
            "EPOCH: 1 D LOSS 0.5836282670497894 G LOSS: 1.3578004837036133\n",
            "EPOCH: 1 D LOSS 0.5903968214988708 G LOSS: 1.5622811317443848\n",
            "EPOCH: 1 D LOSS 0.6614901423454285 G LOSS: 1.4303689002990723\n",
            "EPOCH: 1 D LOSS 0.6734563857316971 G LOSS: 1.1735334396362305\n",
            "EPOCH: 1 D LOSS 0.4812842309474945 G LOSS: 1.2174055576324463\n",
            "EPOCH: 1 D LOSS 0.526270866394043 G LOSS: 1.5489163398742676\n",
            "EPOCH: 1 D LOSS 0.5080857276916504 G LOSS: 1.4140689373016357\n",
            "EPOCH: 1 D LOSS 0.45295921340584755 G LOSS: 1.5159648656845093\n",
            "EPOCH: 1 D LOSS 0.264023020863533 G LOSS: 1.4088952541351318\n",
            "EPOCH: 1 D LOSS 0.6748611778020859 G LOSS: 1.9920883178710938\n",
            "EPOCH: 1 D LOSS 0.4209252744913101 G LOSS: 1.2130155563354492\n",
            "EPOCH: 1 D LOSS 0.4358748644590378 G LOSS: 1.705040693283081\n",
            "EPOCH: 1 D LOSS 0.5068487524986267 G LOSS: 1.9764859676361084\n",
            "EPOCH: 1 D LOSS 0.3381917327642441 G LOSS: 1.5314396619796753\n",
            "EPOCH: 1 D LOSS 0.5073478817939758 G LOSS: 1.4258934259414673\n",
            "EPOCH: 1 D LOSS 0.4858817160129547 G LOSS: 1.1753199100494385\n",
            "EPOCH: 1 D LOSS 0.446916863322258 G LOSS: 1.2612271308898926\n",
            "EPOCH: 1 D LOSS 0.5523083508014679 G LOSS: 1.5021440982818604\n",
            "EPOCH: 1 D LOSS 0.3911993196234107 G LOSS: 1.4716837406158447\n",
            "EPOCH: 1 D LOSS 0.580194354057312 G LOSS: 1.8021371364593506\n",
            "EPOCH: 1 D LOSS 0.4579160809516907 G LOSS: 1.1264656782150269\n",
            "EPOCH: 1 D LOSS 0.6810056418180466 G LOSS: 1.8168549537658691\n",
            "EPOCH: 1 D LOSS 0.38490089774131775 G LOSS: 1.7445225715637207\n",
            "EPOCH: 1 D LOSS 0.40770532935857773 G LOSS: 1.071540117263794\n",
            "EPOCH: 1 D LOSS 0.6278278231620789 G LOSS: 1.7540568113327026\n",
            "EPOCH: 1 D LOSS 0.16064006462693214 G LOSS: 1.5712406635284424\n",
            "EPOCH: 1 D LOSS 0.6593791544437408 G LOSS: 1.9482429027557373\n",
            "EPOCH: 1 D LOSS 0.5034785866737366 G LOSS: 1.4194209575653076\n",
            "EPOCH: 1 D LOSS 0.47294315695762634 G LOSS: 1.570237398147583\n",
            "EPOCH: 1 D LOSS 0.49085354804992676 G LOSS: 2.020932674407959\n",
            "EPOCH: 1 D LOSS 0.4741508662700653 G LOSS: 2.0274674892425537\n",
            "EPOCH: 1 D LOSS 0.4568015933036804 G LOSS: 1.189613699913025\n",
            "EPOCH: 1 D LOSS 0.4825949650257826 G LOSS: 1.9866145849227905\n",
            "EPOCH: 1 D LOSS 0.46406015008687973 G LOSS: 2.8276290893554688\n",
            "EPOCH: 1 D LOSS 0.5189712047576904 G LOSS: 2.2806663513183594\n",
            "EPOCH: 1 D LOSS 0.4418308436870575 G LOSS: 1.5394383668899536\n",
            "EPOCH: 1 D LOSS 0.5529016107320786 G LOSS: 1.9126269817352295\n",
            "EPOCH: 1 D LOSS 0.21554268058389425 G LOSS: 1.8131306171417236\n",
            "EPOCH: 1 D LOSS 0.5914512425661087 G LOSS: 2.2732253074645996\n",
            "EPOCH: 1 D LOSS 0.3862338066101074 G LOSS: 1.4544914960861206\n",
            "EPOCH: 1 D LOSS 0.47283393144607544 G LOSS: 1.521882176399231\n",
            "EPOCH: 1 D LOSS 0.5634881556034088 G LOSS: 1.983884334564209\n",
            "EPOCH: 1 D LOSS 0.5467352569103241 G LOSS: 2.2948086261749268\n",
            "EPOCH: 1 D LOSS 0.6027258336544037 G LOSS: 1.9323288202285767\n",
            "EPOCH: 1 D LOSS 0.6594906449317932 G LOSS: 1.6431329250335693\n",
            "EPOCH: 1 D LOSS 0.7256434261798859 G LOSS: 1.4708659648895264\n",
            "EPOCH: 1 D LOSS 0.5725226402282715 G LOSS: 1.6831320524215698\n",
            "EPOCH: 1 D LOSS 0.49164924025535583 G LOSS: 2.439572334289551\n",
            "EPOCH: 1 D LOSS 0.4809558689594269 G LOSS: 2.0614840984344482\n",
            "EPOCH: 1 D LOSS 0.46618975698947906 G LOSS: 1.5674734115600586\n",
            "EPOCH: 1 D LOSS 0.5782667994499207 G LOSS: 2.4501376152038574\n",
            "EPOCH: 1 D LOSS 0.6930741965770721 G LOSS: 1.6201560497283936\n",
            "EPOCH: 1 D LOSS 0.5902667045593262 G LOSS: 1.8054742813110352\n",
            "EPOCH: 1 D LOSS 0.4236568361520767 G LOSS: 1.8386461734771729\n",
            "EPOCH: 1 D LOSS 0.511476144194603 G LOSS: 1.6108535528182983\n",
            "EPOCH: 1 D LOSS 0.3340948950499296 G LOSS: 2.0028696060180664\n",
            "EPOCH: 1 D LOSS 0.4227677583694458 G LOSS: 2.5216543674468994\n",
            "EPOCH: 1 D LOSS 0.4746987074613571 G LOSS: 2.214526653289795\n",
            "EPOCH: 1 D LOSS 0.5159359499812126 G LOSS: 2.336467742919922\n",
            "EPOCH: 1 D LOSS 0.5233395993709564 G LOSS: 1.6308605670928955\n",
            "EPOCH: 1 D LOSS 0.5306988954544067 G LOSS: 2.0946273803710938\n",
            "EPOCH: 1 D LOSS 0.4915936291217804 G LOSS: 2.6252429485321045\n",
            "EPOCH: 1 D LOSS 0.5095850676298141 G LOSS: 2.1030569076538086\n",
            "EPOCH: 1 D LOSS 0.40888845920562744 G LOSS: 1.4093904495239258\n",
            "EPOCH: 1 D LOSS 0.5157057195901871 G LOSS: 1.7236297130584717\n",
            "EPOCH: 1 D LOSS 0.33698340225964785 G LOSS: 1.0339689254760742\n",
            "EPOCH: 1 D LOSS 0.8161236047744751 G LOSS: 1.8126190900802612\n",
            "EPOCH: 1 D LOSS 0.2978479117155075 G LOSS: 1.6644680500030518\n",
            "EPOCH: 1 D LOSS 0.48361149430274963 G LOSS: 1.3493717908859253\n",
            "EPOCH: 1 D LOSS 0.5534825474023819 G LOSS: 1.6996238231658936\n",
            "EPOCH: 1 D LOSS 0.5322345048189163 G LOSS: 1.6975027322769165\n",
            "EPOCH: 1 D LOSS 0.3446999825537205 G LOSS: 1.8302537202835083\n",
            "EPOCH: 1 D LOSS 0.744841992855072 G LOSS: 2.2878856658935547\n",
            "EPOCH: 1 D LOSS 0.5002660900354385 G LOSS: 2.1090893745422363\n",
            "EPOCH: 1 D LOSS 0.5869611501693726 G LOSS: 1.7916834354400635\n",
            "EPOCH: 1 D LOSS 0.4479869306087494 G LOSS: 1.6055870056152344\n",
            "EPOCH: 1 D LOSS 0.40887995064258575 G LOSS: 1.8421066999435425\n",
            "EPOCH: 1 D LOSS 0.30466278642416 G LOSS: 1.5775337219238281\n",
            "EPOCH: 1 D LOSS 0.4074411243200302 G LOSS: 1.7399179935455322\n",
            "EPOCH: 1 D LOSS 0.14552809298038483 G LOSS: 1.968491792678833\n",
            "EPOCH: 1 D LOSS 0.20664408802986145 G LOSS: 1.9246833324432373\n",
            "EPOCH: 1 D LOSS 0.46990446746349335 G LOSS: 2.4525363445281982\n",
            "EPOCH: 1 D LOSS 0.2999461814761162 G LOSS: 1.8991361856460571\n",
            "EPOCH: 1 D LOSS 0.22006556391716003 G LOSS: 2.2201414108276367\n",
            "EPOCH: 1 D LOSS 0.3309740424156189 G LOSS: 2.5078816413879395\n",
            "EPOCH: 1 D LOSS 0.3114818036556244 G LOSS: 2.041779041290283\n",
            "EPOCH: 1 D LOSS 0.7225846946239471 G LOSS: 2.3632564544677734\n",
            "EPOCH: 1 D LOSS 0.5500985383987427 G LOSS: 2.07135009765625\n",
            "EPOCH: 1 D LOSS 0.6939910054206848 G LOSS: 1.3002989292144775\n",
            "EPOCH: 1 D LOSS 0.5956549644470215 G LOSS: 1.0665149688720703\n",
            "EPOCH: 1 D LOSS 0.6271261870861053 G LOSS: 2.1319479942321777\n",
            "EPOCH: 1 D LOSS 0.41620542109012604 G LOSS: 1.872124195098877\n",
            "EPOCH: 1 D LOSS 0.4816111698746681 G LOSS: 1.2317535877227783\n",
            "EPOCH: 1 D LOSS 0.47680993378162384 G LOSS: 2.0734877586364746\n",
            "EPOCH: 1 D LOSS 0.6874620616436005 G LOSS: 2.4365057945251465\n",
            "EPOCH: 1 D LOSS 0.5483249425888062 G LOSS: 1.631289005279541\n",
            "EPOCH: 1 D LOSS 0.3620444727130234 G LOSS: 0.9372338652610779\n",
            "EPOCH: 1 D LOSS 0.5305808633565903 G LOSS: 1.8125617504119873\n",
            "EPOCH: 1 D LOSS 0.36339171230793 G LOSS: 1.3424878120422363\n",
            "EPOCH: 1 D LOSS 0.48404020071029663 G LOSS: 1.300329327583313\n",
            "EPOCH: 1 D LOSS 0.6047696173191071 G LOSS: 1.6637039184570312\n",
            "EPOCH: 1 D LOSS 0.3915636017918587 G LOSS: 1.2301368713378906\n",
            "EPOCH: 1 D LOSS 0.5059724003076553 G LOSS: 1.835103988647461\n",
            "EPOCH: 1 D LOSS 0.47577860951423645 G LOSS: 1.6279436349868774\n",
            "EPOCH: 1 D LOSS 0.5656394064426422 G LOSS: 1.2312157154083252\n",
            "EPOCH: 1 D LOSS 0.5092168413102627 G LOSS: 1.8249207735061646\n",
            "EPOCH: 1 D LOSS 0.426741361618042 G LOSS: 2.527566909790039\n",
            "EPOCH: 1 D LOSS 0.7033992111682892 G LOSS: 2.033038377761841\n",
            "EPOCH: 1 D LOSS 0.48598647117614746 G LOSS: 1.1767899990081787\n",
            "EPOCH: 1 D LOSS 0.4908475875854492 G LOSS: 1.4022347927093506\n",
            "EPOCH: 1 D LOSS 0.26476020086556673 G LOSS: 1.4706881046295166\n",
            "EPOCH: 1 D LOSS 0.2935074307024479 G LOSS: 1.364196538925171\n",
            "EPOCH: 1 D LOSS 0.5510590225458145 G LOSS: 1.37453031539917\n",
            "EPOCH: 1 D LOSS 0.2680748254060745 G LOSS: 1.733290672302246\n",
            "EPOCH: 1 D LOSS 0.7047229111194611 G LOSS: 2.365037441253662\n",
            "EPOCH: 1 D LOSS 0.40804797410964966 G LOSS: 1.6850178241729736\n",
            "EPOCH: 1 D LOSS 0.2643931992352009 G LOSS: 1.713376760482788\n",
            "EPOCH: 1 D LOSS 0.2093030959367752 G LOSS: 1.2365161180496216\n",
            "EPOCH: 1 D LOSS 0.6655728816986084 G LOSS: 1.6879031658172607\n",
            "EPOCH: 1 D LOSS 0.38628089427948 G LOSS: 1.6699941158294678\n",
            "EPOCH: 1 D LOSS 0.258505180478096 G LOSS: 1.8941023349761963\n",
            "EPOCH: 1 D LOSS 0.44422055035829544 G LOSS: 2.6222751140594482\n",
            "EPOCH: 1 D LOSS 0.6788028180599213 G LOSS: 1.5906522274017334\n",
            "EPOCH: 1 D LOSS 0.391949862241745 G LOSS: 1.1763489246368408\n",
            "EPOCH: 1 D LOSS 0.4761793613433838 G LOSS: 1.8951294422149658\n",
            "EPOCH: 1 D LOSS 0.643625795841217 G LOSS: 2.0795371532440186\n",
            "EPOCH: 1 D LOSS 0.6064517796039581 G LOSS: 1.236417293548584\n",
            "EPOCH: 1 D LOSS 0.5287484377622604 G LOSS: 1.345855474472046\n",
            "EPOCH: 1 D LOSS 0.6582136452198029 G LOSS: 1.7805259227752686\n",
            "EPOCH: 1 D LOSS 0.5729582905769348 G LOSS: 1.3815747499465942\n",
            "EPOCH: 1 D LOSS 0.39544737339019775 G LOSS: 1.4298781156539917\n",
            "EPOCH: 1 D LOSS 0.6557618975639343 G LOSS: 1.6284081935882568\n",
            "EPOCH: 1 D LOSS 0.5493703186511993 G LOSS: 1.1472375392913818\n",
            "EPOCH: 1 D LOSS 0.5927954018115997 G LOSS: 1.361711859703064\n",
            "EPOCH: 1 D LOSS 0.3401419073343277 G LOSS: 0.9994970560073853\n",
            "EPOCH: 1 D LOSS 0.6003239154815674 G LOSS: 1.3931388854980469\n",
            "EPOCH: 1 D LOSS 0.374537393450737 G LOSS: 1.4624202251434326\n",
            "EPOCH: 1 D LOSS 0.48434683680534363 G LOSS: 1.3721551895141602\n",
            "EPOCH: 1 D LOSS 0.5150456130504608 G LOSS: 1.4053492546081543\n",
            "EPOCH: 1 D LOSS 0.5126112103462219 G LOSS: 1.210597276687622\n",
            "EPOCH: 1 D LOSS 0.3925475776195526 G LOSS: 1.202528476715088\n",
            "EPOCH: 1 D LOSS 0.6378479301929474 G LOSS: 2.0237765312194824\n",
            "EPOCH: 1 D LOSS 0.5133611112833023 G LOSS: 1.8874871730804443\n",
            "EPOCH: 1 D LOSS 0.4213731586933136 G LOSS: 1.349531650543213\n",
            "EPOCH: 1 D LOSS 0.3040030747652054 G LOSS: 2.249690532684326\n",
            "EPOCH: 1 D LOSS 0.4376066029071808 G LOSS: 2.4758405685424805\n",
            "EPOCH: 1 D LOSS 0.31720588728785515 G LOSS: 1.294602870941162\n",
            "EPOCH: 1 D LOSS 0.614622950553894 G LOSS: 2.129892349243164\n",
            "EPOCH: 1 D LOSS 0.4411042332649231 G LOSS: 2.0562338829040527\n",
            "EPOCH: 1 D LOSS 0.6054865121841431 G LOSS: 1.8588252067565918\n",
            "EPOCH: 1 D LOSS 0.5194235146045685 G LOSS: 1.8362960815429688\n",
            "EPOCH: 1 D LOSS 0.6246033310890198 G LOSS: 1.7003979682922363\n",
            "EPOCH: 1 D LOSS 0.5732513964176178 G LOSS: 1.1788208484649658\n",
            "EPOCH: 1 D LOSS 0.511391643434763 G LOSS: 1.8586232662200928\n",
            "EPOCH: 1 D LOSS 0.33352237939834595 G LOSS: 1.9619148969650269\n",
            "EPOCH: 1 D LOSS 0.45614899694919586 G LOSS: 1.162980556488037\n",
            "EPOCH: 1 D LOSS 0.6527497470378876 G LOSS: 1.3452394008636475\n",
            "EPOCH: 1 D LOSS 0.6068748235702515 G LOSS: 1.3698023557662964\n",
            "EPOCH: 1 D LOSS 0.6521439850330353 G LOSS: 1.5728561878204346\n",
            "EPOCH: 1 D LOSS 0.5334653854370117 G LOSS: 1.0430748462677002\n",
            "EPOCH: 1 D LOSS 0.57400743663311 G LOSS: 1.4956622123718262\n",
            "EPOCH: 1 D LOSS 0.652814120054245 G LOSS: 1.830963134765625\n",
            "EPOCH: 1 D LOSS 0.4692305475473404 G LOSS: 1.1900633573532104\n",
            "EPOCH: 1 D LOSS 0.35530395805835724 G LOSS: 1.1757266521453857\n",
            "EPOCH: 1 D LOSS 0.3458830490708351 G LOSS: 1.8227849006652832\n",
            "EPOCH: 1 D LOSS 0.20539363473653793 G LOSS: 1.349191427230835\n",
            "EPOCH: 1 D LOSS 0.5823241472244263 G LOSS: 1.771020770072937\n",
            "EPOCH: 1 D LOSS 0.18451064079999924 G LOSS: 1.429307460784912\n",
            "EPOCH: 1 D LOSS 0.4676094055175781 G LOSS: 1.399404764175415\n",
            "EPOCH: 1 D LOSS 0.6826980710029602 G LOSS: 1.533360481262207\n",
            "EPOCH: 1 D LOSS 0.4750351458787918 G LOSS: 1.362282395362854\n",
            "EPOCH: 1 D LOSS 0.5094216912984848 G LOSS: 2.12153697013855\n",
            "EPOCH: 1 D LOSS 0.5202614367008209 G LOSS: 1.8472628593444824\n",
            "EPOCH: 1 D LOSS 0.4928872585296631 G LOSS: 1.7328824996948242\n",
            "EPOCH: 1 D LOSS 0.4826895296573639 G LOSS: 1.9512379169464111\n",
            "EPOCH: 1 D LOSS 0.4420522451400757 G LOSS: 1.8566198348999023\n",
            "EPOCH: 1 D LOSS 0.4360523670911789 G LOSS: 1.886423945426941\n",
            "EPOCH: 1 D LOSS 0.49665622413158417 G LOSS: 1.4586124420166016\n",
            "EPOCH: 1 D LOSS 0.5441611111164093 G LOSS: 2.3284921646118164\n",
            "EPOCH: 1 D LOSS 0.4540042281150818 G LOSS: 2.1919703483581543\n",
            "EPOCH: 1 D LOSS 0.638792872428894 G LOSS: 1.667994737625122\n",
            "EPOCH: 1 D LOSS 0.5738078728318214 G LOSS: 1.9046002626419067\n",
            "EPOCH: 1 D LOSS 0.27271413803100586 G LOSS: 1.8638920783996582\n",
            "EPOCH: 1 D LOSS 0.4660026878118515 G LOSS: 1.5406124591827393\n",
            "EPOCH: 1 D LOSS 0.5683703422546387 G LOSS: 1.6059938669204712\n",
            "EPOCH: 1 D LOSS 0.4444589614868164 G LOSS: 1.8567228317260742\n",
            "EPOCH: 1 D LOSS 0.4337618798017502 G LOSS: 2.06134295463562\n",
            "EPOCH: 1 D LOSS 0.410707488656044 G LOSS: 1.7145074605941772\n",
            "EPOCH: 1 D LOSS 0.5247496366500854 G LOSS: 2.1019747257232666\n",
            "EPOCH: 1 D LOSS 0.4814023971557617 G LOSS: 2.1609914302825928\n",
            "EPOCH: 1 D LOSS 0.5893731713294983 G LOSS: 1.3052096366882324\n",
            "EPOCH: 1 D LOSS 0.6055478751659393 G LOSS: 1.5273897647857666\n",
            "EPOCH: 1 D LOSS 0.39202382043004036 G LOSS: 1.7123591899871826\n",
            "EPOCH: 1 D LOSS 0.3837045431137085 G LOSS: 1.7284057140350342\n",
            "EPOCH: 1 D LOSS 0.45640384405851364 G LOSS: 1.4392452239990234\n",
            "EPOCH: 1 D LOSS 0.48071154952049255 G LOSS: 1.9293371438980103\n",
            "EPOCH: 1 D LOSS 0.3060831129550934 G LOSS: 2.1634583473205566\n",
            "EPOCH: 1 D LOSS 0.25205038115382195 G LOSS: 2.174936294555664\n",
            "EPOCH: 1 D LOSS 0.21186035871505737 G LOSS: 1.5636496543884277\n",
            "EPOCH: 1 D LOSS 0.6150607168674469 G LOSS: 2.925477981567383\n",
            "EPOCH: 1 D LOSS 0.4435069188475609 G LOSS: 1.0465445518493652\n",
            "EPOCH: 1 D LOSS 0.8483087122440338 G LOSS: 2.114044189453125\n",
            "EPOCH: 1 D LOSS 0.29024990648031235 G LOSS: 1.786695122718811\n",
            "EPOCH: 1 D LOSS 0.5487796068191528 G LOSS: 2.4505832195281982\n",
            "EPOCH: 1 D LOSS 0.7297741174697876 G LOSS: 1.8363980054855347\n",
            "EPOCH: 1 D LOSS 0.6085638105869293 G LOSS: 1.685304880142212\n",
            "EPOCH: 1 D LOSS 0.5251653790473938 G LOSS: 1.6330938339233398\n",
            "EPOCH: 1 D LOSS 0.5053530037403107 G LOSS: 1.4413375854492188\n",
            "EPOCH: 1 D LOSS 0.5808598101139069 G LOSS: 1.6084730625152588\n",
            "EPOCH: 1 D LOSS 0.4700462818145752 G LOSS: 1.984287977218628\n",
            "EPOCH: 1 D LOSS 0.4848824441432953 G LOSS: 1.189902424812317\n",
            "EPOCH: 1 D LOSS 0.45255473256111145 G LOSS: 1.7352231740951538\n",
            "EPOCH: 1 D LOSS 0.23279719799757004 G LOSS: 2.264568567276001\n",
            "EPOCH: 1 D LOSS 0.5211467742919922 G LOSS: 1.5085417032241821\n",
            "EPOCH: 1 D LOSS 0.2659873813390732 G LOSS: 1.767676591873169\n",
            "EPOCH: 1 D LOSS 0.5835126340389252 G LOSS: 2.8774800300598145\n",
            "EPOCH: 1 D LOSS 0.6923616826534271 G LOSS: 1.9922046661376953\n",
            "EPOCH: 1 D LOSS 0.5088351368904114 G LOSS: 1.5697113275527954\n",
            "EPOCH: 1 D LOSS 0.49939805269241333 G LOSS: 1.746419906616211\n",
            "EPOCH: 1 D LOSS 0.45601773262023926 G LOSS: 1.6301988363265991\n",
            "EPOCH: 1 D LOSS 0.43381041288375854 G LOSS: 1.9487659931182861\n",
            "EPOCH: 1 D LOSS 0.4602588713169098 G LOSS: 1.0912967920303345\n",
            "EPOCH: 1 D LOSS 0.5360127240419388 G LOSS: 1.3815834522247314\n",
            "EPOCH: 1 D LOSS 0.2079950049519539 G LOSS: 1.4733762741088867\n",
            "EPOCH: 1 D LOSS 0.4924227446317673 G LOSS: 1.781774878501892\n",
            "EPOCH: 1 D LOSS 0.3692772686481476 G LOSS: 1.6048640012741089\n",
            "EPOCH: 1 D LOSS 0.36735450103878975 G LOSS: 1.1566308736801147\n",
            "EPOCH: 1 D LOSS 0.34346336126327515 G LOSS: 2.138336658477783\n",
            "EPOCH: 1 D LOSS 0.1982266753911972 G LOSS: 2.388986587524414\n",
            "EPOCH: 1 D LOSS 0.1983659639954567 G LOSS: 1.723190426826477\n",
            "EPOCH: 1 D LOSS 0.49580545723438263 G LOSS: 2.232311248779297\n",
            "EPOCH: 1 D LOSS 0.16478407755494118 G LOSS: 1.7699185609817505\n",
            "EPOCH: 1 D LOSS 0.4579576849937439 G LOSS: 2.5233607292175293\n",
            "EPOCH: 1 D LOSS 0.11122308671474457 G LOSS: 1.907939076423645\n",
            "EPOCH: 1 D LOSS 0.4528745040297508 G LOSS: 2.695592164993286\n",
            "EPOCH: 1 D LOSS 0.32782265543937683 G LOSS: 1.9179826974868774\n",
            "EPOCH: 1 D LOSS 0.30219052731990814 G LOSS: 1.3956515789031982\n",
            "EPOCH: 1 D LOSS 0.3916120231151581 G LOSS: 3.1356663703918457\n",
            "EPOCH: 1 D LOSS 0.2599227875471115 G LOSS: 2.826730251312256\n",
            "EPOCH: 1 D LOSS 0.4847400337457657 G LOSS: 2.580885887145996\n",
            "EPOCH: 1 D LOSS 0.5623632669448853 G LOSS: 2.3618521690368652\n",
            "EPOCH: 1 D LOSS 0.766200989484787 G LOSS: 1.8276782035827637\n",
            "EPOCH: 1 D LOSS 0.5704895257949829 G LOSS: 1.7382755279541016\n",
            "EPOCH: 1 D LOSS 0.6472548544406891 G LOSS: 1.6986196041107178\n",
            "EPOCH: 1 D LOSS 0.5122909545898438 G LOSS: 1.6534078121185303\n",
            "EPOCH: 1 D LOSS 0.7183272838592529 G LOSS: 1.5254368782043457\n",
            "EPOCH: 1 D LOSS 0.6467982828617096 G LOSS: 1.4486262798309326\n",
            "EPOCH: 1 D LOSS 0.4960445240139961 G LOSS: 1.1268842220306396\n",
            "EPOCH: 1 D LOSS 0.628881573677063 G LOSS: 1.9767682552337646\n",
            "EPOCH: 1 D LOSS 0.44450049102306366 G LOSS: 1.6117345094680786\n",
            "EPOCH: 1 D LOSS 0.4885472059249878 G LOSS: 2.0387682914733887\n",
            "EPOCH: 1 D LOSS 0.5303348153829575 G LOSS: 2.076111078262329\n",
            "EPOCH: 1 D LOSS 0.4896996319293976 G LOSS: 1.611872911453247\n",
            "EPOCH: 1 D LOSS 0.3389875702559948 G LOSS: 1.7188575267791748\n",
            "EPOCH: 1 D LOSS 0.5025035291910172 G LOSS: 1.9612361192703247\n",
            "EPOCH: 1 D LOSS 0.42436614632606506 G LOSS: 2.419050931930542\n",
            "EPOCH: 1 D LOSS 0.4381529428064823 G LOSS: 3.1017537117004395\n",
            "EPOCH: 1 D LOSS 0.566617339849472 G LOSS: 1.368957757949829\n",
            "EPOCH: 1 D LOSS 0.5948028266429901 G LOSS: 2.1483559608459473\n",
            "EPOCH: 1 D LOSS 0.6078022122383118 G LOSS: 2.0292470455169678\n",
            "EPOCH: 1 D LOSS 0.28677038103342056 G LOSS: 1.3295706510543823\n",
            "EPOCH: 1 D LOSS 0.7037575244903564 G LOSS: 2.0325021743774414\n",
            "EPOCH: 1 D LOSS 0.22594979405403137 G LOSS: 1.951099157333374\n",
            "EPOCH: 1 D LOSS 0.3832465261220932 G LOSS: 1.3620131015777588\n",
            "EPOCH: 1 D LOSS 0.2987227141857147 G LOSS: 2.1601221561431885\n",
            "EPOCH: 1 D LOSS 0.7564253211021423 G LOSS: 2.4835050106048584\n",
            "EPOCH: 1 D LOSS 0.7255165576934814 G LOSS: 1.8161468505859375\n",
            "EPOCH: 1 D LOSS 0.5916734337806702 G LOSS: 1.2295126914978027\n",
            "EPOCH: 1 D LOSS 0.6628003418445587 G LOSS: 1.4688729047775269\n",
            "EPOCH: 1 D LOSS 0.40741224586963654 G LOSS: 1.5074131488800049\n",
            "EPOCH: 1 D LOSS 0.17823991179466248 G LOSS: 1.5812771320343018\n",
            "EPOCH: 1 D LOSS 0.06636577844619751 G LOSS: 1.599639654159546\n",
            "EPOCH: 1 D LOSS 0.3661532513797283 G LOSS: 1.6600825786590576\n",
            "EPOCH: 1 D LOSS 0.20215167524293065 G LOSS: 2.5227508544921875\n",
            "EPOCH: 1 D LOSS 0.646448016166687 G LOSS: 3.1578786373138428\n",
            "EPOCH: 1 D LOSS 0.42777810990810394 G LOSS: 1.502105474472046\n",
            "EPOCH: 1 D LOSS 0.7667691111564636 G LOSS: 2.4004852771759033\n",
            "EPOCH: 1 D LOSS 0.6708032786846161 G LOSS: 1.9910792112350464\n",
            "EPOCH: 1 D LOSS 0.6012887954711914 G LOSS: 1.634758472442627\n",
            "EPOCH: 1 D LOSS 0.38885027915239334 G LOSS: 1.1071457862854004\n",
            "EPOCH: 1 D LOSS 0.5725981593132019 G LOSS: 1.487964391708374\n",
            "EPOCH: 1 D LOSS 0.5569153428077698 G LOSS: 1.544891595840454\n",
            "EPOCH: 1 D LOSS 0.59290611743927 G LOSS: 1.5350801944732666\n",
            "EPOCH: 1 D LOSS 0.6045532524585724 G LOSS: 1.6772491931915283\n",
            "EPOCH: 1 D LOSS 0.5517688095569611 G LOSS: 1.527092456817627\n",
            "EPOCH: 1 D LOSS 0.4694315567612648 G LOSS: 1.8130614757537842\n",
            "EPOCH: 1 D LOSS 0.433525949716568 G LOSS: 1.6522494554519653\n",
            "EPOCH: 1 D LOSS 0.40633903443813324 G LOSS: 1.8154850006103516\n",
            "EPOCH: 1 D LOSS 0.5085478723049164 G LOSS: 1.8100237846374512\n",
            "EPOCH: 1 D LOSS 0.40807495824992657 G LOSS: 1.1282577514648438\n",
            "EPOCH: 1 D LOSS 0.4269764646887779 G LOSS: 1.5285708904266357\n",
            "EPOCH: 1 D LOSS 0.4905625879764557 G LOSS: 1.6153368949890137\n",
            "EPOCH: 1 D LOSS 0.662632167339325 G LOSS: 1.8208835124969482\n",
            "EPOCH: 2 D LOSS 0.44578851759433746 G LOSS: 1.0907442569732666\n",
            "EPOCH: 2 D LOSS 0.4978710114955902 G LOSS: 1.820960283279419\n",
            "EPOCH: 2 D LOSS 0.5268032550811768 G LOSS: 1.809140682220459\n",
            "EPOCH: 2 D LOSS 0.5330536663532257 G LOSS: 1.8545225858688354\n",
            "EPOCH: 2 D LOSS 0.42765791714191437 G LOSS: 1.321967363357544\n",
            "EPOCH: 2 D LOSS 0.359907842008397 G LOSS: 1.072643518447876\n",
            "EPOCH: 2 D LOSS 0.4467136859893799 G LOSS: 1.896508812904358\n",
            "EPOCH: 2 D LOSS 0.46765558421611786 G LOSS: 1.845111608505249\n",
            "EPOCH: 2 D LOSS 0.5340056121349335 G LOSS: 1.5275678634643555\n",
            "EPOCH: 2 D LOSS 0.646712452173233 G LOSS: 1.7673273086547852\n",
            "EPOCH: 2 D LOSS 0.454516276717186 G LOSS: 1.5374956130981445\n",
            "EPOCH: 2 D LOSS 0.3726515918970108 G LOSS: 1.4258869886398315\n",
            "EPOCH: 2 D LOSS 0.5427810549736023 G LOSS: 2.0564491748809814\n",
            "EPOCH: 2 D LOSS 0.5606825947761536 G LOSS: 2.0685458183288574\n",
            "EPOCH: 2 D LOSS 0.6285855770111084 G LOSS: 1.479372262954712\n",
            "EPOCH: 2 D LOSS 0.5449385046958923 G LOSS: 1.4643945693969727\n",
            "EPOCH: 2 D LOSS 0.4680722802877426 G LOSS: 1.8232439756393433\n",
            "EPOCH: 2 D LOSS 0.5307275056838989 G LOSS: 2.1833419799804688\n",
            "EPOCH: 2 D LOSS 0.45687417685985565 G LOSS: 1.5809354782104492\n",
            "EPOCH: 2 D LOSS 0.7595457434654236 G LOSS: 1.7304799556732178\n",
            "EPOCH: 2 D LOSS 0.38892287015914917 G LOSS: 1.5210866928100586\n",
            "EPOCH: 2 D LOSS 0.4920828640460968 G LOSS: 1.6059489250183105\n",
            "EPOCH: 2 D LOSS 0.41752370446920395 G LOSS: 1.2463874816894531\n",
            "EPOCH: 2 D LOSS 0.6388139128684998 G LOSS: 1.5785953998565674\n",
            "EPOCH: 2 D LOSS 0.49081963300704956 G LOSS: 1.2245604991912842\n",
            "EPOCH: 2 D LOSS 0.5389049500226974 G LOSS: 1.56708824634552\n",
            "EPOCH: 2 D LOSS 0.3664975203573704 G LOSS: 1.2440388202667236\n",
            "EPOCH: 2 D LOSS 0.506163477897644 G LOSS: 1.7870762348175049\n",
            "EPOCH: 2 D LOSS 0.7080460488796234 G LOSS: 1.922702431678772\n",
            "EPOCH: 2 D LOSS 0.5242255926132202 G LOSS: 1.0534741878509521\n",
            "EPOCH: 2 D LOSS 0.5541796088218689 G LOSS: 1.635603427886963\n",
            "EPOCH: 2 D LOSS 0.32172346115112305 G LOSS: 2.0579047203063965\n",
            "EPOCH: 2 D LOSS 0.5934278815984726 G LOSS: 2.0905532836914062\n",
            "EPOCH: 2 D LOSS 0.42532095313072205 G LOSS: 1.78187894821167\n",
            "EPOCH: 2 D LOSS 0.565336674451828 G LOSS: 1.2517457008361816\n",
            "EPOCH: 2 D LOSS 0.4093987927772105 G LOSS: 1.2591605186462402\n",
            "EPOCH: 2 D LOSS 0.4324990510940552 G LOSS: 1.694130778312683\n",
            "EPOCH: 2 D LOSS 0.33242613822221756 G LOSS: 1.2350627183914185\n",
            "EPOCH: 2 D LOSS 0.6659877896308899 G LOSS: 1.4551736116409302\n",
            "EPOCH: 2 D LOSS 0.33707787841558456 G LOSS: 1.439334511756897\n",
            "EPOCH: 2 D LOSS 0.5777314901351929 G LOSS: 1.772993564605713\n",
            "EPOCH: 2 D LOSS 0.322044737637043 G LOSS: 1.70221745967865\n",
            "EPOCH: 2 D LOSS 0.5997333824634552 G LOSS: 2.0793988704681396\n",
            "EPOCH: 2 D LOSS 0.5767222344875336 G LOSS: 1.8735216856002808\n",
            "EPOCH: 2 D LOSS 0.48325973749160767 G LOSS: 1.7140889167785645\n",
            "EPOCH: 2 D LOSS 0.41906656324863434 G LOSS: 1.1659963130950928\n",
            "EPOCH: 2 D LOSS 0.43963446468114853 G LOSS: 1.7338517904281616\n",
            "EPOCH: 2 D LOSS 0.5695123374462128 G LOSS: 2.2326786518096924\n",
            "EPOCH: 2 D LOSS 0.4917317032814026 G LOSS: 1.8450138568878174\n",
            "EPOCH: 2 D LOSS 0.49654051661491394 G LOSS: 1.603668212890625\n",
            "EPOCH: 2 D LOSS 0.5561008155345917 G LOSS: 1.8820738792419434\n",
            "EPOCH: 2 D LOSS 0.44545477628707886 G LOSS: 1.7076632976531982\n",
            "EPOCH: 2 D LOSS 0.6164084672927856 G LOSS: 1.687693476676941\n",
            "EPOCH: 2 D LOSS 0.449308380484581 G LOSS: 0.9898275136947632\n",
            "EPOCH: 2 D LOSS 0.2769887298345566 G LOSS: 1.2205499410629272\n",
            "EPOCH: 2 D LOSS 0.3186766505241394 G LOSS: 2.2208940982818604\n",
            "EPOCH: 2 D LOSS 0.5795307755470276 G LOSS: 2.377394437789917\n",
            "EPOCH: 2 D LOSS 0.5422403812408447 G LOSS: 1.5110304355621338\n",
            "EPOCH: 2 D LOSS 0.33948122523725033 G LOSS: 1.4647514820098877\n",
            "EPOCH: 2 D LOSS 0.4382396340370178 G LOSS: 2.1313247680664062\n",
            "EPOCH: 2 D LOSS 0.5496447682380676 G LOSS: 1.9209444522857666\n",
            "EPOCH: 2 D LOSS 0.36496224999427795 G LOSS: 1.200362205505371\n",
            "EPOCH: 2 D LOSS 0.2885909527540207 G LOSS: 1.8822364807128906\n",
            "EPOCH: 2 D LOSS 0.417237788438797 G LOSS: 2.3077573776245117\n",
            "EPOCH: 2 D LOSS 0.33365486562252045 G LOSS: 1.6765575408935547\n",
            "EPOCH: 2 D LOSS 0.7680142819881439 G LOSS: 1.6278995275497437\n",
            "EPOCH: 2 D LOSS 0.40484246611595154 G LOSS: 1.699324369430542\n",
            "EPOCH: 2 D LOSS 0.4041767492890358 G LOSS: 1.3890454769134521\n",
            "EPOCH: 2 D LOSS 0.3815950220450759 G LOSS: 1.6971206665039062\n",
            "EPOCH: 2 D LOSS 0.5967371761798859 G LOSS: 2.058900833129883\n",
            "EPOCH: 2 D LOSS 0.4935603439807892 G LOSS: 1.6538803577423096\n",
            "EPOCH: 2 D LOSS 0.6028491258621216 G LOSS: 1.6737349033355713\n",
            "EPOCH: 2 D LOSS 0.4860537648200989 G LOSS: 1.6475088596343994\n",
            "EPOCH: 2 D LOSS 0.46211838722229004 G LOSS: 2.007234573364258\n",
            "EPOCH: 2 D LOSS 0.49551334977149963 G LOSS: 1.0360729694366455\n",
            "EPOCH: 2 D LOSS 0.628324031829834 G LOSS: 1.681848168373108\n",
            "EPOCH: 2 D LOSS 0.3528132438659668 G LOSS: 1.7252967357635498\n",
            "EPOCH: 2 D LOSS 0.3664932809770107 G LOSS: 1.6261440515518188\n",
            "EPOCH: 2 D LOSS 0.3306788206100464 G LOSS: 2.2808713912963867\n",
            "EPOCH: 2 D LOSS 0.2657643388956785 G LOSS: 1.8363869190216064\n",
            "EPOCH: 2 D LOSS 0.45163269340991974 G LOSS: 2.2079262733459473\n",
            "EPOCH: 2 D LOSS 0.5914600193500519 G LOSS: 1.6977944374084473\n",
            "EPOCH: 2 D LOSS 0.6308350563049316 G LOSS: 1.819369912147522\n",
            "EPOCH: 2 D LOSS 0.49552467465400696 G LOSS: 1.9051933288574219\n",
            "EPOCH: 2 D LOSS 0.3798673152923584 G LOSS: 2.0132968425750732\n",
            "EPOCH: 2 D LOSS 0.4891810640692711 G LOSS: 2.5885467529296875\n",
            "EPOCH: 2 D LOSS 0.6737300753593445 G LOSS: 1.775990605354309\n",
            "EPOCH: 2 D LOSS 0.5431652069091797 G LOSS: 1.6897637844085693\n",
            "EPOCH: 2 D LOSS 0.3824970871210098 G LOSS: 1.500604510307312\n",
            "EPOCH: 2 D LOSS 0.7976665198802948 G LOSS: 1.6553490161895752\n",
            "EPOCH: 2 D LOSS 0.5243468880653381 G LOSS: 1.5733479261398315\n",
            "EPOCH: 2 D LOSS 0.509492352604866 G LOSS: 1.283468246459961\n",
            "EPOCH: 2 D LOSS 0.5871624946594238 G LOSS: 1.4232490062713623\n",
            "EPOCH: 2 D LOSS 0.5975528955459595 G LOSS: 1.552998661994934\n",
            "EPOCH: 2 D LOSS 0.7004107236862183 G LOSS: 1.3401809930801392\n",
            "EPOCH: 2 D LOSS 0.6727595925331116 G LOSS: 1.4485399723052979\n",
            "EPOCH: 2 D LOSS 0.6040510833263397 G LOSS: 1.1745518445968628\n",
            "EPOCH: 2 D LOSS 0.4781088838353753 G LOSS: 1.8110382556915283\n",
            "EPOCH: 2 D LOSS 0.43542009592056274 G LOSS: 1.7306350469589233\n",
            "EPOCH: 2 D LOSS 0.3407150059938431 G LOSS: 1.3451104164123535\n",
            "EPOCH: 2 D LOSS 0.18720576167106628 G LOSS: 1.4895802736282349\n",
            "EPOCH: 2 D LOSS 0.5042562931776047 G LOSS: 2.592076539993286\n",
            "EPOCH: 2 D LOSS 0.4683733284473419 G LOSS: 2.1923117637634277\n",
            "EPOCH: 2 D LOSS 0.5362666547298431 G LOSS: 1.6271755695343018\n",
            "EPOCH: 2 D LOSS 0.4729748070240021 G LOSS: 1.6451321840286255\n",
            "EPOCH: 2 D LOSS 0.25901221483945847 G LOSS: 1.9279985427856445\n",
            "EPOCH: 2 D LOSS 0.565555214881897 G LOSS: 2.5828795433044434\n",
            "EPOCH: 2 D LOSS 0.7555302679538727 G LOSS: 1.7757418155670166\n",
            "EPOCH: 2 D LOSS 0.5200821459293365 G LOSS: 1.2314562797546387\n",
            "EPOCH: 2 D LOSS 0.5512430369853973 G LOSS: 1.383108377456665\n",
            "EPOCH: 2 D LOSS 0.43426060676574707 G LOSS: 1.1990513801574707\n",
            "EPOCH: 2 D LOSS 0.49696385860443115 G LOSS: 1.3583959341049194\n",
            "EPOCH: 2 D LOSS 0.5173492282629013 G LOSS: 1.885514497756958\n",
            "EPOCH: 2 D LOSS 0.4538258761167526 G LOSS: 1.7480125427246094\n",
            "EPOCH: 2 D LOSS 0.5169516354799271 G LOSS: 2.10135555267334\n",
            "EPOCH: 2 D LOSS 0.5121328830718994 G LOSS: 1.3941525220870972\n",
            "EPOCH: 2 D LOSS 0.5237289369106293 G LOSS: 1.9449925422668457\n",
            "EPOCH: 2 D LOSS 0.5153114348649979 G LOSS: 2.6437978744506836\n",
            "EPOCH: 2 D LOSS 0.7598247528076172 G LOSS: 1.7557051181793213\n",
            "EPOCH: 2 D LOSS 0.5618884861469269 G LOSS: 1.1013259887695312\n",
            "EPOCH: 2 D LOSS 0.5656147003173828 G LOSS: 1.2266669273376465\n",
            "EPOCH: 2 D LOSS 0.5297144651412964 G LOSS: 1.5209567546844482\n",
            "EPOCH: 2 D LOSS 0.6129864454269409 G LOSS: 1.7972878217697144\n",
            "EPOCH: 2 D LOSS 0.502133920788765 G LOSS: 1.3073248863220215\n",
            "EPOCH: 2 D LOSS 0.5617816001176834 G LOSS: 1.163625717163086\n",
            "EPOCH: 2 D LOSS 0.6339063048362732 G LOSS: 1.4960651397705078\n",
            "EPOCH: 2 D LOSS 0.4106499180197716 G LOSS: 1.4127776622772217\n",
            "EPOCH: 2 D LOSS 0.5513451397418976 G LOSS: 1.625779390335083\n",
            "EPOCH: 2 D LOSS 0.41817156970500946 G LOSS: 1.4184508323669434\n",
            "EPOCH: 2 D LOSS 0.5180617570877075 G LOSS: 1.853893756866455\n",
            "EPOCH: 2 D LOSS 0.4647473692893982 G LOSS: 1.687138557434082\n",
            "EPOCH: 2 D LOSS 0.37287725508213043 G LOSS: 1.833014726638794\n",
            "EPOCH: 2 D LOSS 0.45403730869293213 G LOSS: 2.001710891723633\n",
            "EPOCH: 2 D LOSS 0.5502833724021912 G LOSS: 1.721442699432373\n",
            "EPOCH: 2 D LOSS 0.4203256815671921 G LOSS: 1.2150917053222656\n",
            "EPOCH: 2 D LOSS 0.4616106450557709 G LOSS: 1.9261960983276367\n",
            "EPOCH: 2 D LOSS 0.33235861361026764 G LOSS: 2.2174386978149414\n",
            "EPOCH: 2 D LOSS 0.4591112807393074 G LOSS: 2.383159875869751\n",
            "EPOCH: 2 D LOSS 0.5457226037979126 G LOSS: 1.562208890914917\n",
            "EPOCH: 2 D LOSS 0.6195964813232422 G LOSS: 1.518991231918335\n",
            "EPOCH: 2 D LOSS 0.47760947048664093 G LOSS: 1.8678834438323975\n",
            "EPOCH: 2 D LOSS 0.3599173575639725 G LOSS: 1.8564881086349487\n",
            "EPOCH: 2 D LOSS 0.4636308550834656 G LOSS: 2.332096576690674\n",
            "EPOCH: 2 D LOSS 0.48608413338661194 G LOSS: 1.8034106492996216\n",
            "EPOCH: 2 D LOSS 0.45932648703455925 G LOSS: 1.2392427921295166\n",
            "EPOCH: 2 D LOSS 0.3731630742549896 G LOSS: 1.935049057006836\n",
            "EPOCH: 2 D LOSS 0.6206841468811035 G LOSS: 2.062295436859131\n",
            "EPOCH: 2 D LOSS 0.34551626443862915 G LOSS: 1.8682154417037964\n",
            "EPOCH: 2 D LOSS 0.6586461961269379 G LOSS: 1.8341038227081299\n",
            "EPOCH: 2 D LOSS 0.6706115007400513 G LOSS: 1.4828846454620361\n",
            "EPOCH: 2 D LOSS 0.5339089035987854 G LOSS: 1.7261106967926025\n",
            "EPOCH: 2 D LOSS 0.41546885669231415 G LOSS: 1.3758559226989746\n",
            "EPOCH: 2 D LOSS 0.4006984541192651 G LOSS: 1.7352259159088135\n",
            "EPOCH: 2 D LOSS 0.5154229700565338 G LOSS: 1.6326086521148682\n",
            "EPOCH: 2 D LOSS 0.4700237512588501 G LOSS: 1.490237832069397\n",
            "EPOCH: 2 D LOSS 0.7420065999031067 G LOSS: 1.7720459699630737\n",
            "EPOCH: 2 D LOSS 0.4208102449774742 G LOSS: 1.415473222732544\n",
            "EPOCH: 2 D LOSS 0.32001490145921707 G LOSS: 1.2676172256469727\n",
            "EPOCH: 2 D LOSS 0.1502247452735901 G LOSS: 2.0206751823425293\n",
            "EPOCH: 2 D LOSS 0.23822471499443054 G LOSS: 2.3360159397125244\n",
            "EPOCH: 2 D LOSS 0.24607279151678085 G LOSS: 2.1157002449035645\n",
            "EPOCH: 2 D LOSS 0.8442477285861969 G LOSS: 2.0964598655700684\n",
            "EPOCH: 2 D LOSS 0.6152382493019104 G LOSS: 1.705135464668274\n",
            "EPOCH: 2 D LOSS 0.2657879963517189 G LOSS: 1.3322687149047852\n",
            "EPOCH: 2 D LOSS 0.2570105791091919 G LOSS: 1.5755345821380615\n",
            "EPOCH: 2 D LOSS 0.5306403413414955 G LOSS: 2.457533836364746\n",
            "EPOCH: 2 D LOSS 0.30911344289779663 G LOSS: 1.871888279914856\n",
            "EPOCH: 2 D LOSS 0.7611312568187714 G LOSS: 2.0237417221069336\n",
            "EPOCH: 2 D LOSS 0.3943318501114845 G LOSS: 1.1811408996582031\n",
            "EPOCH: 2 D LOSS 0.5965365469455719 G LOSS: 1.9612897634506226\n",
            "EPOCH: 2 D LOSS 0.642251193523407 G LOSS: 2.15427827835083\n",
            "EPOCH: 2 D LOSS 0.6136267781257629 G LOSS: 1.3175263404846191\n",
            "EPOCH: 2 D LOSS 0.4833575636148453 G LOSS: 1.1418200731277466\n",
            "EPOCH: 2 D LOSS 0.2463744431734085 G LOSS: 1.6806390285491943\n",
            "EPOCH: 2 D LOSS 0.44188301265239716 G LOSS: 1.6621880531311035\n",
            "EPOCH: 2 D LOSS 0.3263389151543379 G LOSS: 1.1905922889709473\n",
            "EPOCH: 2 D LOSS 0.6926589012145996 G LOSS: 2.1525321006774902\n",
            "EPOCH: 2 D LOSS 0.6944202482700348 G LOSS: 1.9257757663726807\n",
            "EPOCH: 2 D LOSS 0.4818076193332672 G LOSS: 0.9790676236152649\n",
            "EPOCH: 2 D LOSS 0.6941587924957275 G LOSS: 1.5658292770385742\n",
            "EPOCH: 2 D LOSS 0.3611081391572952 G LOSS: 1.4259982109069824\n",
            "EPOCH: 2 D LOSS 0.5950169265270233 G LOSS: 1.485152006149292\n",
            "EPOCH: 2 D LOSS 0.5502216815948486 G LOSS: 1.4693701267242432\n",
            "EPOCH: 2 D LOSS 0.6075988709926605 G LOSS: 1.4771615266799927\n",
            "EPOCH: 2 D LOSS 0.5057850480079651 G LOSS: 1.1765003204345703\n",
            "EPOCH: 2 D LOSS 0.49179969169199467 G LOSS: 1.2109639644622803\n",
            "EPOCH: 2 D LOSS 0.4726007878780365 G LOSS: 1.689941644668579\n",
            "EPOCH: 2 D LOSS 0.39143921434879303 G LOSS: 1.3266570568084717\n",
            "EPOCH: 2 D LOSS 0.20194977521896362 G LOSS: 1.1557393074035645\n",
            "EPOCH: 2 D LOSS 0.33088603615760803 G LOSS: 1.656172752380371\n",
            "EPOCH: 2 D LOSS 0.5946557968854904 G LOSS: 2.271048069000244\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8f1a0c4f3128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-94dac85d219e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m#Train the discriminator (add random smoothing to labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                                                     class_weight)\n\u001b[1;32m   1899\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}